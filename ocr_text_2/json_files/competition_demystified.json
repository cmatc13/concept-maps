{"002911.png": {"text": "CHAPTER 1\n\nStrategy, Markets, and Competition\n\nWHAT IS STRATEGY?\n\nFor at least the last half century, strategy has been a major focus of management concern. The Allied victory in the Second World\nWar highlighted the necessity of grand strategy for success in warfare, and in the subsequent decades, corporate chieftains appro-\npriated the concept for their own battlefields. Today, strategy is a primary business school discipline. Most major companies have\nin-house strategic planning units, and those that don\u2019t often hire teams of outside consultants to come in and guide the process.\n\nOver the decades, definitions of strategy have changed, and the processes for developing it have undergone endless modifica-\ntions and revolutions. Some companies have even abandoned formal processes altogether. Yet within all of this flux, one feature of\nstrategy has stood out to distinguish it from other management responsibilities.\n\nStrategy is big. Unlike tactical choices, everyone knows strategic decisions mean long-term commitments for the organization.\n\nThey require large allocations of resources. Top management makes the strategic decisions. And setting strategy entails arduous\n\f"}, "002912.png": {"text": "research and bone-wearying meetings. Changing strategies is like changing the direction of an aircraft carrier\u2014it doesn\u2019t happen\n\nquickly.\n\nIn World War II, the highest-level strategic decision made by the United States was whether to fight the major campaign first\n\nin Europe or in the Pacific. Other strategic decisions at somewhat lower levels were the commitment to open a second front and\n\nthe selection of the Normandy beaches for the invasion of Europe. On the corporate side, AT&T\u2019s two separate decisions to enter\n\nthe information processing business and to spin off local telephone service were strategic choices.: Neither was successful. General\n\nElectric\u2019s policy, enunciated long before Jack Welch became CEO, that it would leave any business in which it did not have a leading\n\nmarket share, was a strategic principle.\n\nTABLE 1.1\nDistinctions between strategic and tactical decisions\n\nStrategic Decisions\n\nManagement level Top management, board of directors\n\nResources Corporate\n\nTime frame Long term\n\nRisk Success or even survival\nQuestions What business do we want to be in?\n\nWhat critical competencies must we\n\ndevelop?\n\nHow are we going to deal with competitors?\n\nTactical (and Operational or Functional) Decisions\nMidlevel, functional, local\nDivisional, departmental\nYearly, monthly, daily\nLimited\n\nHow do we improve delivery times?\n\nHow big a promotional discount do we offer?\n\nWhat is the best career path for our sales representatives?\n\f"}, "002913.png": {"text": "Occasionally, enormous consequences flow from decisions that at the time do not look strategic. When IBM entered the\npersonal computer business, it chose an open standards approach and made two build-or-buy decisions that probably seemed\ninconsequential and merely tactical. Rather than developing the operating system itself, it licensed one from a tiny company no\none had heard of. It made a similar choice for the microprocessor, giving the business to another supplier. These decisions created\ntwo of the most successful business franchises of all time, Microsoft and Intel. These companies, rather than IBM, became the ben-\neficiaries of the boom in personal computing. In retrospect, these were clearly strategic decisions with enormous consequences. If\nwe were to look closely at the history of big outcomes, we would no doubt find that many others were not results of any strategic\nplanning process but were either unintended by-products of some other decision or simply were results on a much larger scale\nthan anticipated.\n\nBut big, whether measured by financial commitments or hours spent in planning, or even outcomes, is not the same thing as\nstrategic. Although size and significance are aspects of most strategic business decisions, we propose that they are not the defining\ncriteria. We think the dividing line between strategy and tactics lies elsewhere.\n\nIn our view, strategic decisions are those whose results depend on the actions and reactions of other economic entities. Tactical\ndecisions are ones that can be made in isolation and hinge largely on effective implementation. Understanding this distinction is\nkey to developing effective strategy.\n\nFormulating effective strategy is central to business success. It is also extremely challenging. The most valuable resource in any\nbusiness is management attention, especially the attention of high-level management. This attention should not be squandered\nona range of unfocused or inappropriate objectives or consumed by endless discussions about the proper direction for the firm.\nOur goal in this book is to present a clear step-by-step process for strategic analysis, first to help a firm understand where it fits in\n\nthe competitive environment and second, to guide it in its strategic choices.\n\nSTRATEGIC VS. TACTICAL ISSUES\n\f"}, "002914.png": {"text": "Consider this example. Responding to the success of the Jeep in the mid 1980s, many automobile companies chose to produce\n\na sport utility vehicle. The decision to enter the SUV market was strategic for those companies. After that, everything was tac-\ntical. Success depended on efficient performance, including the appropriate investments in plants and equipment, marketing\ncampaigns, design and engineering time, and management attention devoted to continuous organizational improvement. That\u2019s\nbecause, given the competitive nature of this market, and the ease with which all the companies could enter, no firm needed\n\nto concern itself with the actions of its competitors. There were simply too many to worry about. Success depended on skillful\nimplementation.\n\nStrategic choices, in contrast to tactical ones, are outward looking. They involve two issues that every company must face.\n\nThe first issue is selecting the arena of competition, the market in which to engage. All the illustrations we\u2019ve cited\u2014the United\nStates picking the prime theater of operations in World War II, AT&T\u2019s selection of markets to enter and to abandon, General Elec-\ntric\u2019s policy of qualifying business segments in which to compete\u2014involve this kind of choice. So did IBM\u2019s decision to outsource\nthe operating system and the microprocessor for its PC; it opted not to compete in those markets. The choice of markets is strate-\ngic, according to our definition, because it determines the cast of external characters who will affect a company\u2019s economic future.\n\nThe second strategic issue involves the management of those external agents. In order to devise and implement effective strat-\negy, a firm has to anticipate and, if possible, control the responses of these external agents. Both theory and experience indicate\nthat this is no easy task. These interactions are complicated and uncertain. There are no exact prescriptions available for the man-\nagers who have to make strategic decisions or for the business scholars who have to explain why certain ones work out better than\nothers. All the best-in-class disciplines in the world cannot predict with absolute certainty how some testosterone-crazed CEO will\n\nrespond to your latest move. Yet devising strategy without taking that response into account can be a glaring mistake.\n\nONE SINGLE FORCE\n\f"}, "002915.png": {"text": "Thanks to Michael Porter\u2019s groundbreaking work, Competitive Strategy, published in 1980, strategic thinking in recent years in-\ncreasingly has come to recognize the importance of interactions among economic actors. By concentrating on external agents and\nhow they behave, Porter clearly moved strategic planning in the right direction. But, for many people, identifying the many factors\nin Porter\u2019s complex model and figuring out how they will play off one another has proven to be frustratingly difficult. What we are\nproposing here is a radically simpler approach.\n\nWe agree with Porter\u2019s view that five forces\u2014Substitutes, Suppliers, Potential Entrants, Buyers, and Competitors within the\nIndustry\u2014can affect the competitive environment. But, unlike Porter and many of his followers, we do not think that those forces\nare of equal importance. One of them is clearly much more important than the others. It is so dominant that leaders seeking to\ndevelop and pursue winning strategies should begin by ignoring the others and focus only on it. That force is barriers to entry\u2014the\nforce that underlies Porter\u2019s \u201cPotential Entrants.\u201d\n\nIf there are barriers, then it is difficult for new firms to enter the market or for existing companies to expand, which is basically\nthe same thing. Essentially there are only two possibilities. Either the existing firms within the market are protected by barriers to\nentry (or to expansion), or they are not. No other feature of the competitive landscape has as much influence on a company\u2019s suc-\ncess as where it stands in regard to these barriers.\n\nIf there are no barriers to entry, then many strategic concerns can be ignored. The company does not have to worry about\ninteracting with identifiable competitors or about anticipating and influencing their behavior. There are simply too many of them\nto deal with.\n\nWith a universe of companies seeking profitable opportunities for investment, the returns in an unprotected industry will be\ndriven down to levels where there is no \u201ceconomic profit,\u201d that is, no returns above the costs of the invested capital. If demand con-\nditions enable any single firm to earn unusually high returns, other companies will notice the same opportunity and flood in. Both\nhistory and theory support the truth of this proposition. As more firms enter, demand is fragmented among them. Costs per unit\n\nrise as fixed costs are spread over fewer units sold, prices fall, and the high profits that attracted the new entrants disappear.\n\f"}, "002916.png": {"text": "Life in an unprotected market is a game played on a level field in which anyone can join. In these markets, often but mistakenly\nidentified as \u201ccommodity\u201d markets,: only the very best players will survive and prosper, and even they have to be continually on\ntheir toes. Without the protection of barriers to entry, the only option a company has is to run itself as efficiently and effectively as\npossible.\n\nOperational effectiveness might be thought of as a strategy, indeed, as the only strategy appropriate in markets without\nbarriers to entry. However, operational effectiveness, identified by Michael Porter as doing what rivals do but doing it better, is\nan internal matter. According to our definition of strategy, it is tactical rather than strategic. That does not make it insignificant.\nOperational effectiveness can be the single most important factor in the success, or indeed in the survival, of any business. In the\nlast chapter of this book, we describe the extent to which a determined focus on operational effectiveness may carry one firm far\nahead of its competitors, even though there is nothing that distinguishes its fundamental economic position from that of its less\nsuccessful rivals.\n\nStill, the pursuit of operational effectiveness does not require consideration of all the external interactions that are the essence\n\nof real strategy.\n\nBARRIERS TO ENTRY AND COMPETITIVE ADVANTAGES\n\nThe existence of barriers to entry means that incumbent firms are able to do what potential rivals cannot. Being able to do what\nrivals cannot is the definition of a competitive advantage. Thus, barriers to entry and incumbent competitive advantages are simply\ntwo ways of describing the same thing. Entrant competitive advantages, on the other hand, have no value. By definition, a success-\nful entrant becomes the incumbent. It then is vulnerable to the next entrant, who benefits from newer technology, less expensive\nlabor, or some other temporary competitive edge. And because there are no barriers to entry, the cycle doesn\u2019t stop. So it is only in\n\nthe presence of incumbent competitive advantages that strategy, in our sense of the term, comes to the fore.\n\f"}, "002917.png": {"text": "LOCAL CHAMPIONS\n\nIn an increasingly global environment, with lower trade barriers, cheaper transportation, faster flow of information, and relent-\nless competition from both established rivals and newly liberalized economies, it might appear that competitive advantages and\nbarriers to entry will diminish. The fate of once powerful American firms in industries like machine tools (Cincinnati), textiles\n(Burlington Industries, J. P. Stevens), and even automobiles (Chrysler, GM, and Ford) seems to support this position. Either profits\nhave shrunk or companies have disappeared entirely under the onslaught of imports. But this macro view misses one essential\nfeature of competitive advantages\u2014that competitive advantages are almost always grounded in what are essentially \u201clocal\u201d\ncircumstances.\n\nConsider the history of Wal-Mart, one of the greatest economic success stories of the late twentieth century. The retail busi-\nness, especially discount retailing, is not an industry with many trade secrets or rare skills. The practices for which Wal-Mart is\nknown, like \u201ceveryday low prices\u201d and efficient distribution, are hardly proprietary technologies, impossible for other firms to du-\nplicate. Yet Wal-Mart has successfully dominated many, although not all, of the markets in which it competes. The way in which it\nachieved this position is instructive.\n\n\u2018Wal-Mart began as a small and regionally focused discounter in a part of the country where it had little competition. It\nexpanded incrementally outward from this geographic base, adding new stores and distribution centers at the periphery of its\nexisting territory. The market that it dominated and in which it first enjoyed competitive advantages was not discount retailing in\nthe United States, but discount retailing within a clearly circumscribed region. As it pushed the boundaries of this region outward,\nit consolidated its position in the newly entered territory before continuing its expansion. As we shall see, when it moved too far\nbeyond its base, its results deteriorated.\n\nThe same process of establishing local dominance and then expanding into related territories accounts for two of the other\ngreat corporate achievements of the period, although in these cases the geography in question is product market space, not physi-\n\ncal territory.\n\f"}, "002918.png": {"text": "Microsoft began by dominating one particular segment, the operating system for IBM-type personal computers. It faced some\ncompetitors at the start, including for a time IBM itself, but Microsoft was able to establish and secure competitive advantages and\nmarginalize all the other players. It expanded successfully at the edges of this business, adding adjacent software products like\nword processing, spreadsheets, and other productivity tools. Even as a much larger company, with an extensive product line, the\ncore of its profitability remains the operating system and the adjacent software.\n\nApple's experience stands in stark contrast. From the start, Apple took a more global approach than Microsoft. It was both a\ncomputer manufacturer and a software producer. Its Macintosh operating system anticipated the attractive features of Windows\nby many years\u2014 \u201cWindows 5=Macintosh 87,\u201d as the saying goes. Yet its comprehensive product strategy has been at best a limited\nand occasional success, especially when compared to Microsoft\u2019s more focused approach.\n\nIntel\u2019s history is closer to Microsoft's. It began life as a manufacturer of memory chips in the 1970s and was profitable for a\ntime in that market. It also designed and produced microprocessors, one of which was selected by IBM as the heart of its new PC\nin 1980. Intel continued in both businesses for several years, but it began to lose out on the memory chip side to companies with\nlower costs and fewer defects. It made the decision in 1985 to abandon that business, even though memory chips were part of its\ncorporate DNA. By concentrating on microprocessors, Intel restored and increased its profitability and has maintained its domi-\nnance in that large market ever since.\n\nCompetitive advantages that lead to market dominance, either by a single company or by a small number of essentially equiv-\nalent firms, are much more likely to be found when the arena is local\u2014bounded either geographically or in product space\u2014than\nwhen it is large and scattered. That is because the sources of competitive advantage, as we will see, tend to be local and specific, not\ngeneral or diffuse.\n\nParadoxically, in an increasingly global world, the key strategic imperative in market selection is to think locally. Dominance at\nthe local level may be easier to accomplish than one might initially think. If the global economy follows the path of the more devel-\noped national economies, service industries will become increasingly important and manufacturing less significant. The distin-\n\nguishing feature of most services is that they are produced and consumed locally. As a consequence, opportunities for sustained\n\f"}, "002919.png": {"text": "competitive advantages, properly understood, are likely to increase, not diminish. The chances of becoming the next Wal-Mart or\n\nMicrosoft are infinitesimal, but the focused company that understands its markets and its particular strengths can still flourish.\n\n\u2018WHICH COMPETITIVE ADVANTAGES?\n\nStrategic analysis should begin with two key questions: In the market in which the firm currently competes or plans to enter, do\nany competitive advantages actually exist? And if they do, what kind of advantages are they?\n\nThe analysis is made easier because there are only three kinds of genuine competitive advantage:\n\n+ Supply. These are strictly cost advantages that allow a company to produce and deliver its products or services\nmore cheaply than its competitors. Sometimes the lower costs stem from privileged access to crucial inputs, like\naluminum ore or easily recoverable oil deposits. More frequently, cost advantages are due to proprietary technol-\nogy that is protected by patents or by experience\u2014know-how\u2014or some combination of both.\n\n+ Demand. Some companies have access to market demand that their competitors cannot match. This access is not\nsimply a matter of product differentiation or branding, since competitors may be equally able to differentiate or\nbrand their products. These demand advantages arise because of customer captivity that is based on habit, on the\ncosts of switching, or on the difficulties and expenses of searching for a substitute provider.\n\n- Economies of scale. If costs per unit decline as volume increases, because fixed costs make up a large share of total\ncosts, then even with the same basic technology, an incumbent firm operating at large scale will enjoy lower costs\n\nthan its competitors.\n\f"}, "002920.png": {"text": "Beyond these three basic sources of competitive advantage, government protection or, in financial markets, superior access to\ninformation may also be competitive advantages, but these tend to apply to relatively few and specific situations. The economic\nforces behind all three primary sources of competitive advantage are most likely to be present in markets that are local either\ngeographically or in product space. Pepsi loyalists have no particular attachment to Frito-Lay salty snacks, any more than Coke\ndrinkers prefer movies from Columbia Studios when that was owned by Coca-Cola. Nebraska Furniture Mart, the store Warren\nBuffett bought for Berkshire Hathaway one afternoon, is a dominant player in Omaha and its hinterland, more powerful there\nthan Ethan Allen or other large national furniture retailers.\n\nAs we examine the workings of the different sources of competitive advantages through detailed examples, the benefits of op-\nerating in markets with limited boundaries will become apparent, as will the difficulties of establishing or sustaining dominance\nwhere the boundaries are vast. Most companies that manage to grow and still achieve a high level of profitability do it in one of\nthree ways. They replicate their local advantages in multiple markets, like Coca-Cola. They continue to focus within their product\nspace as that space itself becomes larger, like Intel. Or, like Wal-Mart and Microsoft, they gradually expand their activities outward\n\nfrom the edges of their dominant market positions.\n\nTHE PROCESS OF STRATEGIC ANALYSIS\n\nThe natural starting point for any strategic analysis is a market-by-market assessment of the existence and sources of competitive\nadvantages.\n\nWhen there are no competitive advantages present, then genuine strategic issues are of little concern. Therefore, in markets\nalong the \u201cCompetitive Advantage: No\u201d branch in figure 1.1, operational effectiveness\u2014efficiency, efficiency, efficiency\u2014is both\n\nthe first priority and the last.\n\f"}, "002921.png": {"text": "But for markets along the \u201cCompetitive Advantage: Yes\u201d branch, where companies do benefit from competitive advantages,\nthe next step is to identify the nature of the competitive advantages and then to figure out how to manage them. The alternatives\nare not pleasant. If the advantages dissipate, whether through poor strategy, bad execution, or simply because of the unavoidable\ngrindings of a competitive economy, these firms will find themselves on a level economic playing field\u2014the no-competitive-ad-\n\nvantage branch\u2014where life is all work and where profits, except for the exceptionally managed companies, are average at best.\n\nStrategic Possibilities:\nManaging the Advantage\n(Analysis: What kind of\nCompetitive Advantage: advantage?)\nYES\n\nALL MARKETS\n\nCom petitive Advantage:\nNO\n\nOperational Effectiveness:\nEfficiency, Efficiency. Efficiency\n\nFIGURE 1.1\n\nStrategic analysis, step one\n\f"}, "002922.png": {"text": "THE COMPETITIVE LANDSCAPE\n\nMANAGING COMPETITIVE ADVANTAGES\n\nBy definition, in any market in which companies enjoy a competitive advantage, there will be a short list of legitimate competitors.\nAt the extreme, companies such as Microsoft in the world of PC operating systems or IBM in its golden days will find themselves\nalone or surrounded by dwarfs. From their perspective, their competitors constitute an army of ants who can\u2019t enjoy the picnic\nbecause they are outside the barriers to entry. These firms are free to make their decisions without regard to what the ants might\ndo in response to their initiatives. They need not spend much time anticipating specific competitive interactions.\n\nIn this situation\u2014generally one large firm and many smaller ones\u2014a company is either an ant or an elephant. The ants, outside\nthe walls and looking in, operate at a competitive disadvantage. The strategy for a firm that finds itself in the ant\u2019s position is clear-\ncut. If it is already in the industry, it should consider getting out as painlessly as possible and returning to its owners as much of its\neconomic resources as are salvageable. Admittedly, the list of CEOs who have followed this prescription is short. If it is considering\ngetting into the business, the company ought to stop and look elsewhere because whatever slim chance it has for success depends\nentirely on the elephant competitor messing up.\n\nAnd then, even if the incumbent\u2019s advantage shrinks and the barriers to entry disappear, the new firm will be just one of many\nentrants pursuing profit on an essentially level playing field. It should remind itself of Groucho Marx\u2019s rule not to join any club that\nwould have him as a member. At best, economic life will be average, with normal profits; more likely, the elephant trods on it and\nthe ant gets crushed.\n\nFor an elephant operating within the barriers, life is sweet and returns are high. But competitive advantages still have to be\nmanaged. Complacency can be fatal, as can ignoring or misunderstanding the sources of one\u2019s strength. An elephant\u2019s first priority\nis to sustain what it has, which requires that it recognize the sources and the limits of its competitive advantages.\n\nA thorough understanding makes all the difference:\n\f"}, "002923.png": {"text": "+ It allows the firm to reinforce and protect existing advantages and to make those incremental investments that\ncan extend them.\n\n+ It distinguishes those potential areas of growth\u2014both geographically and in product lines\u2014that are likely to\nyield high returns from tempting areas that would undermine the advantages.\n\n-It highlights policies that extract maximum profitability from the firm\u2019s situation.\n\n+ It spots the threats that are likely to develop and identifies those competitive inroads that require strong counter-\n\nmeasures.\n\nFor functional departments within the firm, understanding the nature of the competitive advantages is essential for capital\nbudgeting, for marketing, for evaluating mergers and acquisitions, and for new ventures.\n\nIn these markets of one dominant firm and an army of ants, strategic analysis for the dominant firm consists almost exclu-\nsively of understanding and managing competitive advantages. It doesn\u2019t need to confront the complexities of explicit mutual in-\n\nteractions among competitors. We illustrate this state in figure 1.2, which extends figure 1.1.\n\nCONFLICTS AS GAMES: INTERACTING WITH COMPETITORS\n\nIn the remaining strategic situations, several companies enjoy roughly equivalent competitive advantages within a single market\nsetting. The soft drink market in the United States is a prime example. Nationally, Coke and Pepsi are two elephants, with the\nother players considerably smaller, although in particular geographic markets, regional favorites like Dr Pepper may be legitimate\ncompetitors. Commercial aircraft manufacturing has a similar structure. Boeing and Airbus control the market for larger jets, with\n\nthe smaller manufacturers like Embraer and Bombardier competing in the regional jet market. In the personal computer business,\n\f"}, "002924.png": {"text": "Intel and Microsoft dominate their specific niches, but they compete indirectly against one another for a share of the overall value\n\ncreated in the industry.\nManage Competitive\ner Advantage\nyou\nOTHERS \u2014 You are an ant;\nYES EXIT GRACEFULLY\n. rat .\nSingle Deminant Firm?\nee\nCompetitive Advantage: oe NO\nYES\n\u2014 Ss Difficult Strategic\nALL MARKETS Decisions\nCompetitive Advantage:\nNO\nOperational Effectiveness:\nEfficiency, Efficiency, Efficiency\nFIGURE 1.2\n\nAsingle dominant firm\n\f"}, "002925.png": {"text": "It is for companies in these markets, those that enjoy the benefits of competitive advantages but with potent competitors of\nsimilar capabilities, that strategy formulation is most intense and demanding. They face the big challenge of figuring out how to\nmanage their competitors.\n\nTo develop an effective strategy, a company not only needs to know what its competitors are doing, but to also be able to antici-\npate these competitors\u2019 reactions to any move the company makes. This is the true essence of strategic planning. It embraces all of\nthe things a company does in which a competitor\u2019s direct reactions are critical to its performance\u2014pricing policies, new product\nlines, geographical expansions, capacity additions.\n\nThere are several distinct approaches that are particularly valuable in developing competitive strategies: game theory, simula-\ntion, and cooperative analysis.\n\nClassical game theory is primarily useful because it imposes a systematic approach to collecting and organizing the mass of\ninformation about how competitors may behave. Game theory, as the Stanford Encyclopedia of Philosophy describes it, is \u201cthe study\nof the ways in which strategic interactions among rational players produce outcomes with respect to the preferences (or utilities) of\nthose players, none of which might have been intended by any of them.\u201d\n\nThe salient features of a competitive situation are:\n\n+ The players\u2014a restricted number of identifiable actors, generally competitors; if the list is not short and manage-\nable, there are probably no genuine barriers to entry\n\n+ The actions each player can pursue\u2014the choices that are available to them.\n\n+ The motives that drive them\u2014profitability is the most common in business, but other goals, like winning against\ncompetitors regardless of the costs to oneself, may take hold and therefore need to be considered\n\n+ The rules that govern the game\u2014who goes when, who knows what and when, and what penalties there are for\n\nbreaking the rules\n\f"}, "002926.png": {"text": "Fortunately, the fundamental dynamics of the great majority of competitive situations can be captured by two relatively simple\ngames.\n\nThe prisoner\u2019s dilemma (PD) game has been thoroughly studied theoretically, historically, and experimentally. It describes\ncompetition that concerns price and quality. A great deal is known about how a PD game is likely to play out, and this knowledge\ncan be brought to bear on any situation in which price/quality competition is a key to competitive interactions. We describe the PD\ngame in chapter 7 and use it to analyze competitive interactions in chapters 9 and 10.\n\nAnother game focuses on entry/preemption behavior, by capturing the dynamics of quantity and capacity competition (unfor-\ntunately this game lacks a catchy name). Whenever a company decides to build a new plant or open a new store in a market served\nby a competitor, entry/preemption is the game being played. There is also a wealth of established knowledge about how this game\nworks out. We will discuss entry/preemption in chapter 11 and illustrate its principles at play in chapters 12 and 13.\n\nGiven these available insights, a valuable approach to strategic analysis is to start by putting this received wisdom to use. First\nyou must identify the competitive situations to which one or another of these two games can appropriately be applied. For exam-\nple, if an industry\u2019s history has been dominated by a long-lived and debilitating price war, then the natural place to look for a solu-\ntion is the accumulated knowledge about how to play the prisoner\u2019s dilemma game. If the industry is one in which any expansion\nby one firm has habitually induced its rivals to counter with their own expansions, then the entry/preemption game provides the\ntemplate for strategic analysis.\n\nIn simple, straightforward interactions, it may be possible to anticipate how the game will evolve merely by listing the various\ncourses of action and comparing the results. In practice, however, alternative possibilities multiply rapidly, and the analysis be-\ncomes intractable. In many cases, a better way to proceed is by simulation. One can assign individuals or teams to represent each\ncompetitor, provide them with appropriate choices for actions and with motives, and then play the game several times. The simu-\n\nlation should provide a rough sense of the dynamics of the situation, even though the outcomes are only rarely definitive.\n\f"}, "002927.png": {"text": "A Cooperative Alternative\n\nIn addition to classic games and simulations, another approach to analyzing competition among the elephants is to assume that\ninstead of battling, companies can learn how to cooperate for mutual gain and to fairly share the benefits of their jointly held com-\npetitive advantage. This type of interaction among competitors\u2014which could also be called \u201cbargaining\u201d\u2014makes all the players\nbetter off, but it requires an outlook and a disposition rarely found in this environment.\n\nPlayers, nonetheless, need to think about what this ideal state of affairs would look like, even if it is not immediately practical.\nThey need to identify joint gains and envision the best configuration of market activity. This would be the one in which costs are\nminimized, products and services most efficiently produced and delivered, and prices set to maximize income. In this ideal con-\nfiguration, everyone in the market, including their competitors, must benefit. In other words, if this market were organized as a\ncartel or a monopoly, what would it look like? The players also have to decide upon a fair division of the spoils, because cooperative\narrangements do not last if any participant believes it is being unfairly treated.\n\nThis analysis of the theoretically ideal market configuration has two distinct benefits. First, it identifies the possibilities that a\ncooperative posture might produce. Second, it helps a firm on the margin of a protected market, or a potential entrant, to set rea-\nsonable strategic goals.\n\nFor example, the relatively high-cost supplier with no captive customers should see that it cannot expect to gain any advantage\nthrough strategic alliances, competitive threats, or other means. That\u2019s because, if the market is configured efficiently, such a\nsupplier has really no role to play. Why should other, more powerful competitors support it at the price of a reduction in overall\nindustry performance, especially when it is they who will inevitably pay the costs? In other words, if you don\u2019t bring anything to\nthe dance, don\u2019t expect to take anything home.\n\nWhen these conditions apply, the high-cost firm\u2019s continued existence will usually hinge on irrational and noncooperative be-\nhavior from the other companies. Identifying and exploiting that behavior\u2014making sure they don\u2019t get together\u2014thus becomes\n\nthe core of its strategy.\n\f"}, "002928.png": {"text": "In practice, a high level of cooperation among firms in any market is rare. Still, contemplating cooperative possibilities reveals\naspects of the strategic situation that can guide company decision making even in the absence of full-fledged cooperation. It adds\na bargaining perspective as a complement to the more traditional noncooperative assumptions embodied in classical game theory\nand other treatments of competitive interaction.\n\nTaken together, these three approaches\u2014application of knowledge about specific games (prisoner\u2019s dilemma, entry/preemp-\ntion), simulation, and cooperative analysis\u2014produce a balanced and comprehensive treatment of the problems of formulating\nstrategy in markets with a few genuine competitors, all mutually capable and conscious of one another.\n\nThis last step in the analysis is depicted in figure 1.3, which extends the previous figures to incorporate those situations in\n\nwhich several firms with competitive advantages share a market.\n\nTHE ROAD AHEAD\n\nIn this chapter and the two that follow, we discuss competitive advantage in general (position 1 in figure 1.3). There are only a few\ntypes of competitive advantage (demand, supply, and economies of scale) and two straightforward tests (market-share stability\nand high return on capital) to confirm their existence. Next, we will cover those situations in which a single firm dominates a\nmarket, using historical examples to illustrate how the different companies have identified and managed their competitive advan-\ntages, some successfully, others less so (position 2). We will then discuss competitive interactions among firms that share a single\nmarket (position 3). For these companies, strategy can lead to continual war punctuated by the occasional cease-fire, or to long-\n\nterm cooperation for mutual benefit.\n\f"}, "002929.png": {"text": "Manage Competitive\n\nAdvantage\n2\n\n \n\nyou\nOTHERS \u2014 You are an ant;\nEXIT GRACEFULLY\nSingle vitae Firm?\nsas Pe\nee aes \u2122 NO : Game Structure!\nSimulation\nwore 2 2 ap risoner\u2019s Dilemma\nALL MARKETS Analysis and Applications Entry/Preemption\n1 4 Cooperation!\nBargaining\nCompetitive Advantage:\nNO\n\nOperational Effectiveness:\n\nEfficiency, Efficiency, Efficiency e\n\nFIGURE 1.3\nArchitecture of the book\n\f"}, "002930.png": {"text": "In the later chapters of the book we apply the competitive advantage concepts to functional areas like valuation, mergers and\nacquisitions, and brand extensions (position 4). Finally, we will turn to those markets in which there are no barriers to entry or\ncompetitive advantages (position 5), to explain why some firms do much better than others even though there is no fundamental\neconomic distinction between them. Good management matters enormously. The key to operational effectiveness is relentless\nfocus, which requires that the enveloping fog of visionary strategic possibilities first be dissipated. This book is designed to do just\nthat.\n\nLike most other recent authors on strategy, we owe a debt to Michael Porter. As we mentioned earlier, Porter highlighted the im-\nportance of interactions among economic actors and identified the five forces that he feels explain the competitive world in which\na company operates. He thus gave us an invaluable approach, but the complexity of his model makes it difficult to apply. It sacri-\nfices clarity for completeness. Attending to five forces at one time is not easy, especially if none of them has any claim to priority.\n\nWe have simplified Porter\u2019s approach by concentrating first on the one force that dominates all the others: barriers to entry.\nThen we turn to the other forces, starting with industry competitors and direct competitive interactions where these apply and\nnext including suppliers and customers in a bargaining context. Our purpose here is not to ignore Porter\u2019s forces but to prioritize\nand clarify them. Simplicity and clarity are important virtues of strategic analysis, provided we keep in mind Einstein\u2019s admoni-\n\ntion that \u201cEverything should be made as simple as possible, but not simpler.\u201d\n\f"}, "002931.png": {"text": "CHAPTER 2\n\nCompetitive Advantages I\n\nSupply and Demand\n\nTHE DIFFERENTIATION MYTH\n\nAccording to an axiom of managerial wisdom, commodity businesses are to be avoided. Any operation in which sellers offer essen-\ntially identical products to price-sensitive customers faces an intense struggle for economic survival and must accept a lower than\naverage level of profitability.\n\nStrategic thinking often seems to start with this admonition: Do not allow yourself to be trapped in a commodity business.\nFledgling business majors are taught that the essential first step in formulating any legitimate business plan is to differentiate\nyour product from that of the competition. But on its own, differentiation as a strategy to escape the woes of commodity busi-\n\nnesses has one major flaw\u2014it doesn\u2019t work.\n\f"}, "002932.png": {"text": "Differentiation may keep your product from being a generic commodity item, but it does not eliminate the intense competition\nand low profitability that characterize a commodity business. Although nature of the competition may change, the damage to\nprofit persists because the problem is not lack of differentiation, but the absence of barriers to entry. Understanding the signifi-\ncance of barriers to entry and how they operate is the key to developing effective strategy.\n\nThere is probably no product in the world more successfully differentiated from its global competitors than a Mercedes-Benz\nautomobile. Many newly installed heads of state seek to buttress their positions by acquiring at least one; the more grandiose opt\nfor a fleet. Branding is a primary tactic for product differentiation, and the Mercedes-Benz star may be the most widely recognized\nsymbol for quality in the global marketplace. Cadillac once had an equivalent position in the United States, and its name entered\nthe vernacular as a mark of quality\u2014\u201cthe Cadillac of burgers\u201d (Nat Cole\u2019s commentary on a P. J. Clarke hamburger in the 1950s),\n\u201cthe Cadillac of bassinets\u201d (www.epinions.com), \u201cthe Cadillac of PCs\u201d (BusinessWeek, May 19, 1999). And yet, despite the recogni-\ntion and the associations with quality, Mercedes-Benz and Cadillac have not been able to translate the power of their brands into\nexceptionally profitable businesses. In fact, their economic performance is not distinguishable from those mundane commodity\nbusinesses everyone tries so assiduously to avoid.\n\nThe process by which high returns are eroded is straightforward. In the case of automobiles, it began in the years after World\nWar II, when Cadillac (with Lincoln in the United States) and Mercedes-Benz dominated their local markets and made exceptional\nprofits. Those profits attracted other companies to enter these markets, seeking a share of the high returns. In the American lux-\nury car market, the first entrants of scale were the Europeans\u2014Mercedes, Jaguar, BMW in the 1970s\u2014soon followed by the Japa-\nnese\u2014Acura, Lexus, Infiniti in the 1980s.\n\nIf luxury cars had been a commodity business, the entry of new competitors would have undermined prices. But that is not\nwhat happened. Cadillacs and Lincolns continued to sell for premium prices, even after the entry of the imports. This was because\nthe imports did not, as a rule, undercut them on price. But with a wider variety of luxury cars available, the sales and market\nshares of Cadillac and Lincoln began to decline. Meanwhile, the fixed costs of their differentiation strategy\u2014product development,\n\nadvertising, maintaining dealer and service networks\u2014did not contract. As a result, the fixed cost for each auto went up, and the\n\f"}, "002933.png": {"text": "overall profit margin per car dropped. Cadillac and Lincoln found themselves selling fewer cars with lower profit margins. Their\nprofitability shrank even though their products were thoroughly differentiated.\n\nThis process\u2014in which prices remain stable, while sales fall and fixed costs per unit sold rise\u2014differs from that which operates\nin a price-driven (commodity) market, but the ultimate effect on profitability is the same. In the luxury car business, the decline\ndid not happen all at once. When the first European brands entered the market, Cadillac and Lincoln lost some of their sales and\nsaw their margins erode. But after this first wave, returns were still high enough to attract additional entrants. Inevitably, more\ncompetitors showed up, this time as carriage trade versions of Hondas, Toyotas, and Nissans.\n\nThe flood of entrants would only cease when lucrative profit opportunities in the luxury car market vanished. These opportu-\nnities would disappear only after entrants had fragmented the market to such an extent that high fixed costs per unit eliminated\nany extraordinary profit. When financial returns in this market became ordinary, the attraction ceased and entry stopped.\n\nGiven a process like this, it should be no surprise that even a brand as renowned as Mercedes-Benz has produced no better than\naverage financial returns. By itself, product differentiation does not eliminate the corrosive impact of competition. Well-regarded\nbrands are no better protected than commodities. High returns attract new entrants, or expansion by existing competitors, or\n\nboth, in all markets. The inexorable nature of this process leads to our most important statement of strategic principle:\n\nIfno forces interfere with the process of entry by competitors, profitability will be driven to levels at which efficient\nfirms earn no more than a \u201cnormal\u201d return on their invested capital. It is barriers to entry, not differentiation by itself,\n\nthat creates strategic opportunities.\n\nEFFICIENCY MATTERS\n\f"}, "002934.png": {"text": "This proposition has several significant implications. The first is the connection between efficiency and survival in all markets\nwhere there are no barriers to entry.\n\nIn copper, steel, or bulk textiles, it is clear that if a company cannot produce at a cost at or below the price established in the\nmarket, it will fail and ultimately disappear. Since the market price of a commodity is determined in the long run by the cost levels\nof the most efficient producers, competitors who cannot match this level of efficiency will not survive. But essentially the same\nconditions also apply in markets with differentiated products.\n\nProduct differentiation is like lunch; it doesn\u2019t come for free. Companies must invest in advertising, product development, sales\nand service departments, purchasing specialists, distribution channels, and a host of other functions to distinguish their offerings\nfrom those of their competitors. If they cannot operate all these functions efficiently, then they will lose out to better-run rivals.\nThe prices their products command and/or their market share will trail those of their competitors. As a consequence, the return\nthey earn on the investments made to differentiate their products will fall below that of their more efficient competitors.\n\nWhen the successful companies expand, which they inevitably do, market shares of less efficient firms decline further. Even if\nthey can continue to charge a premium price, the returns they earn on their investments in differentiation will fall.\n\nUltimately, when the returns no longer justify the investment, the less efficient companies will struggle merely to stay afloat.\nThis has been the history of many industries with differentiated products\u2014cars, appliances, retailing, beer, airlines, office equip-\nment, and many others. Only a few successful competitors survive, and many once-dominant firms\u2014General Motors, Zenith, A&P,\nCoors, Kmart, PanAm\u2014decline, sometimes terminally.\n\nThe need for efficiency when products are differentiated is no less crucial than when they are commodities, and it is more\ndifficult to achieve. In a commodity business, efficient operations are largely a matter of controlling production costs. Marketing\nrequirements are usually minimal. With differentiated products, efficiency is a matter both of production cost control and effec-\ntiveness in all the functions that underlie successful marketing.\n\nCompetition extends to dimensions beyond simple cost control. A company in a differentiated business has to manage product\n\nand packaging development, market research, a product portfolio, advertising and promotion, distribution channels, anda skilled\n\f"}, "002935.png": {"text": "sales force, and do it all without wasting money. Unless something interferes with the processes of competitive entry and expan-\nsion, efficient operations in all aspects of the business are key to successful performance.\n\nThe second implication of our basic proposition involves understanding the nature of a \u201cnormal\u201d return. Investors in a business\nneed to be compensated for the use of their capital. To be \u201cnormal,\u201d the return to capital should be equivalent to what the investor\ncan earn elsewhere, suitably adjusted for risk. If investors can earn a 12 percent return by buying stocks in companies with average\nrisk, then the companies have to earn 12 percent on their own average risk investments. Otherwise, investors will ultimately with-\ndraw their capital. In practice, a management that produces a lower rate of return can hang on for many years before the process\n\nruns its course, but in the long run\u2014and \u201cnormal\u201d implies the average return over a period of years\u2014the company will succumb.\n\nBARRIERS TO ENTRY AND COMPETITIVE ADVANTAGES\n\nBarriers to entry lie at the heart of strategy. The first task in our simplified approach to strategic thinking is to understand what\nbarriers are and how they arise. It is essential to distinguish between the particular skills and competences that a firm may possess\nand genuine barriers to entry, which are characteristics of the structural economics of a particular market.\n\nThe skills and competencies of even the best-run companies are available to competitors, at least in theory. Systems can be\nreplicated, talent hired away, managerial quality upgraded. All these are ultimately parts of the operational effectiveness of the\ncompany.\n\nStrategy, on the other hand, is concerned with structural barriers to entry. Identifying those barriers and understanding how\nthey operate, how they can be created, and how they must be defended is at the core of strategic formulation. If barriers to entry\nexist, then firms within the barriers must be able to do things that potential entrants cannot, no matter how much money they\nspend or how effectively they emulate the practices of the most successful companies. In other words, firms within the barriers\n\nmust enjoy competitive advantages over potential entrants.\n\f"}, "002936.png": {"text": " \n\nENTRY, EXIT, AND LONG-RUN PROFITABILITY\n\nThere is a reverse side to the entry and expansion process in industries with out barriers to entry: exit and contrac-\ntion. Just as extraordinary profits attract new competitors or motivate existing ones to expand, below-average profits\nwill keep them away. If the process is sustained long enough, the less efficient firms within the industry will wither\nand disappear. But these two processes are not symmetrical. As any family with children knows, it is far easier to buy\nkittens and puppies than to drown them later. In business, the kittens and puppies are new plants, new products, new\n\ncapacity of all sorts, and they are much more fun to acquire than to close down.\n\nBecause of this asymmetry, it takes longer for an industry with excess capacity and below-average returns to\neliminate unnecessary assets than it does for an industry with above average returns to add new capacity. Periods of\noversupply last longer than periods in which demand exceeds capacity. Though in the long run companies do need to\nprovide investors with returns commensurate with the level of risk\u2014to earn their cost of capital\u2014the long run can\nextend beyond what anyone other than management would regard as reasonable. The problem is compounded by the\nlongevity of new plants and products. For mature, capital-intensive businesses, these time spans are apt to be longer\n\nthan for younger industries that require less in the way of plant and equipment.\n\nCommodity businesses are generally in the mature camp, and part of their poor performance stems from their\ndurability, even after they are no longer earning their keep. But the powerful driving force is the dynamics of entry\nand exit, not the distinction between commodities and differentiated products. Competitors with patient capital and\n\nan emotional commitment to the business can impair the profitability of efficient competitors for years, as the his-\n\f"}, "002937.png": {"text": "tory of the airlines industry attests.\n\n \n\nAlthough often treated as separate aspects of strategy, barriers to entry and competitive advantages are essentially alternative\nways of describing the same thing. The only necessary qualification to this statement is that barriers to entry are identical to\nincumbent competitive advantages; whereas entrant competitive advantages\u2014situations in which the latest firm to arrive in the\nmarket enjoys an edge (the benefit of the latest generation of technology, the hottest product design, no costs for maintaining\nlegacy products or retired workers)\u2014are of limited and transitory value.\n\nOnce an entrant actually enters a market, it becomes an incumbent. The same types of advantages it employed to gain entry\nand win business from existing firms\u2014cutting-edge technology, lower labor costs, hotter fashions\u2014now benefit the next new kid\non the block. If the last firm in always has the advantage, there are, by definition, no barriers to entry and no sustainable excess\nreturns.\n\nBecause competitive advantages belong only to the incumbents, their strategic planning must focus on maintaining and ex-\nploiting those advantages. Meanwhile, any firms bold enough to enter markets protected by barriers to entry ought to devise plans\n\nthat make it less painful for incumbents to tolerate them than to eliminate them.\n\nTYPES OF COMPETITIVE ADVANTAGES\n\nThere are really only a few types of genuine competitive advantages. Competitive advantages may be due to superior production\ntechnology and/or privileged access to resources (supply advantages). They may be due to customer preference (demand advan-\ntages), or they may be combinations of economies of scale with some level of customer preference (the interaction of supply-and-\ndemand advantages, which we discuss in chapter 3). Measured by potency and durability, production advantages are the weakest\n\nbarrier to entry; economies of scale, when combined with some customer captivity, are the strongest.\n\f"}, "002938.png": {"text": "In addition, there are also advantages emanating from governmental interventions, such as licenses, tariffs and quotas, au-\nthorized monopolies, patents, direct subsidies, and various kinds of regulation. Television broadcast licenses, for example, convey\npowerful competitive advantages to their holders. Designation as a \u201cNationally Recognized Statistical Rating Organization\u201d by the\nSecurities and Exchange Commission helps Standard & Poor\u2019s, Moody\u2019s, and several smaller agencies maintain their dominance in\nthe market for credit ratings, despite the steep fees they charge. Even in the most liberal economy, the state is an actor from whom\nsome benefit more than others. Government favor aside, the other sources of competitive advantages are rooted in basic economic\n\nconditions.\n\nSUPPLY ADVANTAGES: COMPETITIVE COSTS\n\nOne way a market incumbent obtains a competitive advantage is by having a lower cost structure that cannot be duplicated by\npotential rivals. The incumbent can earn attractive returns under prevailing market conditions\u2014prices and sales levels\u2014but po-\ntential entrants, thanks to their higher cost structures, cannot.\n\nSuch an advantage deters most sensible firms from entering the incumbent's market. If some foolishly optimistic companies\nmake the attempt anyway, the incumbent, taking advantage of its lower cost structure, can underprice, outadvertise, outservice,\nor otherwise outmarket them. Ultimately, the would-be entrants fail and exit the market, leaving a discouraging lesson for any\nwho would follow them.\n\nLower cost structures are due either to lower input costs or, more commonly, proprietary technology. In its most basic form,\nproprietary technology is a product line or a process that is protected by patents. During the term of the patent, protection is\nnearly absolute. Patent infringement penalties and legal fees make the potential costs to a would-be entrant impractically high,\n\nperhaps even infinite.\n\f"}, "002939.png": {"text": "Historically, Xerox in copiers, Kodak and Polaroid in film, and pharmaceutical companies in a range of medicines have enjoyed\nthese kinds of advantages for the lives of their product patents. Process patents may be equally powerful. Alcoa was able to monop-\nolize the aluminum market for many years through patents on processes, and DuPont has a history of economic success based on\nboth process and product patents. But patents expire, generally after seventeen years. Thus, cost advantages based on patents are\nonly sustainable for limited periods. Compared to IBM\u2019s long-term dominance in computers, from the late 1950s to 1990, for ex-\nample, or Coca-Cola\u2019s century-long history in the soda market, patent protection is relatively brief.\n\nOutside of pharmaceuticals, patent-protected positions are relatively rare. Even within pharmaceuticals, \u201cme-too\u201d products\n\u2014how many selective serotonin reuptake inhibitors are there on the market?\u2014tend to undermine technological advantages. But\npatents are not the only source of advantages from proprietary technology.\n\nIn industries with complicated processes, learning and experience are a major source of cost reduction. The percentage of good\nyields in most chemical and semiconductor processes often increases dramatically over time, due to numerous small adjustments\nin procedures and inputs. Higher yields mean lower costs, both directly and by reducing the need for expensive interventions to\nmaintain quality. The same adjustments can trim the amount of labor or other inputs required. Companies that are continually\ndiligent can move down these learning curves ahead of their rivals and maintain a cost advantage for periods longer than most\npatents afford.\n\nBut, as with patents, there are natural limits to the sustainability of these learning-based proprietary cost advantages. Much\ndepends on the pace of technological change. If it is swift enough, it can undermine advantages that are specific to processes that\nquickly become outdated. Cost advantages thus have shorter life expectancies in rapidly changing areas like semiconductors,\nsemiconductor equipment, and biotechnology.\n\nOn the other hand, if technological change slows down as an industry matures, then rivals will eventually acquire the learned\nefficiencies of the leading incumbents. In the 1920s, RCA, manufacturing radios, was the premier high-tech company in the\n\nUnited States. But over time, the competitors caught up, and radios became no more esoteric to make than toasters. In the long run\n\f"}, "002940.png": {"text": "everything is a toaster, and toaster manufacturing is not known for its significant proprietary technology advantages, nor for high\nreturns on investment.\n\nFurther, simple products and simple processes are not fertile ground for proprietary technology advantages. They are hard to\npatent and easy to duplicate and transfer to other firms. If a particular approach to production and/or service can be fully under-\nstood by a few employees, competitors can hire them away and learn the essentials of the processes involved.: If the technologies\nare simple, it is difficult for the developer to make the case for intellectual theft of proprietary property since much of the tech-\nnology will look like \u201ccommon sense.\u201d This limitation is particularly important in the vast and growing area of services\u2014medical\ncare, transaction processing, financial services, education, retailing\u2014that account for roughly 70 percent of global economic\nactivity. The technology in these fields tends to be either rudimentary or else it has been developed by specialist third parties.\nTechnology that is truly proprietary must be produced within the firm. Markets in which consultants or suppliers, such as NCR in\nretailing, are responsible for most product or process innovations cannot be markets with substantial cost advantages based on\ntechnology, because the advantages are available to anyone willing to pay for them.\n\nThis is why the idea that information technologies will be the source of competitive advantages is misguided. Most of the\ninnovations in information technology are created by firms like Accenture, IBM, Microsoft, SAP, Oracle, and a number of smaller\nand more specialized companies that make their living by disseminating innovations as widely as they can. Innovations that are\ncommon to all confer competitive advantages on none. Some firms may make better use of those innovations, but that is a matter\nof organizational effectiveness, not competitive advantage.\n\nIf cost advantages rooted in proprietary technology are relatively rare and short-lived, those based on lower input costs are\nrarer still. Labor, capital in all its various forms, raw materials, and intermediate inputs are all sold in markets that are generally\ncompetitive. Some companies have to deal with powerful unions that are able to raise labor costs. They may also face an overhang\nof underfunded pension and retiree health-care liabilities. But if one company can enter the market with nonunion, low-benefit\n\nlabor, others can follow, and the process of entry will eliminate any excess returns from lower labor costs.\n\f"}, "002941.png": {"text": "Unionized firms may stagnate or die, yet the survivors enjoy no competitive advantages. The first company to find a lower cost\nof labor in a country such as China may gain a temporary benefit over rivals who are slower to move, but the benefit soon disap-\npears as others follow.\n\nAccess to cheap capital or deep pockets is another largely illusory advantage. One lesson the Internet boom taught is how easy\nit can be to raise money. Companies with barely plausible business plans had virtually unlimited access to capital at rates that\nproved ridiculously cheap, given the risks of new and untested businesses. But that easy funding did not assure them success.\n\nHistory is full of companies driven out of business by more efficient competitors\u2014steel producers, appliance manufacturers,\nsmall-scale retailers, and nationwide chain stores. But only a small number of companies have been forced to the wall by competi-\ntors whose sole advantage was their deep pockets. In many cases, the putatively deep-pocketed firms\u2014such as IBM, AT&T, Kodak,\nJapan Inc.\u2014have chiefly hurt themselves by spending lavishly on mistaken ventures in part because they simply had the money.\n\nAn argument sometimes made, especially during the high tide of Japanese incursions into the U.S. and European manufac-\nturing sectors, is that some companies or sectors enjoy preferred access to capital, making capital \u201ccheap\u201d for them. This access is\noften underwritten by government, as in the case of Airbus. Sometimes the \u201ccheap\u201d capital is based on access to funds that were\nraised in the past at unusually low costs. But the real cost of funds in these cases is not \u201ccheap.\u201d\n\nIf capital markets at large offer 10 percent returns on investments, then investing capital in projects that return 2 percent is\na money loser\u2014an 8-percentage-point loser\u2014even though the funds may have cost only 2 percent to raise. Taking advantage of\n\u201ccheap\u201d capital in this way is a stupidity, not a competitive advantage. Like all stupidities not underwritten by a government, it is\nunlikely to be sustainable for very long.\n\nIn the absence of government support, the notion of \u201ccheap\u201d capital is an economic fallacy. \u201cCheap\u201d capital that is due to gov-\nernment support is best thought of as just another competitive advantage based on a government subsidy.\n\nSome companies do have privileged access to raw materials (e.g., Aramco) or to advantageous geographical locations (e.g.,\nUnited Airlines at Chicago\u2019s O\u2019Hare International Airport). These advantages, though, tend to be limited both in the markets to\n\nwhich they apply and in the extent to which they can prevent competitive entry. Aramco can make more profit on a barrel of oil\n\f"}, "002942.png": {"text": "than Norway\u2019s Statoil, but so long as demand for oil is high enough, it can\u2019t keep Statoil out of the market. And United cannot ex-\ntend its strong position at O\u2019Hare to other airports.\n\nThe same is true for exceptional talent. The studio that has signed up a Julia Roberts or a Tom Cruise enjoys a competitive\nadvantage over other studios when it comes to opening a new movie, although even stars of this magnitude are no guarantee of\nsuccess. However, like other advantages based on special resources, this one is limited in several ways. First, star power is ulti-\nmately owned not by the studio but by the stars themselves. They can sign with whomever they like for the next film. Second,\nstars lose their appeal or their contracts expire. And there are no barriers to entry in creating the next Julia Roberts or Tom Cruise,\nas the armies of aspiring actors and agents attest. Third, the value of any star is limited to a particular audience and does not trans-\nlate into broad market dominance.\n\nThese basic limitations apply equally to other special resources like rich mineral deposits or advantageous leases on desirable\nlocations. With few exceptions, access to low-cost inputs is only a source of significant competitive advantage when the market is\n\nlocal, either geographically or in product space. Otherwise, it is not much help as a barrier to entry.\n\nDEMAND ADVANTAGES: CUSTOMER CAPTIVITY\n\nFor an incumbent to enjoy competitive advantages on the demand side of the market, it must have access to customers that rivals\ncannot match. Branding, in the traditional sense of a quality image and reputation, by itself is not sufficient to establish this su-\nperior access. If an entrant has an equal opportunity to create and maintain a brand, the incumbent has no competitive advantage\nand no barrier impedes the process of entry.\n\nCompetitive demand advantages require that customers be captive in some degree to incumbent firms. This captivity is what\ngives the incumbent its preferred access. In a cigarette ad of some years ago\u2014when there still were cigarette ads\u2014smokers pro-\n\nclaimed that they \u201cwould rather fight than switch.\u201d Every company would love to have customers with this kind of loyalty.\n\f"}, "002943.png": {"text": "It may not be impossible for entrants to lure loyal customers away from an incumbent. They can cut prices to the bone, or even\ngive the product away to induce people to try it. They can tie it in to other products and otherwise make it desirable. But customer\ncaptivity still entails a competitive advantage because entrants cannot attract customers under anywhere near the same terms as\nthe established firms.\n\nUnless they have found a way to produce the item or deliver the service at a cost substantially below that of the incumbent,\nwhich is not likely, either the price at which they sell their offerings or the volume of sales they achieve will not be profitable for\nthem, and therefore not sustainable. The incumbent has a competitive advantage because it can do what the challenger cannot\u2014\nsell its product at a profit to its captive customers.\n\nThere are only a limited number of reasons why customers become captive to one supplier.\n\nHABIT\n\nCigarette smoking is an addiction; buying a particular brand is a habit. Habit leads to customer captivity when frequent purchases\nof the same brand establish an allegiance that is as difficult to understand as it is to undermine. Cigarette smokers have their\nbrands, though in a pinch they will light up a substitute; such is the pull of the addiction.\n\nSoda drinkers are also loyal. To someone who generally asks for coffee, tea, or water, Coca-Cola and Pepsi taste pretty much\nalike. Yet each cola has its devotees, and they are generally firm in their commitments. Coca-Cola decided to reformulate and\nsweeten the drink in the 1980s, to stem the loss of young and therefore uncommitted cola lovers to Pepsi. It made the change\nonly after extensive taste tests among its own drinkers convinced them that the New Coke taste had more support. But when the\ncompany actually introduced New Coke and took the traditional drink off the shelves, Coca-Cola loyalists were furious. After some\nmonths of indecision, the company reversed course and reestablished Classic Coke, as it was briefly called, as the flagship brand.\n\nCoca-Cola was lucky to escape the problem it had created. As a rule, it isn\u2019t wise to antagonize captive customers.\n\f"}, "002944.png": {"text": "For reasons that are not entirely evident, the same kind of attachment does not extend to beer drinkers. People who normally\nbuy Coors or Budweiser for their homes, and order it when they eat in local restaurants, are only too eager to have a Corona or a Dos\nEquis in a Mexican restaurant, or a Tsingtao in a Chinese one, which may explain why Anheuser-Busch bought a stake in Tsingtao.\nYet the cola drinker seldom thinks of asking for Great Wall Cola or some such brand.\n\nHabit succeeds in holding customers captive when purchases are frequent and virtually automatic. We find this behavior in\nsupermarkets rather than automobile dealers or computer suppliers. Most consumers enjoy shopping for a new car, and the fact\nthat they owned a Chevrolet last time, or a BMW, doesn\u2019t mean they won't test-drive a Ford or a Lexus.\n\nBoth personal computer buyers and IT managers shop for replacement hardware on the basis of price, features, and depend-\nability, not whether their current machines are IBMs, Dells, or HPs. They do need to think about compatibility with their existing\nsoftware, but that is a legacy situation and a switching-cost issue and does not mean that they are creatures or captives of habit.\n\nHabit is usually local in the sense that it relates to a single product, not to a company\u2019s portfolio of offerings. The habitual user\n\nof Crest toothpaste is not necessarily committed to Tide or any of the other Procter & Gamble brands.\n\nSWITCHING COSTS\n\nCustomers are captive to their current providers when it takes substantial time, money, and effort to replace one supplier with\nanew one. In the computer era, software is the product most easily associated with high switching costs. The costs can become\nprohibitive when they involve not simply the substitution of some computer code, proprietary or commercial, but the retraining\nof the people in the firm who are the application users.\n\nIn addition to all the extra money and time required, any new system is likely to bump up the error rate. When the applications\ninvolved are critical to the company\u2019s operations\u2014order entry, inventory, invoicing and shipping, patient records, or bank transac-\ntions\u2014few want to abandon a functioning system, even for one that promises vast increases in productivity, if it holds the threat\n\nof terminating the business through systemic failure, the ultimate \u201ckiller app.\u201d\n\f"}, "002945.png": {"text": "These costs are reinforced by network effects. If your computer system must work compatibly with others, then it is difficult\n\nto change to an alternative when others do not, even if the alternative is in some ways superior. The move will be costly, to ensure\n\n \n\ncontinued compatibility, and perhaps disastrous if the new system cannot be meshed with the existing one.\n\nSoftware is not the only product or service that imposes substantial switching costs on customers and thus gives the incum-\nbent a leg up on potential competitors. Whenever a supplier has to learn a great deal about the lives, needs, preferences, and other\ndetails of a new customer, there is a switching cost involved for the customer, who has to provide all this information, as well as\na burden on the supplier to master it. This is one reason that clients don\u2019t switch lawyers lightly. Likewise, doctors who become\ncomfortable prescribing a particular medicine may be reluctant to substitute a new drug with which they are less familiar, despite\nall the brochures and entreaties from the drug detail person.\n\nStandardized products, especially if the standards are not proprietary, are one antidote to high switching costs, which is why\ncustomers like them. In its glory days, the IBM mainframe was built out of IBM components, ran an IBM operating system, used\nIBM-produced applications programs, and was even leased from IBM. Moving from one IBM computer to another was difficult, but\nswitching to a new system entirely was perilous and daunting. Switching became easier as other companies offered compatible\nperipherals, applications programs, and financing. And the whole edifice began to collapse when new firms found ways to link\ndesktop machines, built to open standards\u2014thanks to IBM\u2019s design decision for its PC\u2014into useable systems.\n\nChanging credit cards used to require careful timing. Old card balances had to be paid off before the new credit facility became\navailable. Then the card issuers began to offer preapproval and to encourage balance transfers. Costs of switching were reduced or\n\neliminated, and competition in the industry intensified.\n\nSEARCH COSTS\n\nCustomers are also tied to their existing suppliers when it is costly to locate an acceptable replacement. If the need is a new refrig-\n\nerator, the search costs are minimal; information and ratings on competitive products are easily available. But for many people,\n\f"}, "002946.png": {"text": "finding a new doctor involves more than looking in the yellow pages or even in a health-care network directory. There is no ready\nsource of the kind of information a prospective patient wants, and given the personal nature of the relationship, no alternative to\ndirect experience.\n\nHigh search costs are an issue when products or services are complicated, customized, and crucial. Automobile insurance is ba-\nsically a standardized product, so much coverage at so much cost, with concern for the reliability of the underwriter alleviated by\nstate regulation. Home ownership insurance, by contrast, is more detailed, and can involve the kind of coverage, the deductibles,\nspecial schedules of items included or excluded, the creditworthiness of the insurance company, its history of payment for claims,\nand other issues.\n\nAll these details foster an aversion to change. Only homeowners made seriously unhappy by their insurer\u2019s premium or level of\nservice are going to take the trouble to search for a replacement, especially since the penalty for picking an inadequate insurer may\nbe substantial. In this case, the real relationship may be with a trusted broker, not the actual underwriter, so the broker may enjoy\nthe benefits of customer captivity because of the high switching costs.\n\nFor businesses, the more specialized and customized the product or service, the higher the search cost for a replacement.\nProfessional services, which also may involve an intense level of personal contact, fit into this category, as do complicated manu-\nfacturing and warehousing systems. It is easier to upgrade with a current vendor or continue with a law firm even when not to-\ntally satisfied, because finding a better one is costly and risky. To avoid the danger of being locked in to a single source, many firms\ndevelop relationships with multiple suppliers, including professional service providers.\n\nTaken together, habits, switching costs, and search costs create competitive advantages on the demand side that are more\ncommon and generally more robust than advantages stemming from the supply or cost side. But even these advantages fade over\ntime. New customers, by definition, are unattached and available to anyone. Existing captive customers ultimately leave the scene;\nthey move, they mature, they die. In the market for teenage consumables, existing customers inevitably become young adults,\nand a new, formerly preteen, generation enters the market largely uncommitted. The process is repeated throughout the life cycle,\n\nputting a natural limit on the duration of customer captivity. Even Coca-Cola, as we shall see, was vulnerable to Pepsi when the\n\f"}, "002947.png": {"text": "latter discovered \u201cthe Pepsi Generation.\u201d Only a very few venerable products like Heinz ketchup seem to derive any long-term ben-\n\nefit from some intergenerational transfer of habit.\n\f"}, "002948.png": {"text": "CHAPTER 3\n\nCompetitive Advantages II\n\nEconomies of Scale and Strategy\n\nECONOMIES OF SCALE AND CUSTOMER CAPTIVITY\n\nThe competitive advantages we have described so far are uncomplicated. An incumbent firm may defeat entrants either because\nit has sustainably lower costs or, thanks to customer captivity, it enjoys higher demand than the entrants. Together, these two\nappear to cover fully the revenue and cost elements that determine profitability. But there is an additional potential source of com-\npetitive advantage. In fact, the truly durable competitive advantages arise from the interaction of supply-and-demand advantages,\nfrom the linkage of economies of scale with customer captivity. Once the firm understands how these operate together\u2014some-\ntimes in ways that are surprisingly contrary to commonly held beliefs about the attractiveness of growing markets\u2014it can design\n\neffective strategies to reinforce them.\n\f"}, "002949.png": {"text": "The competitive advantage of economies of scale depend not on the absolute size of the dominant firm but on the size differ-\nence between it and its rivals, that is, on market share. If average costs per unit decline as a firm produces more, then smaller\ncompetitors will not be able to match the costs of the large firm even though they have equal access to technology and resources\nso long as they cannot reach the same scale of operation. The larger firm can be highly profitable at a price level that leaves its\nsmaller competitors, with their higher average costs, losing money. The cost structure that underlies these economies of scale\nusually combines a significant level of fixed cost and a constant level of incremental variable costs. An apparel company, for exam-\nple, needs the same amount of fabric and labor to make each unit and very little in the way of complicated machinery, so its level\nof variable to fixed costs is high. A software publisher, by contrast, has almost all fixed costs, which are the expenses of writing\nand checking the software code. Once the program has been finished, the costs of producing an additional unit are miniscule. So\nits total expenses increase very slowly, no matter the number of customers. As the scale of the enterprise grows, the fixed cost is\nspread over more units, the variable cost per unit stays the same, and the average cost per unit declines.\n\nBut something in addition to this cost structure is necessary for economies of scale to serve as a competitive advantage. If an\nentrant has equal access to customers as the incumbents have, it will be able to reach the incumbents\u2019 scale. A market in which all\nfirms have equal access to customers and common cost structures, and in which entrants and incumbents offer similar products\non similar terms, should divide more or less evenly among competitors. This holds true for differentiated markets, like kitchen\nappliances, as well as commodity markets. All competitors who operate effectively should achieve comparable scale and therefore\ncomparable average cost.\n\nFor economies of scale to serve as a competitive advantage, then, they need to be coupled with some degree of incumbent\ncustomer captivity. If an efficient incumbent matches his competitors on price and other marketing features, then, thanks to the\ncustomer captivity, it will retain its dominant share of the market. Though entrants may be efficient, they will not match the in-\ncumbent\u2019s scale of operations, and their average costs will be permanently higher.\n\nThe incumbent, therefore, can lower prices to a level where it alone is profitable and increase its share of the market, or elim-\n\ninate all profit from competitors who match its prices. With some degree of customer captivity, the entrants never catch up and\n\f"}, "002950.png": {"text": "stay permanently on the wrong side of the economies of scale differential. So the combination of even modest customer captivity\nwith economies of scale becomes a powerful competitive advantage.\n\nThe dynamics of situations like this are worth a closer look. It seems reasonable to think that a persistent entrant will sooner or\nlater reach an incumbent's scale of operation if it has access to the same basic technologies and resources. If the incumbent is not\nvigilant in defending its market position, the entrant may indeed catch up. The Japanese entry into the U.S. car market, the success\nof Fuji Film in taking on Kodak, and the initial significant market share captured by Bic disposable razors from Gillette in the 1980s\nare testimony to the vulnerability of poorly safeguarded economies of scale advantages.\n\nStill, if an incumbent diligently defends its market share, the odds are clearly in its favor. This is why it is important that\nincumbents clearly understand the nature of their competitive advantages and make sure that their strategies adequately defend\nthem. Think of Microsoft in the operating systems market, Boeing versus McDonnell-Douglas in the commercial airframe busi-\nness, or Pitney-Bowes in postage equipment.\n\nAsimple example should help explain why small markets are more hospitable than large ones for attaining competitive advan-\ntages. Consider the case of an isolated town in Nebraska with a population of fifty thousand or less. A town of this size can support\nonly one large discount store. A determined retailer who develops such a store should expect to enjoy an unchallenged monopoly.\nIfa second store were to enter the town, neither would have enough customer traffic to be profitable. Other things being equal, the\nsecond entrant could not expect to drive out the first, so its best choice would be to stay away, leaving the monopoly intact.\n\nAt the other extreme from our Nebraska town is downtown New York City. This large market can support many essentially\nsimilar stores. The ability of even a powerful, well-financed incumbent to prevent entry by a newcomer will be limited. It cannot,\nin other words, establish effective barriers to entry based on economies of scale relative to its competitors. Markets of intermediate\nsize and density, as we would expect, fall between small and large cities regarding the ability to establish and maintain barriers to\nentry. This general principle applies to product as well as to geographic space; the special-purpose computer in a niche market has\n\nan easier time in creating and profiting from economies of scale than the general-purpose PC competing in a much larger market.\n\f"}, "002951.png": {"text": "Long before it became the global powerhouse in retailing, Wal-Mart enjoyed both high levels of profitability and a dominant\nmarket share in the south-central United States due to regional economies of scale in distribution, advertising, and store supervi-\nsion. It defended its territory with an aggressive policy of \u201ceveryday low prices.\u201d Southwest Airlines, with a regional franchise in\nTexas and the surrounding states, was similarly profitable, as have been a lot of other strong local companies in service industries\n\nlike retailing, telecommunications, housing development, banking, and health care.\n\nDEFENDING ECONOMIES OF SCALE\n\nThe best strategy for an incumbent with economies of scale is to match the moves of an aggressive competitor, price cut for\n\nprice cut, new product for new product, niche by niche. Then, customer captivity or even just customer inertia will secure the\nincumbent's greater market share. The entrant\u2019s average costs will be uniformly higher than the incumbent\u2019s at every stage of the\nstruggle. While the incumbent's profits will be impaired, the entrant\u2019s will be even lower, often so much lower as to disappear alto-\ngether. The incumbent\u2019s competitive advantage survives, even under direct assault.\n\nThe combination of economies of scale coupled with better access in the future to existing customers also produces an advan-\ntage in the contest for new customers and for new technologies. Consider the competition between Intel and Advanced Micro De-\nvices (AMD)\u2014or any other potential entrant, like IBM or Motorola\u2014to provide the next-generation microprocessor for Windows-\ncompatible personal computers.\n\nComputer manufacturers are accustomed to dealing with Intel and are comfortable with the level of quality, supply stability,\nand service support they have received from it. AMD may have performed nearly as well in all these areas, but with a much smaller\nmarket share and less interaction, AMD does not have the same intimate association with personal computer manufacturers. If\nAMD and Intel produce next-generation CPUs that are similarly advanced, at equal prices, and at roughly the same time, Intel will\n\ninevitably capture a dominant market share. All Intel need do is match AMD's offering to retain the roughly 90 percent share it cur-\n\f"}, "002952.png": {"text": "rently commands. In planning its next-generation chip, Intel can afford to invest much more than AMD, knowing that its profits\nwill be much greater, even if its CPU is no better.\n\nArough rule of thumb should lead Intel and AMD to invest in proportion to their current market shares. If each company\ninvests 10 percent of current sales in R&D, Intel will outspend AMD $2.6 billion to $300 million. That enormous edge makes Intel\nthe odds-on favorite in the race for next-generation technology. In fact, the situation is even more unequal for AMD. Should it\nmanage to produce a better new chip, computer manufacturers would almost certainly allow Intel a significant grace period to\ncatch up, rather than switch immediately to AMD. The history of competition between the two has seen instances both of Intel\u2019s\nlarger investments usually paying off in superior technology and of its customer captivity allowing it time to catch up when AMD\nhas taken a lead. Thus, economies of scale have enabled Intel to sustain its technological advantage over many generations of\ntechnology.\n\nEconomies of scale in distribution and advertising also perpetuate and amplify customer captivity across generations of\nconsumers. Even if smaller rivals can spend the same proportion of revenue on product development, sales force, and advertising\nas, for example, Kellogg\u2019s, McDonald\u2019s, and Coca-Cola, they can\u2019t come close to matching the giants on actual dollars deployed to at-\ntract new customers. Because of the edge it gives incumbents in both winning new generations of customers and developing new\ngenerations of technology, the combination of economies of scale and customer captivity produces the most sustainable competi-\ntive advantages.\n\nThree features of economies of scale have major implications for the strategic decisions that incumbents must make.\n\nFirst, in order to persist, competitive advantages based on economies of scale must be defended. Any market share lost to rivals\nnarrows the leader\u2019s edge in average cost. By contrast, competitive advantages based on customer captivity or cost advantages are\nnot affected by market share losses. Where economies of scale are important, the leader must always be on guard. If a rival intro-\nduces attractive new product features, the leader must adopt them quickly. If the rival initiates a major advertising campaign or\n\nnew distribution systems, the leader has to neutralize them one way or another.\n\f"}, "002953.png": {"text": "Unexploited niche markets are an open invitation to entrants looking to reach a minimally viable scale of operations. The\nincumbent cannot concede these niches. When the Internet became a major focus of personal computing, Microsoft had to in-\ntroduce its own browser to counter Netscape and offer network alternatives to niche players like AOL. When Pepsi-Cola targeted\nsupermarkets in the 1950s as an alternative distribution channel, Coca-Cola was too slow to respond, and Pepsi picked up market\nshare. The American motorcycle industry did not challenge Japanese companies like Honda when they began to sell inexpensive\ncycles in the 1960s. That was the beginning of the end for almost all the American firms. Harley-Davidson survived, though barely\nand with government help, in part because the Japanese allowed it to control the heavyweight bike niche. Economies of scale need\nto be defended with eternal vigilance.\n\nSecond, the company has to understand that pure size is not the same thing as economies of scale, which arise when the dom-\ninant firm in a market can spread the fixed costs of being in that market across a greater number of units than its rivals. It is the\nshare of the relevant market, rather than size per se, that creates economies of scale.\n\nThe relevant market is the area\u2014geographic or otherwise\u2014in which the fixed costs stay fixed. In the case of a retail company,\ndistribution infrastructure, advertising expenditures, and store supervision expenses are largely fixed for each metropolitan area\nor other regional cluster. If sales are added outside the territory, fixed costs rise and economies of scale diminish. When it was still\nin the cellular business, AT&T\u2019s cellular operations in the Northeast and Atlantic states had larger fixed costs per dollar of revenue\nin that region than Verizon\u2019s, which controlled a far greater share of the territory. The fact that AT&T cellular may have been larger\nnationally than Verizon cellular is irrelevant.\n\nThe same conditions apply when the relevant geography is a product line rather than a physical region. Research and develop-\nment costs, including the start-up costs of new production lines and product management overhead, are fixed costs associated\nwith specific product lines. Though IBM's total sales dwarf those of Intel, its research and development expenses are spread over a\nfar greater range of products. In CPU development and production, which has its own particular technologies, Intel enjoys the ben-\n\nefits of economies of scale.\n\f"}, "002954.png": {"text": "Network economies of scale are similar. Customers gain by being part of densely populated networks, but the benefits and\nthe economies of scale extend only as far as the reach of the networks. Aetna\u2019s HMO has many more subscribers nationally than\nOxford Health Plans. But because medical services are provided locally, what matters is share in a local market. In the New York\nmetropolitan region, Oxford has more patients and more doctors enrolled than Aetna. Its 60 percent share of doctors makes it\nmore appealing to new patients than Aetna\u2019s 20 percent share. The fact that Aetna also has 20 percent in Chicago, Los Angeles,\nDallas, or even Philadelphia is irrelevant. The appropriate measure of economies of scale is comparative fixed costs within the rel-\nevant network.\n\nThere are only a few industries in which economies of scale coincide with global size. The connected markets for operating\nsystems and CPUs is one example; Microsoft and Intel are the beneficiaries of global geographic economies of scale. The commer-\ncial airframe industry, now shared between Boeing and Airbus, is another. However, despite some other interests, each of these\nfour companies concentrates on a single product line and hence on local product space economies of scale. General Electric, the\nmost successful conglomerate, has always focused on its relative share within the particular markets in which it competes, not on\nits overall size.\n\nThird, growth of a market is generally the enemy of competitive advantages based on economies of scale, not the friend. The\nstrength of this advantage is directly related to the importance of fixed costs. As a market grows, fixed costs, by definition, remain\nconstant. Variable costs, on the other hand, increase at least as fast as the market itself. The inevitable result is that fixed costs de-\ncline as a proportion of total cost.\n\nThis reduces the advantages provided by greater incumbent scale. Consider two companies, an incumbent and an entrant,\ncompeting in a market in which fixed costs are $100,000 per year. If the entrant has sales of $500,000 and the incumbent\n$2,500,000, then fixed costs consume 20 percent of the entrant\u2019s revenue versus 4 percent of the incumbent\u2019s, a gap of 16 percent.\nNow the market doubles in size, and each company doubles as well. The gap in fixed cost as a percentage of sales declines to 8 per-\n\ncent. At a level ten times the original, the gap drops to 1.6 percent. See table 3.1.\n\f"}, "002955.png": {"text": "Moreover, growth in the market lowers the hurdle an entrant must clear in order to become viably competitive. Let us assume\nthat the entrant can compete with the incumbent if the economies of scale advantage is no more than 2 percent against it. With\nfixed costs at $100,000 per year, the gap drops to that level if the entrant has sales of $5 million. So if the size of the market were\n$25 million, the entrant would need to capture a 20 percent share; in a market of $100 million, it would only need a 5 percent\nshare, clearly a much lower hurdle. Even if the incumbent were the only other firm in the industry and thus had sales of $95 mil-\nlion, the entrant would still face less than a 2 percent competitive gap.\n\nThere are some highly visible instances of how economies of scale advantages have dwindled as markets have become inter-\nnational and thus massive. The global market for automobiles is so large that many competitors have reached a size, even with a\nsmall percentage of the total, at which they are no longer burdened by an economies of scale disadvantage. For very large potential\nmarkets like Internet services and online sales, the relative importance of fixed costs are unlikely to be significant. If new entrants\ncan capture a share sufficient to support the required infrastructure, then established companies like Amazon will find it difficult\n\nto keep them out.\n\nTABLE 3.1\n\f"}, "002956.png": {"text": "Sales\nFixed costs (FC)\nFC as % of sales\n\nSales\nFixed costs (FC)\nFC as % of sales\n\nSales\nFixed costs (FC)\nFC as % of sales\n\nEntrant Incumbent\nOriginal market size\n\n$500,000 $2,500,000\n$100,000 $100,000\n20% 4%\n\nTwo times original market size\n$1,000,000 $5,000,000\n$100,000 $100,000\n10% 2\n\nTen times original market size\n$5,000,000 $25,000,000\n$100,000 $100,000\n2% 0.4%\n\nIncumbent's Difference\n\n$2,000,000\n\n16% lower\n\n$4,000,000\n\n8% lower\n\n$20,000,000\n\n1.6% lower\n\nAlthough it may seem counterintuitive, most competitive advantages based on economies of scale are found in local and niche\n\nmarkets, where either geographical or product spaces are limited and fixed costs remain proportionately substantial.\n\nThe postderegulation telecommunications industry is a good example of the importance of local economies of scale. The old-\n\ntechnology local exchange carriers, whose markets are not large enough for a second or third company to reach viable scale, have\n\nfared much better in terms of profitability than the national long-distance and cellular carriers like AT&T, MCI-WorldCom, and\n\nSprint.\n\f"}, "002957.png": {"text": "STRATEGY AND COMPETITIVE ADVANTAGE THROUGH SUPPLY OR DEMAND\n\nPrescriptions for strategy in any particular market depend on the existence and types of competitive advantages that prevail in it.\n\nThe first and simplest case is where there are no competitive advantages in the market. There is nothing that fundamentally\ndistinguishes an existing firm from actual and potential rivals, and the economic playing field is level. History and logic both con-\nfirm how difficult it is for a single firm to shift the basic economic structure of such a market significantly for its benefit.\n\nA firm in an industry with no competitive advantages basically should forget visionary strategic dreams and concentrate on\nrunning itself as effectively as it can. What matters in these circumstances are efficiencies in managing costs, in product develop-\nment, in marketing, in pricing to specific customer segments, in financing, and in everything else it does. If it can operate more\neffectively than its competitors, it will succeed.\n\nOperational effectiveness can make one company much more profitable than its rivals even in an industry with no competitive\nadvantages, where everyone has basically equal access to customers, resources, technology, and scale of production. In the last\nchapter of the book, we document for a range of industries just how large and important these differences are. Firms that are oper-\nationally effective, however, do tend to focus on a single business and on their own internal performance.\n\nIn competitive situations where a company enjoys advantages related to proprietary technologies and customer captivity, its\nstrategy should be to both exploit and reinforce them where they can.\n\nExploitation can take several forms. A company with captive customers can charge more than the competition does. If the\nadvantages stem from lower costs, it can strike a balance between underpricing competitors to increase sales and charging the\nsame to keep the full benefit of the cost advantage. So long as the firm is either alone in the market or surrounded by a myriad of\nsmaller and weaker competitors, it can determine the appropriate price level by trial and error. It needs to monitor its steps to see\nwhich price levels and other marketing choices provide the best return, but it does not have to worry explicitly about the reactions\n\nof particular competitors.\n\f"}, "002958.png": {"text": "In fact, the process of exploitation in these cases is largely a matter of operational effectiveness. Strategies only become com-\nplicated where a small number of powerful firms enjoy competitive advantages in common. Much of the rest of this book concen-\ntrates on particular cases in which strategic interactions among the few are critical.\n\nTo reinforce its competitive advantages, a company first has to identify their sources and then to intensify the economic\nforces at work. If the source is cost advantages stemming from proprietary technologies, the company wants to improve them\ncontinually and to produce a successive wave of patentable innovations to preserve and extend existing advantages. The practice\nhere is again a matter of organizational effectiveness, including making sure that investments in research and development are\nproductive.\n\nIf the source is customer captivity, the company wants to encourage habit formation in new customers, increase switching\ncosts, and make the search for alternatives more complicated and difficult. For expensive items, it wants to make purchases more\nfrequent and to spread payments out over time, to ensnare the customer in an ongoing relationship that is easier to continue than\nto replace.\n\nThe automobile companies, facing lengthening intervals between car purchases, mastered the techniques long ago. In the late\n1950s and early 1960s, they began to use highly visible annual style changes to encourage more frequent purchases. They also\nbegan accepting trade-ins and monthly payments to ease the financial burden. More recently, leasing programs have been tailored\nto accomplish the same thing, with customers offered new cars before the old leases have expired.\n\nCustomer loyalty programs\u2014frequent-flier miles, affinity credit cards, and other reward plans\u2014have the same goal, keeping\ncaptive customers in the corral. The famous Gillette strategy of selling the razor cheaply and then making money from the regular\npurchase of blades has been copied by other industries. Magazine subscription campaigns that offer inexpensive initial subscrip-\ntions to profit from higher-priced renewals are a variant. The common element in all these approaches is that they encourage re-\npeated, virtually automatic and nonreflective purchases that discourage the customer from a careful consideration of alternatives.\n\nAmplifying switching costs is usually a matter of extending and deepening the range of services offered. Microsoft has\n\nregularly added features to its basic Windows operating system, making the task of switching to other systems and mastering\n\f"}, "002959.png": {"text": "their intricacies more onerous. As banks move beyond simple check processing and ATM withdrawals to automatic bill payment,\npreestablished access to lines of credit, direct salary deposit, and other routine functions, customers become more reluctant to\nleave for another bank, even if it offers superior terms on some products.\n\nThe same tactic of providing more integration of multiple features raises search costs. Comparison shopping is more difficult if\nthe alternatives are equally complicated but not exactly comparable. Few people spend their leisure time analyzing the pricing and\nservice plans of wireless telephone companies. Also, as the importance and added value of products and services increases, so does\nthe risk of getting a poor outcome from an alternative provider.\n\nThe same potentially poor results also raise the cost of sampling; something might go seriously wrong during the trial period.\nThis problem extends beyond the more obvious situations like finding a new cardiologist or a residential insurance carrier. Philip\nMorris spent a fortune promoting the image of the Marlboro smoker. If a Marlboro Man\u2019s standing in society seems to depend on\nthe brand of cigarette he chooses, the risk of a switch to Camels may be more than he is willing to assume. Complexity, high added\n\nvalue, and significance are all components of high search costs.\n\nSTRATEGY AND ECONOMIES OF SCALE\n\nCompetitive advantages based on economies of scale are in a class by themselves for two reasons.\n\nFirst, as we have mentioned, they tend to be far longer lived than the two other types, and therefore more valuable. Coca-Cola\nis one of the most valuable brands in the world not because it is so widely recognized, but because of customer captivity and, more\nimportantly, local economies of scale in advertising and distribution. Due to these competitive advantages, Coca-Cola has an edge\nin acquiring new customers. It can appeal to them (advertising) and serve them (distribution) at a much lower unit cost than can\nits smaller competitors. But these advantages are particular to specific geographic regions. Despite its worldwide recognition,\n\nCoca-Cola is not the dominant soft drink everywhere. In places like Korea, where a local company allied with Pepsi is currently on\n\f"}, "002960.png": {"text": "top, Coca-Cola is not the most valuable brand. In Venezuela, Coca-Cola suddenly displaced Pepsi only because the leading local bot-\ntler suddenly shifted allegiance.\n\nSecond, advantages based on economies of scale are vulnerable to gradual erosion and thus need to be defended vigorously.\nOnce a competitor increases the size of its operations, it shrinks the unit cost gap between it and the leader. Each step a competitor\ntakes toward closing the gap makes the next step easier, because its margins and therefore its resources are improving as its costs\ndecline. At some point the entire advantage may be gone or even turn negative for the incumbent, if the entrant has become the\nlarger firm.\n\nThese advantages can be destroyed, but they can also be created. In a market with significant fixed costs but currently served by\nmany small competitors, an individual firm has an opportunity to acquire a dominant share. If there is also a degree of customer\ncaptivity, that dominant share will be defensible.\n\nThe best course is to establish dominance in a local market, and then expand outward from it. This is the path Sam Walton ini-\ntially pursued as he established dominance in small-town Arkansas and then from that base expanded nationally. It also describes\nMicrosoft\u2019s extension of its product space from operating systems to office applications. Even where incumbent competitors have\ndominant positions, lack of vigilance on their part may present openings for successful encroachment.\n\n\u2018Wal-Mart won out over Kmart and most of its other discount store competitors by extending its economies of scale strategy\ninto what had been the enemy\u2019s territory. Microsoft did the same to Lotus and WordPerfect in applications software. Economies of\nscale, especially in local markets, are the key to creating sustainable competitive advantages.\n\nIn pursuit of these opportunities, it is important to remember that size and rapid growth of the target market are liabilities for\nincumbents, not assets. Big markets will support many competitors, even when there are substantial fixed costs. Markets grow\nrapidly because they attract many new customers, who are by definition noncaptive. They may provide a base of viable scale for\n\nnew entrants.\n\f"}, "002961.png": {"text": "The appropriate strategy for both incumbents and entrants is to identify niche markets, understanding that not all niches are\nequally attractive. An attractive niche must be characterized by customer captivity, small size relative to the level of fixed costs,\nand the absence of vigilant, dominant competitors. Ideally, it will also be readily extendable at the edges. The key is to \u201cthink local.\u201d\n\nThe other side of this coin is the need to defend those local markets where a firm enjoys competitive advantages by responding\naggressively to all competitive initiatives however they arrive.\n\nThe incumbent can also take the first step and not wait to counterpunch. Anything it does to increase fixed costs, like advertis-\ning heavily, will present smaller competitors with the nasty alternatives of matching the expenses and hurting their margins or\nnot matching and losing the competition for new customers. Production and product features that require capital expenditures,\nlike building centralized facilities to provide automated processing, will also make life more difficult for smaller competitors.\nAccelerating product development cycles, and thereby upping the costs of research and development, is another possibility. Every-\nthing that efficiently shifts costs from variable to fixed will reinforce advantages from economies of scale.\n\nIll-conceived growth plans, in contrast, can do just the opposite. Grow or die corporate imperatives too often lead to grow and\ndie results. The fates of Kmart, Kodak, RCA, Westinghouse, CBS, the original Bank of America, and AT&T, all once lustrous corpo-\nrate names, are evidence of the perils of unfocused growth strategies. Instead of defending the markets in which they were domi-\nnant and profitable, they spent copiously in markets where they were newcomers battling powerful incumbents.\n\nIn contrast, companies that have stayed within their areas of fundamental competitive advantage, like Kimberly-Clark, Wal-\ngreen, Colgate-Palmolive, and Best Buy, have survived and generally flourished. Competitive advantages are invariably market-spe-\n\ncific. They do not travel to meet the aspirations of growth-obsessed CEOs.\n\nCOMPETITIVE ADVANTAGE, STRATEGY FORMULATION, AND LOCAL OPPORTUNITIES\n\f"}, "002962.png": {"text": "In the next chapter, we will provide a detailed procedure for assessing competitive advantages. The method needs to be used in the\nproper context. The first step in formulating strategy is to take an inventory of a firm\u2019s current and potential markets from a com-\npetitive advantage point of view.\n\nIn some markets, where there are no competitive advantages and none likely ever to emerge, the only approach is to operate\nefficiently. In another group of markets, where vigilant incumbents enjoy competitive advantages, potential entrants would do\nwell to back off, and nondominant incumbents to depart. In still other markets, a firm will enjoy current competitive advantages.\nIn these cases, its strategy should be to manage and defend them.\n\nFinally, there will be markets in which a company can establish competitive advantages by achieving defensible economies of\nscale. Most of these will be local, either geographically or in product space. They are the proper focus of strategic analysis. Many\ncompanies, if they look carefully, will find possibilities for dominance in some of their markets, where they can earn above normal\nreturns on investment. Unfortunately, these local opportunities are too often disregarded in the pursuit of ill-advised growth asso-\n\nciated with global strategic approaches.\n\f"}, "002963.png": {"text": "CHAPTER 4\n\nAssessing Competitive Advantages\n\nTHREE STEPS\n\nBecause the concept of competitive advantage lies at the core of business strategy, it is essential to determine whether a company\nbenefits from a competitive advantage, and if it does, to identify the sources of that advantage.\n\nThere are three basic steps to doing such an assessment:\n\n1. Identify the competitive landscape in which the firm operates. Which markets is it really in? Who are its competi-\ntors in each one?\n2. Test for the existence of competitive advantages in each market. Do incumbent firms maintain stable market\n\nshares? Are they exceptionally profitable over a substantial period?\n\f"}, "002964.png": {"text": "3. Identify the likely nature of any competitive advantage that may exist. Do the incumbents have proprietary tech-\n\nnologies or captive customers? Are there economies of scale or regulatory hurdles from which they benefit?\n\nThe first and most important step is to develop an industry map that shows the structure of competition in the relevant\nmarkets. This map will identify the market segments that make up the industry as a whole and list the leading competitors within\neach one. Deciding where one segment ends and another begins is not always obvious. However, if the same company names show\nup in adjacent market segments, then these segments can usually be treated as a single market. Mapping an industry helps a com-\npany see where it fits in the larger picture and who its competitors are, even if the segment breakdowns are not always precise.\n\nThe second step is to determine for each market segment whether it is protected by barriers to entry, or in other terms, whether\nsome incumbent firms enjoy competitive advantages. There are two telltale signs of the existence of barriers to entry/competitive\n\nadvantages:\n\n+ Stability of market share among firms. If companies regularly capture market share from each other, it is unlikely\nthat any of them enjoys a position protected by competitive advantages. In contrast, if each firm can defend its\nshare over time, then competitive advantages may be protecting their individual market positions.:\n\nStability in the relative market positions of firms is a related issue. The key indicator of this is the history of the\ndominant firm in the segment. If the leading company has maintained its position over a period of many years,\nthat fact strongly suggests the existence of competitive advantages. If, on the other hand, it is impossible to single\nout a dominant firm, or if the firm at the top changes regularly, then no single company is likely to enjoy sustain-\nable competitive advantages.\n\nThe history of entry and exit in a market segment provides another clue. The more movement in and out, the\n\nmore turbulent the ranking of the companies that remain, and the longer the list of competitors, the less likely it\n\f"}, "002965.png": {"text": "is that there are barriers and competitive advantages. Where the list of names is short and stable, the chances are\ngood that the incumbents are protected by barriers and benefit from competitive advantages.\n\nProfitability of firms within the segment. Ina market without competitive advantages, entry should eliminate\nreturns above a firm\u2019s cost of capital. If the companies in a market maintain returns on capital that are substan-\ntially above what they have to pay to attract capital, the chances are strong that they benefit from competitive\nadvantages/ barriers to entry. These sustainable excess returns may be restricted to a single dominant firm, or\nthey may be shared by a limited number of companies who all enjoy competitive advantages over smaller firms\nand potential entrants.\n\nThere are a number of ways to measure profitability. The approaches that permit comparisons across industries\ncalculate returns either on equity or on invested capital.\n\nAfter-tax returns on invested capital averaging more than 15 to 25 percent\u2014which would equate to 23 to 38\npercent pretax return with tax rates of 35 percent\u2014over a decade or more are clear evidence of the presence of\ncompetitive advantages. A return on capital in the range of 6-8 percent after tax generally indicates their absence.\nThere is one major difficulty in measuring returns on investment in any particular market. Corporations report\ntheir results for the company as a whole; they may include breakdowns for highly aggregated industry segments\nand for continental-sized geographic regions. But the markets where competitive advantages are likely to exist\nwill often be local, narrowly bounded either in geography or product space. A typical company of even medium\nsize may benefit from barriers to entry in several such markets, but stellar results there will be diluted in the\nfinancial reports by being combined with returns from other, less profitable operations. Identifying historical\nprofitability for particular markets often requires extrapolation. The best way is to look at the reported profits of\n\u201cpure play\u201d companies, whose operations are narrowly focused within these markets. The resulting profitability\ncalculations for focused segments are critical to any strategy for exploiting competitive advantages and minimiz-\n\ning the impact of competitive disadvantages.\n\f"}, "002966.png": {"text": "When the analysis of market share stability and profitability are consistent with one another, the case for the existence of\ncompetitive advantage is robust. For example, Enron reported only a 6 percent return on capital for the year 2000\u2014its most\nprofitable year\u2014and it needed the help of accounting manipulations to do even that. This result by itself should have cast doubt on\nits claim to competitive advantages in trading markets for new commodities like broadband and old ones like energy. The history\nof the trading operations of established Wall Street firms, in which changing relative market positions are the rule, makes the case\nagainst competitive advantage for Enron even stronger.\n\nIf market share stability and profitability indicate the existence of competitive advantages, the third step is to identify the\nlikely source of these advantages. Do the dominant firms in this industry benefit from proprietary technologies or other cost\nadvantages? Do they have captive customers, thanks to consumer habit formation, switching costs, or search costs? Are there sig-\nnificant economies of scale in the firm\u2019s operations, combined with at least some degree of customer captivity? Or, if none of these\nconditions seems present, do the incumbent firms profit from government intervention, such as licenses, subsidies, regulations,\nor some other special dispensation?\n\nIdentifying the likely source of a firm\u2019s competitive advantage serves as a check to confirm the findings from the data on mar-\nket share stability and profitability. Even when market share is stable and profitability is high, a close look at the business may fail\nto spot any clearly identifiable cost, customer captivity, or economies of scale advantages.\n\nThe likely explanation for this discrepancy is either that the market share and profitability figures are temporary, or that they\nare the consequence of good management\u2014operational effectiveness\u2014that can be emulated by any sufficiently focused entrant.\nIdentifying the sources of competitive advantages should help predict their likely sustainability, a necessary step for both incum-\nbents and potential entrants when formulating their strategies.\n\nThe three-step procedure for assessing competitive advantage is depicted in figure 4.1.\n\nTHE STEPS IN PRACTICE: A LOOK AT THE FUTURE OF APPLE COMPUTER\n\f"}, "002967.png": {"text": "Now let\u2019s use this procedure to look at Apple Computer. We will review its past and forecast its likely future. In its history, Apple\nhas chosen strategies that have involved it in almost every important segment of the personal computer (PC) industry. The vision-\naries at Apple, first Steve Jobs, then John Sculley, then Jobs in his second tenure, have at times sought to revolutionize not simply\n\nthe PC industry itself, including most of the hardware and software segments, but also the related areas of personal communica-\n\ntions and consumer electronics.\n\n \n\n1. Develop an industry map\n\n \n\n+ Wentify individual market segments\n+ Identify competitors in each segment\n\n \n\n \n\n \n\nFor each segment\n\n \n\n2. Test for the existence of competitive\nadvantages\n\n \n\n \n\n+ Market-share stability, dominant firm,\nlow entries and exits\n+ Sustained high profitability\n\n \n\n \n\n \n\n \n\n3. Lock for sources of ccenpetitive advantage\n\n \n\nProprietary technology, cheap reacurces\nCustomer captivity\n\nEconomies of scale\n\nGovernment intervention\n\n \n\n \n\n \n\f"}, "002968.png": {"text": "FIGURE 4.1\n\nAssessing competitive advantage: three steps\n\nApple has consciously attempted to bring an inclusive vision to this collection of often unrelated segments. The hope was to\nreap the benefits of synergies across chip and component development, hardware design, manufacturing, software features, and\neven communications protocols. John Sculley, describing Apple\u2019s personal digital assistant in 1992, said of the company \u201cwe really\ndon\u2019t invent new products, but the best ones are there already, only invisible, waiting to be discovered.\u201d\n\nGiven Apple\u2019s checkered economic history, the initial presumption has to be that its aspirations have not coincided with the\neconomic realities of the markets in which it has competed. Since Apple has never been a particularly efficient operator, the burden\nhas fallen almost entirely on the strategic choices it has made, its ability to benefit from competitive advantages. Apple is not alone\nin this position. An argument of this book is that large and diffuse, as opposed to local and specific, strategic visions are almost al-\n\nways misguided.\n\nDEVELOPING AN INDUSTRY MAP: APPLE IN THE PERSONAL COMPUTER INDUSTRY\n\nLike maps in an atlas, industry maps can be drawn at various levels of detail. Our initial effort divides the PC industry into only six\nsegments, as shown in figure 4.2. PCs are built from components, of which the central processing unit (CPU), the chip at the heart\nof every personal computer, is the most important. The leading CPU manufacturers are Intel, Motorola, IBM, and AMD. Other com-\nponents include keyboards, power supplies, graphic interface boards, disk storage devices, memory chips, monitors, speakers, and\nscores of additional parts.\n\nPersonal computer manufacturers like Dell, IBM, HP, Compag (which merged with HP in 2002), and many others assemble\n\nthese components into PC systems. They also incorporate operating system software, from companies such as Microsoft, and\n\f"}, "002969.png": {"text": "may add some applications software packages, such as word processors, spreadsheets, Internet browsers, financial management\nprograms, graphics programs, security, and more. The applications programs are more frequently sold directly to users. Some of\nthese applications programs are produced by the operating system software companies; some come from specialized providers like\nAdobe and Intuit.\n\nFinally, PC owners today almost invariably connect their machines to the Internet through network service providers, like AOL,\nEarthlink, MSN, Time Warner, or the regional telephone companies that allow them to communicate with other users. Yahoo,\n\nGoogle, and other Internet sites are also in the network segment, broadly conceived.\n\n  \n\nPC Manufacturing\n\n  \n \n\nSystem Software ee Networks\n\n    \n\nOther\nComponents\n\nFIGURE 4.2\n\nMap of the personal computer industry (first version)\n\nAn initial industry map almost invariably represents a compromise between the virtues of simplicity and tractability, on the\none hand, and the requirements of comprehensiveness, on the other. Too much detail risks overwhelming the map with too many\nsegments; too little detail risks missing important distinctions.\n\nThe appropriate amount of precision depends on the specific case, and also on what we discover in the initial analysis. The\n\nOther Components segment, for example, could be broken down into a number of separate units\u2014printers, modems, disk drives,\n\f"}, "002970.png": {"text": "monitors, and so on. The Applications Software segment should ultimately also be subdivided into more niches, like database\nmanagement, desktop publishing, photographic and motion picture editing, and more.\n\nOur bias for starting simple also influences our treatment of the PC Manufacturing segment, where we have deliberately\nexcluded game consoles, workstations, handheld computers, and other products that all compete at some level with PCs. Finer-\ngrained divisions become necessary only if we think, after our initial foray, that Apple\u2019s future may depend significantly on the\nstructure of competition in these particular markets. Starting with six segments allows us to keep things simple unless there is a\nneed to make them more complex.\n\nWe next list the names of the firms that operate in each segment of the map, putting the dominant company, measured by mar-\nket share, at the top (figure 4.3).\n\nFor microprocessors (CPU chips), Intel is clearly the leader, followed by AMD, IBM, and Motorola, which was Apple\u2019s primary\nsupplier at the introduction of the Macintosh, and later shared the business with IBM. The hardware (PC) manufacturers include\n\nDell, HP, Compaq, IBM, Gateway, Toshiba, and of course, Apple.\n\f"}, "002971.png": {"text": " \n\nCPU Chips\nIntel\nAMD\nIBM\n\nMotorola\n\nFIGURE 4.3\n\nMap of the PC industry (with names)\n\nEven at this early stage of the analysis, two obvious and important facts emerge. First, there is almost no overlap in names\nbetween the two segments, meaning that each has to be analyzed separately. (IBM is in both segments, but it primarily uses Intel\n\nCPUs in its own PCs.) Second, while there are only four companies in the microprocessor segment, the list of PC manufacturers is\n\nPC Manufacturing\nDell\n\nCompaq\nHewlett-Packard\nIBM\n\nGateway\n\nApple\n\n \n\nSoftware\n\nSystems\nMicrosoft\nIBM\nApple\nLinux\n\nApplications\n\nMicrosoft\nTntuit\nAdobe\nAutodesk\n\nboth long and incomplete, and the identity of the dominant firm is not obvious.\n\nNetworks\nAOL\nYahoo\nMicrosoft\nEarthlink\n\n \n\f"}, "002972.png": {"text": "The Systems and Applications Software segment list is headed by Microsoft; other players are Apple, IBM (with its OS/2 system,\nat one time a potential competitor), and Linux, all much smaller. Two firms, IBM and Apple, are also PC manufacturers, but Micro-\nsoft makes neither chips nor PC \u201cboxes.\u201d In cases where there is some overlap in names, the segments need to be kept distinct and\ntreated separately so long as the dominant firms differ across segments.\n\nMicrosoft is also the dominant firm in the Applications Software segment; its office productivity suite of programs and its\nbrowser lead their categories in current sales and size of the installed base of users. Other companies with visibility, including In-\ntuit in financial software, Adobe in graphics and typographics, Autodesk in architectural and design software, do not appear else-\nwhere. So there is a decision to make on whether to consolidate the segments.\n\nIt is usually preferable to begin by keeping segments distinct and then look for connections across segments. Amalgamation\ntends to conceal strategic issues that separate treatment may reveal. For the sake of simplicity, in this example we will use Micro-\nsoft\u2019s dominance in both system and applications software to justify combining the two segments into one software group, with\nthe intention of revisiting the decision when we are further along in the analysis.\n\nAOL is the dominant firm in the Networks segment. The one company whose name appears here and elsewhere is Microsoft,\nwhose MSN has become a major competitor in the network business. But because AOL operates only in this segment, and Apple\nhas virtually no presence, we will treat it as distinct. PC wholesaling and retailing is also a distinct segment, even though Apple\ndoes run around eighty retail outlets. Because it is not relevant to the company\u2019s competitive position, we are going to ignore it\naltogether.\n\nWe have also dropped the Other Components segment from this version of the map. Given the diversity of these components\u2014\nprinters, disk drives, memory chips, keyboards, and all the others\u2014and the fact that each subsegment has many competitors with\nvirtually no crossover of names, each would need to be analyzed separately. All these segments look much like the PC Manufac-\nturing sector\u2014a long and unstable list of competitors with no firm clearly dominant. Industries with these characteristics tend to\nhave similar strategic implications, both in themselves and for segments upstream and downstream from them. So we can defer\n\ntreatment of Other Components until we have looked closely at PC Manufacturing to see whether more detailed examination is\n\f"}, "002973.png": {"text": "necessary to understand Apple's strategic choices. In this case, since Apple has not tended to compete significantly in these compo-\nnent segments, the chances are that we will continue to ignore them.\n\nThe three segments that we cannot ignore are CPUs, Software, and PC Manufacturing. For each of these, we need to know\nwhether competitive advantages exist, and, if they do, what they are and whether it is Apple or its competitors who benefit from\n\nthem.\n\nTESTING FOR AND IDENTIFYING COMPETITIVE ADVANTAGES: THE CHIP SEGMENT\n\nIn the CPU industry, market share has been quite stable since the early 1980s, after the introduction of IBM\u2019s PC, around which\nmuch of the industry standardized. Intel has been the dominant supplier for two decades, through many generations of chips.\nOther powerful companies like IBM, NEC, and Texas Instruments have tried, over time, to gain entry but have not been particu-\nlarly successful. Motorola was a major competitor in the early 1980s but since then has fallen far behind Intel. Intel\u2019s share has\nheld fairly stable since then, hovering around 90 percent. At times, AMD has made some inroads, but Intel has always rebounded.\nShare stability like this is evidence of the existence of major barriers to entry and competitive advantages.\n\nThe history of Intel\u2019s profitability tells the same story. Except for a brief period in the mid 1980s, before it quit the memory\nchip business, Intel\u2019s average returns on capital have exceeded 30 percent after tax. The ratio of its market value to the estimated\nreplacement cost of its net assets has continually exceeded 3 to 1; each dollar invested by Intel has created three or more dollars\nin shareholder value. The absence of successful entry and Intel\u2019s continued dominance in the CPU chip market is clearly a sign of\na strong incumbent competitive advantage. The sources of Intel\u2019s advantage\u2014captive customers, economies of scale, and some\npatent protection\u2014are clear; we discussed them in chapters 2 and 3.\n\nUnfortunately for Apple, it has been on the losing side in this competition. Its alliance has been with Motorola for the first\ngeneration of Macintosh CPUs, and with Motorola and IBM for the PowerPC chips. The introduction of the Macintosh, in 1984,\n\nwith its graphical user interface based on a Motorola chip, secured for Apple the lead in everything graphic that might be done on\n\f"}, "002974.png": {"text": "a personal computer. But Intel powered ahead, and its later generation of CPUs have been capable of running Microsoft\u2019s Windows\nsoftware, in most ways indistinguishable from the Macintosh interface.\n\nGiven Intel\u2019s economies of scale advantages, it has been able to outdistance Motorola in adding processing power to the CPU.\nApple has been left having to play catch-up, sometimes missing an upgrade cycle. Though Motorola and Apple have won praise\nfor the graphic and multimedia capabilities of their chip-operating system integration, the alliance has put Apple at a competitive\ndisadvantage because each generation of CPU chips requires about $1 billion in research and development costs. Intel sells more\nthan 100 million chips per generation, making their R&D cost per chip around $10. The Apple-Motorola-IBM alliance has sales of\n10 million chips in a generation, putting their R&D cost at around $100 per chip. They are faced with the choice of severely cutting\ntheir R&D spending, which would virtually guarantee failure in the race for new technology, or shouldering the much higher cost\n\nper chip. In either case, they are playing on a field tilted against them, and will not fare well.\n\nTESTING FOR AND IDENTIFYING COMPETITIVE ADVANTAGES: THE SOFTWARE SEGMENT\n\nMicrosoft\u2019s dominance of the software segment is even more pronounced than Intel\u2019s position in microprocessors. IBM\u2019s open\narchitecture for the PC allowed many other companies to become manufacturers, but the operating system was standardized on\nMicrosoft\u2019s MS-DOS. Since then, Microsoft has made the most of this privileged position, both by defending its core turf and by\nextending its franchise. It smothered IBM\u2019s effort to take back some of the operating system market with OS/2. It overcame Apple\u2019s\ninitial lead in graphical user interface by developing Windows to succeed MS-DOS. It fought off potential threats to the primacy\nof the operating system by taking the browser market away from Netscape, and it continues to keep Linux and the open source\nmovement a marginal factor in the desktop market, although Linux has gained more acceptance as the operating system for work-\nstations and servers.\n\nAt the same time, Microsoft has become a leading applications provider in word processing, spreadsheet, presentation, and\n\nfinancial programs for the PC. Versions of the Windows operating system extend downward to personal digital assistants and mo-\n\f"}, "002975.png": {"text": "bile telephones and upward to larger server computers. It has not been able to dominate the game console business, where it is one\nof the three leading console manufacturers (and not yet a profitable one), or cable television systems, set-top boxes, and other mar-\nkets more remote from its central strength in the desktop operating system.\n\nIn the operating systems market, its share has remained above 80 percent, often above 90 percent, for two decades. It used this\ndominance, and the profitability that stemmed from it, to push its way to the top of the office suite and browser businesses. Its\nleverage from the ownership of the operating software code insured early compatibility of applications programs, and its posi-\ntion as supplier of the operating system assured that PC manufacturers needed Microsoft much more than it needed any of them.\nSometimes its aggressive behavior brought out the regulators, but two major antitrust cases in the United States left Microsoft\natop its markets, hardly scathed by the experience. The European Union may do more damage.\n\nIt is a criminal understatement to say that Microsoft has been profitable. From its IPO in 1986 through 2000, Microsoft aver-\naged an after-tax return on capital of 29 percent per year. In 2001 and 2002, the figure dropped to 15 percent, still high although\nnot so stratospheric. Yet these figures, impressive as they are, do not begin to reveal the extraordinary profitability of Microsoft\u2019s\ncore business. In 2002, the company\u2019s capital\u2014its total debt and equity\u2014totaled $52 billion. Since Microsoft had no debt, all of\nthat figure represented equity.\n\nThe equity was invested in two businesses. The first business was money, cash in the bank or some close equivalent. In 2002,\nits average cash balance was $35 billion, on which it earned roughly $1.2 billion after tax, or around 3.5 percent. The rest of its\nafter-tax earnings, around $6.6 billion, came from its software businesses, on an investment of $13.5 billion (debt plus equity\nminus cash), or a return on investment of 49 percent.: Only by blending the returns of its software operations with the returns\non its mountain of cash could Microsoft report an after-tax return on capital of 15 percent. Calculated in this manner, from 1986\nthrough 2000, Microsoft\u2019s software business averaged a return on capital of around 100 percent, after tax.: See table 4.1.\n\nIt is abundantly clear that Microsoft enjoys a competitive advantage. The sources of that advantage are not difficult to identify.\n\nIt isn\u2019t technology. Talented computer programmers have been abundant for decades, and even though Microsoft does have copy-\n\f"}, "002976.png": {"text": "right protection for its source code, nothing prevents other software companies from turning out comparable or superior products\nwith their own software. Many professionals have been scornful of Microsoft\u2019s offerings for years.\n\nThe company does have captive customers, partially because much of the software they own is not compatible with other oper-\nating systems, making change expensive and time-consuming. Its economies of scale are vast, since writing standard programs is\nalmost entirely a fixed-cost business. With its enormous customer base, Microsoft has been able to throw years of program writing\ninto any project it thinks important and still end up spending less per unit sold than its competitors.\n\nFinally, there is the network effect, the fact that the value of the product to the user depends on how many other people also use\nit. A competitor to Microsoft in both the operating system and applications software businesses is at a huge disadvantage, no mat-\n\nter the quality of its offerings.\n\nTABLE 4.1\n\nMicrosoft\u2019s returns on investment, 2002 ($ billion)\n\nCash at end of year $38.6\nDebt $0\nEquity $52.2\nCapital\u2014cash $13.6\nNet income $7.8\nEarnings on cash $1.2\n\nEarnings on software $6.6\n\nTotalreturnon capital 15.0%\n\f"}, "002977.png": {"text": "Return on capital\n| | 48.8%\ninvested in software\n\nApple has been competing against Microsoft since IBM introduced the PC in 1981. At times it has had a superior operating sys-\ntem by almost any independent measure, yet it has never managed to gain much more than around 13 percent of the market, and\nthat figure has been considerably lower since Microsoft introduced a workable version of Windows. The situation in the software\nsegment parallels that in microprocessors, with Apple and its allies losing out to Microsoft and Intel, or \u201cthe Wintel platform,\u201d as\nthe tight relationship between Microsoft and Intel has been called. Apple's strategy of integration has been no match for the mar-\n\nket-specific competitive advantages that its rivals enjoy.\n\nTESTING FOR AND IDENTIFYING COMPETITIVE ADVANTAGES: THE PC MANUFACTURING SEGMENT\n\nThe PC manufacturing segment of the industry looks nothing like the microprocessor or software segments. The dominant firm\nhas changed over time; new companies have entered and existing ones exited; and the share of the market held by the top twenty\nfirms has seldom exceeded 60 percent of the total. Even among the largest firms, market share changes from year to year have been\nsubstantial. Data for the years 1990-98 reveals how much market share varied from year to year, and how far the top firms in 1990\nhad fallen by 1998.\n\nThe basic share stability calculation is shown in table 4.2. Columns 1 and 2 are simply the share each company held in the U.S.\nmarket in 1990 and 1998. In columns 3 and 4, the combined share of the seven companies has been set to 100 percent, and each\ncompany\u2019s portion of that total has been calculated. Finally, column 5 reports the change between 1990 and 1998 in normalized\n\nshares on an absolute basis (i.e., column 4 minus column 3, leaving negative signs out). The average gain or loss for each firm over\n\f"}, "002978.png": {"text": "the entire period was 15 percentage points, a marked contrast with the less than 2 percentage point figures for software and CPU\nchips.\n\nTABLE 4.2\nCalculating market-share stability\n\nU.S. Market Share Normalized Market Share Absolute Change\n\n1990 1998 1990 1998\nApple 10.0% 4.6% 20.1% = 71% 22.1%\nCompaq 45% 16.7% 12.0% 25.7% 13.6%\nDell 1.0% 13.2% 2.7% 20.3% 17.6%\nGateway 1.0% 8.4% 2.7% 12.9% 10.2%\nHP 0.0% 78% 0.0% 12.0% 12.0%\nIBM 16.1% 8.29% 43.0% 12.6% 30.5%\nPackard Bell 3.9% 6.29% 10.4% 9.5% 0.9%\nThese seven \u2014 \u2014\u2014\u2014\u2014\u2014\u2014\u2014\ncompanies:\ncombined 87.4% 65.1% 100.0% 100.0% 15.3%\n\nAsa first rule of thumb, if you can\u2019t count the top firms in an industry on the fingers of one hand, the chances are good that\nthere are no barriers to entry. The rapid change in market share in table 4.2 confirms the rule. As a second rule of thumb, if over a\nfive-to eight-year period, the average absolute share change exceeds 5 percentage points, there are no barriers to entry; if the share\n\nchange is 2 percentage points or less, the barriers are formidable.\n\f"}, "002979.png": {"text": "Profitability for firms in this segment has been uneven. Some of the leading companies, especially IBM and Hewlett-Packard,\nare so diversified that it is difficult to get a good look at how much they earn, and on how much in dedicated assets, within the PC\nbusiness. Apple, Dell, Compaq, and Gateway, however, do allow a more direct view of discrete PC profitability.\n\nWithin a given industry, there are two primary approaches to gauge profitability. One uses income as a percentage of revenue,\nthe other income as a percentage of the resources employed in the business. Net income figures are readily available, but they in-\nclude items such as interest paid (or earned), taxes paid (or refunded), and extraordinary items like earnings or losses from uncon-\nsolidated investments, none of which reflect the actual operations of the business. So our preference is to look at operating income\n(earnings before interest and taxes, or EBIT), which omits interest, taxes, and some other extraneous charges (or additions).\n\nWe should not ignore what the companies report as extraordinary gains or charges, like the writing down of inventory or other\nassets, because these reflect operating business decisions even though they may accumulate unreported until some event forces\nan acknowledgment that something significant has occurred. To incorporate these sporadic entries in the income statement,\nwherever possible we take the average of \u201cextraordinary items\u201d for the current and four prior years, and add or subtract it from\noperating earnings, labeling the result \u201cadjusted operating earnings.\u201d We divide this figure by revenue to produce the \u201cadjusted op-\nerating margin.\u201d\n\nFor the four PC manufacturers on which we can get reasonably relevant numbers, adjusted operating margins for the ten years\n1991-2000 averaged 5.8 percent (table 4.3). Net income margins were lower, largely due to taxes, although Apple had some nonop-\nerating income that resulted in the two margin figures being the same.\n\nDell\u2019s operating margins, at 8 percent for the period, were the highest; Apple\u2019s, at 2.2 percent, the lowest. Among the undiver-\nsified PC makers, there is relatively little dispersion, certainly nothing like the gap between Intel and its smaller competitors. This\nclustering is itself a sign that there are no strong competitive advantages in the industry. Also, these operating margins are mod-\nest. For Intel, the comparable figure for this same period averages almost 32 percent. (See the appendix on methods for measuring\n\nreturns.)\n\f"}, "002980.png": {"text": "When we compare the four companies using different ways of measuring returns on resources, several findings stand out\n(table 4.4). First, Dell and Gateway were much more profitable than Apple and Compaq, no matter which measure is chosen. Sec-\nond, the pretax ROIC for Dell and, to a lesser extent, Gateway are suspiciously high. The explanation for these extraordinary results\nis that Dell\u2019s business model, mimicked by Gateway, requires very little invested capital to support large amounts of revenue and\noperating income. In Dell\u2019s fiscal 1998 (ending February 1, 1998), for example, the company had higher current liabilities than\ncurrent assets, once surplus cash is excluded (table 4.5). Its build-to-order approach allowed it to run a very tight ship. Its revenue\nfor the year was eight times the value of year-end receivables, fifty-three times the value of year-end inventory, and thirty-six\ntimes the value of year-end plant and equipment. Not only did Dell have negative working capital, it had more surplus cash on its\nbalance sheet than the combined total of debt and equity. With negative invested capital, the return calculation is infinite (and\n\nonly by omitting 1998 were we able to produce any figure for Dell in table 4.4).\n\nTABLE 4.3\nAdjusted operating and net income margins for four PC manufacturers, 1991-2000\n\nAdjusted Operating Margins Net Income Margins\n\nApple 2.2% 2.2%\nCompaq 6.5% 3.8%\nDell 8.0% 5.5%\nGateway 6% 5.1%\n\nAverage 5.8% 4.1%\n\f"}, "002981.png": {"text": "Part of the problem is due to the shortcomings of the measurement of assets under standard accounting procedures. Much of\nDell\u2019s investment is in intangibles\u2014brand recognition, organizational capital, sales relationships, and trained personnel. None\nof the funds spent on developing these valuable attributes appears on a company\u2019s balance sheet, leaving invested capital under-\nstated and returns on invested capital substantially overstated. Using returns on sales as a measure of operating efficiency, Dell\nand Gateway are not that different from Compag (see table 4.3), and the difference is accounted for largely by Compaq\u2019s greater\n\nspending on research and development.\n\nTABLE 4.4\n\nReturn on resources measures for four PC manufacturers, 1991-2000\n\nAdjusted Adjusted\n\nOperating Operating\n\nNet Income\u2019 Net Income/\n\nIncome/ Assets Income/ Invested\n\nAssets (ROA Equity Capital\n\n(ROA) Adjusted) (ROE) (ROIC)\n\nApple 2.6% 3.2% 0.4% 24.5%\nCompaq = 6.5% 10.9% 10.196 33.6%\nDell 13.0% 18.6% 34.2% 236.0%\nGateway 15.9% 20.3% 29.3% 71.3%\n\nAverage 9.596 13.2% 18.596 91.6%\n\f"}, "002982.png": {"text": "TABLE 4.5\nDell\u2019s invested capital, FY 1998 ($ million)\n\nTotal acts $  4zee\n(Cath and ecurton $ tee\nCash at 18 of revs $ 123\nSuphe cach 3 it\nNonrrtorectbeaing cunect lnbitiee $2807\nImoated capt g eo)\n\nEven though the results for Apple and Compaq demonstrate decent returns on invested capital on average, there were years\nin which they lost money. And Gateway, whose returns for the decade look so strong, lost over a billion dollars in 2001 and $300\nmillion in 2002. Considering all the information, both market share stability and profitability, it seems likely that the PC industry\nwas not protected by barriers to entry during this period and that if any competitive advantages existed, they were minimal. Dell\u2019s\nundeniable success should be attributed to operating efficiency, both the speed with which it assembled and shipped its machines\nout the door and the brilliant design of a business model that made such efficient use of its assets.\n\nIt is difficult to see what the sources of competitive advantage could have been. Customer captivity is low. Both individuals and\ninstitutions upgrading their systems shop for the best current tradeoff between features and value. The only exception is among\nApple\u2019s devoted users, but these have been a dwindling share of the overall market for some time. There is no proprietary technol-\nogy within the manufacturing segment. Again, except for Apple, all the major manufacturers are buying their components from\nthe same set of suppliers. Economies of scale are also hard to spot, at least historically. Fixed costs have represented a small portion\nof total production. Manufacturing facilities are widely dispersed, indicating no advantages to large-sized plants.\n\nGiven its leadership, Dell may benefit from being able to spread its sales and marketing operations over a larger base, and\nperhaps it is able to customize machines more cheaply because of its size. But these advantages are not enormous. Even as Dell in-\n\ncreased in size, its sales per employee did not continue to grow, nor did its lead over its competitors (figure 4.4).\n\f"}, "002983.png": {"text": "If any competitive advantages did exist in the past, it is certain that Apple has not been a beneficiary. If competitive advantages\nemerge in the future, primarily because of economies of scale combined with some customer captivity, the likely winner will be\nDell, not Apple. If Dell were to stumble or even fail because of some enormous strategic miscalculation, like being left behind after\narevolutionary shift in technology, the chances of Apple being the beneficiary are miniscule. The PC manufacturing segment has\nnot been the driving force in the industry, nor the place where most of the money has been earned. Since Apple has been on the\nwrong side of competitive advantages in both microprocessors and software, it is not realistic to think that it will be redeemed by\n\nits role as a manufacturer of boxes.\n\n31.200\n\n \n\n\u201cN\n\n3300\n\n3600\n\n$400\n\n \n\n \n\nso\n\n \n\n1990 199] 1992 1993 1994 1995 1905 1997 1998 1999 2000\n\nwees Apple \u2014 = \u2014 Compaq Dell ummm Gateway\n\n \n\f"}, "002984.png": {"text": "FIGURE 4.4\nSales per employee ($000)\n\nTHE BIG PICTURE FOR APPLE\n\nIf Apple does not come out on top in any of the segments that make up the personal computer industry, perhaps it can thrive by\nmaking it easy for a user to integrate some crucial parts, not only of the PC industry proper, but of other elements in the digital\nuniverse. Apple was an early\u2014premature\u2014entrant into what has become the personal digital assistant (PDA) market, but its New-\nton wasa flop. The handwriting recognition software was not up to the task and became the butt of comic strip jokes. Palm put the\nPDA business on its feet with its easy-to-use machines in the late 1990s, and when Microsoft produced a scaled-down version of\nWindows that could be crammed into handhelds, a number of manufacturers came to market with pocket PCs. Neither first-mover\nadvantage nor ease of integration with a Macintosh had been able to lift the Newton.\n\nApple has been more successful with its portable digital music player, the iPod, praised for its ease of use and elegant design.\nApple introduced the iPod in October 2001. Over 1 million units were sold within the first two years, and Apple continued to\nimprove the product, making it more compact and increasing its capacity to hold music. When third-party developers wrote\nsoftware allowing the iPod to be synchronized with Windows-based PCs, they helped iPod sales even as they undermined the syn-\nergistic appeal of the Macintosh-iPod connection. Sparked by the success of the iPod, other companies have introduced competing\nproducts, and the final chapters in the story have yet to be written.\n\nArguments for the advantages of synergy are generally suspect. If a firm in one market has a competitive advantage, it may be\nable to expand its reach by some well-chosen move into an adjacent area. But if it does not benefit from a competitive advantage in\nits core business, there is nothing it does that its competitors cannot match. Putting one and one together will not produce three,\n\nno matter how many times the magic word synergy is invoked. If ever there were an industry, broadly considered, in which this\n\f"}, "002985.png": {"text": "principle applies, it is the digital universe in which Apple works, where piracy\u2014unauthorized duplication\u2014is a constant threat.\nApple and its Macintosh have been able to delight their dedicated users with superior design and easier compatibility between\ndifferent pieces of hardware and software, but synergy on this scale has not provided Apple with enough leverage to overcome the\ndisadvantages it faces by being on the wrong side of the competitive advantages divide in both CPUs and software.\n\nApple operates in one field\u2014PC manufacturing\u2014where it is arguably on an equal footing with its competition. It has linked\nthis business to its positions in two other industries\u2014CPU chips and software\u2014where it operates at a significant competitive\ndisadvantage. Thanks to these connections, Apple is like a champion swimmer who decides to compete with a large cement block\nattached to each ankle. No matter how brilliant Steve Jobs is in running the company, the outcome of the race seems inevitable,\nand Apple does not look like the winner.\n\nIn our first pass through the PC industry, we ignored some segments that did not seem central to understanding the compet-\nitive landscape. But now a closer look may be warranted to discover whether Apple might benefit from some advantage in one of\n\nthese other segments.\n\nACLOSER LOOK AT OTHER COMPONENTS\n\nThis segment of the PC industry, we said earlier, has had characteristics much like those of the PC Manufacturing segment: many\ncompetitors with none dominant, no discernable competitive advantages, and no benefits to integration. There may be a few\nexceptions to this generalization. Hewlett-Packard has dominated the printer business for both laser and inkjet printers for some\nyears, with up to half the overall market and even more in the black-and-white laser area. But it is hard to imagine that anyone\nbuys a Hewlett-Packard PC because they want to use the same company\u2019s laser printer. Compatibility makes the printers popular,\nand compatibility eliminates any benefit that owning a printer and PC from the same manufacturer might provide. The same\nholds true for monitors, disk drives, keyboards, and most of the other peripherals. If some peripheral manufacturers are to thrive,\n\nit will be because they have specialized in their markets, run very efficient operations, and perhaps benefited from economies of\n\f"}, "002986.png": {"text": "scale. The idea that Apple may create a competitive advantage by integrating itself with a particular peripheral or component\n\nseems unlikely. So this more detailed examination of the component segment does not alter our original conclusions.\n\nACLOSER LOOK AT APPLICATIONS SOFTWARE\n\nBecause of Microsoft\u2019s dominance of both the operating system and the office suite markets, we merged the operating systems and\napplications software segments together in our initial treatment. Since applications software is not confined to word processing,\nspreadsheets, and presentation programs, the segment is worth a second look. Personal computers are ubiquitous, and the uses to\nwhich they are put are almost uncountable. Within that broad world, there is ample room for areas of specialization, niche mar-\nkets that are sizable enough to attract skilled programmers.\n\nThese markets look radically different from the individual component markets. Applications software segments are often dom-\ninated by a particular competitor\u2014Intuit in personal and small business accounting and tax preparation, Adobe in various graph-\nics programs, Symantec in security\u2014whose leading market position has been stable for some years. These competitors tend to be\nhighly profitable, with returns closer to those of Microsoft than to the hardware manufacturers. These firms enjoy a significant\nmeasure of customer captivity thanks to the time and effort that customers have made in mastering the software, which raises\nswitching costs. Like Microsoft, even though their underlying technology is not proprietary, they benefit from major economies of\nscale in software development and marketing. Each of these successful niche companies appears to enjoy significant competitive\nadvantages. But only within its niche; no firm is a dominant player in more than one vertical market.\n\nApple has benefited from such advantages in two applications areas. The first is graphics, broadly considered. The Macintosh\nhas historically been the computer of choice in areas with high visual and multimedia content. In desktop publishing, photogra-\nphy and digital film editing, and other kinds of creative design tasks, Macintosh has maintained a strong position, even as succes-\nsive Windows versions have come ever closer to matching the Macintosh\u2019s intuitive ease of use. Yet the disadvantages of being tied\n\nto an idiosyncratic operating system and its own CPU technology have gradually undermined Apple\u2019s position in these markets. In\n\f"}, "002987.png": {"text": "the early 1990s, analysts estimated that Apple had captured over 80 percent of the graphics and desktop publishing market. By the\nearly 2000s, that share had fallen to roughly 50 percent.\n\nApple\u2019s other great strength had been in the market for educational software. The Macintosh had the lion\u2019s share of the educa-\ntion (K-12) market in the early 1990s, in part because of software, in part because of the effort it put into the education market, in\npart because of loyalty. But that share eroded because its machines were more expensive, because school districts standardized on\nthe Windows platform, and because educators saw the benefits of educating students on the machines they were more likely to\nuse after they left school. By 2002, the Macintosh\u2019s share of the market had fallen to under 30 percent; in 1990, it had been more\nthan twice that. Again, competitive advantages in applications areas were undermined by the disadvantages of being outside the\n\nMicrosoft-Intel platform of CPUs, operating systems, and hardware.\n\nCONCLUSIONS\n\nThese abbreviated treatments of components and applications software are merely suggestive, not definitive. A thorough investi-\ngation of these segments would need the same detail as devoted to hardware, software, and CPU chips. We include them to drive\nhome a point about applying strategic analysis. It is always best to begin simply and only add complexity as required. Undue com-\nplexity creates an intractable picture of the forces at work. The diagram in figure 4.5 was produced by and for John Sculley and\nthe rest of Apple management in the early 1990s. It was intended to describe the structure of the information industry, but the\nresult was too complicated to be useful. Apple went everywhere and nowhere. For the year ending September 2003, its sales were\nstill down more than 40 percent from 1995 and it earned no operating income. For all of Steve Jobs\u2019s brilliance and the elegance of\nApple\u2019s product design, it seems consigned to always push uphill against the advantages of Microsoft and Intel. In the PC industry,\n\nApple is going nowhere.\n\f"}, "002988.png": {"text": " \n\f"}, "002989.png": {"text": "FIGURE 4.5\nThe Apple vision\n\nIn the approach we recommend here, the central question is whether, in the market in which the firm operates or is considering\nentering, competitive advantages exist. If they are present, what are they and who has them? We have described two tests for their\nexistence: stable market shares and a high return on investment for the dominant incumbent firms. To keep the analysis manage-\nable, our advice is to move one step at a time. Begin with one force\u2014potential entrants/barriers to entry\u2014not five. Start simply and\nadd complexity later. Whenever things become confusing, step back and simplify again. Clarity is essential for strategic analysis.\nFinally, \u201cthink local.\u201d Whatever historical promise existed in Apple\u2019s strategic position lay in the segment of desktop publishing\nand other graphic-intensive applications. It had virtually no chance in taking on the broad PC industry, and it has no chance of\n\ndoing so today.\n\f"}, "002990.png": {"text": "CHAPTER 5\n\nBig Where It Counts\n\nWal-Mart, Coors, and Local Economies of Scale\n\n\u2018WAL-MART: NEW WORLD CHAMPION\n\nIn four decades, the Wal-Mart juggernaut rolled out of small towns in Arkansas to become the largest retailer in the world. By any\nmeasure, it has been one of the greatest successes in business history. It is also the most compelling example of how a strategy\nbuilt on a local focus can produce a company that dominates both its original market and neighboring ones into which it expands.\nSam Walton and his brother Bud began to build their empire in 1945 as franchisees of the Ben Franklin variety store with a single\noutlet in Newport, Arkansas. Twenty years later they moved into the discount store field, convinced that rural America could sup-\nport the same kind of full-line, low-priced stores that had become popular in larger cities. They were correct. When the company\nwent public in 1970, Wal-Mart owned 30 stores, all located in small towns in Arkansas, Missouri, and Oklahoma. At the end of\n\n1985, it had grown to 859 discount stores in twenty-two states. By the year 2000, Wal-Mart sold more merchandise than any other\n\f"}, "002991.png": {"text": "retailer, anywhere. It had over 3,000 stores in the United States and Puerto Rico\u2014no state was without a Wal-Mart\u2014and more\nthan 1,000 stores in eight foreign countries. Its sales of $191 billion were almost twice the combined sales of Kmart, Sears, and\nJcPenney, other retailing giants.\n\n\u2018Wal-Mart\u2019s arrival in a new area made existing store owners quake, as well they might. Though zoning laws and other regu-\nlations occasionally stalled the company or forced it to adjust its plans, Wal-Mart's thrust was as inexorable as the waves and as\nfutile to resist.\n\nThe growth in sales over these thirty years was more than matched by the performance of Wal-Mart\u2019s publicly traded shares.\nIts market value was $36 million in 1971; it was $230 billion in early 2001.: At that level, Wal-Mart was worth fourteen times the\ncombined market value of Sears, Kmart, and JCPenney. The reason is simple: it was more profitable and more reliable. In 2000, not\na bad year for the other companies, they reported combined net income of $2.2 billion. Wal-Mart earned $5.4 billion. A year later,\nwhen Wal-Mart earned $6.3 billion, the others could muster only $394 million. See figure 5.1.\n\n\u2018Wal-Mart managed to combine sustained growth with sustained profitability in one of the most competitive industries in the\neconomy. Each of the three other companies we have used as a benchmark was itself a leading merchant for an extended period,\nonly to be eclipsed by Wal-Mart. When a company has been this successful in this kind of competitive environment, with no\npatents, government licenses, or years of productive research and development to keep would-be contenders at bay, any student of\n\nbusiness strategy wants to identify the sources of its success.\n\f"}, "002992.png": {"text": "$10,000\n\n2\n3 \u2018\n\u00ae $100\n$10\n$1\n1971 1976 1981 19% 91 1996 2001\nee Wal-Mart \u2018Total of others\n\n \n\nFIGURE 5.1\nNet income of Wal-Mart compared with Sears, Kmart, and JCPenney ($ million)\n\f"}, "002993.png": {"text": "First, we need to confirm the premise. Has Wal-Mart\u2019s record been an unalloyed triumph, or have there been blemishes that\nmay have been overlooked? Then we can ask what Wal-Mart did that the other retailers were unable to duplicate, and we may be\nable to identify strategic choices that Wal-Mart might pursue to maintain and extend its superior performance. Finally, we can ask\n\nwhat Wal-Mart\u2019s success says about the possibilities facing other companies.\n\nINDUSTRY ANALYSIS\n\nAn analysis of the retail industry in which Wal-Mart operates is straightforward (figure 5.2). Stores sell directly to household\nconsumers. Upstream, Wal-Mart and its competitors are supplied by manufacturers of everything from soft drinks to washing\nmachines, from blouses to lawn mowers. These companies range from the makers of famous national brands like Coca-Cola, to\ncontractors who make private-label products for the retailers, to small local suppliers of nameless merchandise. Wal-Mart sells\nsuch a broad range of goods that it competes on some products with virtually every other retailer. Still, the demarcations between\nindustries along the supply chain are distinct; the names do not carry over from one sector to another. Like most other retailers,\n\u2018Wal-Mart does little or no manufacturing.\n\nThe number of competitors that Wal-Mart faces within the industry suggests that the perspective we should apply, at least\ninitially, is what we have called \u201carmy of the ants,\u201d a situation in which competitors are so numerous that none of them tries to\nanticipate how others will respond to its actions. As Wal-Mart grew and became an elephant among these ants, it did not need to\n\nworry about what any of the individual ants might do, but they certainly had to be nimble to avoid being squashed.\n\f"}, "002994.png": {"text": " \n \n \n     \n     \n   \n       \n   \n\nMANUFACTURERS RETAILERS CONSUMERS\n\n   \n\nProcter & Gamble\n\nWalMart\n\nCoca-Cola Kmart\nHanes Sears\nWhirlpool Target\nJohnson & Johnson Kroger's\nCasio Home Depot\nMany, many others Amazon.com\nBest Buy\n\n \n\nMom and pop stores\n\nFIGURE 5.2\nMap of the retail industry\n\n\u2018WAL-MART'S PERFORMANCE: FROM GREAT TO GOOD\n\nWe know that Wal-Mart became the giant while some former retailing heavyweights sputtered or disappeared. It must have been\ndoing something right. But what, exactly? How did Wal-Mart grow and prosper, while the others were mediocre at best?\n\nBefore we start to answer that question, we should examine in detail Wal-Mart\u2019s performance over time. We can do that by\nlooking at two measures of performance: operating margins and return on invested capital. Operating margins (earnings before\ninterest and taxes, divided by net sales) are most revealing when comparing firms within the same industry, because they are\n\nlikely to have similar requirements for capital. Return on invested capital (how much the company earns on the debt and equity it\n\f"}, "002995.png": {"text": "needs to run its business) is useful as a measure of performance between industries as well as within them. (We are using the pre-\ntax return on invested capital.) Both of these ratios are driven by operating profit and so should track one another. If they do not, it\nis probably a sign that there have been changes in the way the business is financed.\n\nBy comparing Wal-Mart with Kmart over the period 1971-2000, we can see that Wal-Mart was indeed the superior business\n(figure 5.3). Its margins exceeded Kmart\u2019s starting in 1980, when it was only about one-tenth the size of its older rival. The return\non invested capital has a similar history. Wal-Mart did better than Kmart when it was still the much smaller company, and its per-\n\nformance was continually better from then on (fig. 5.4), with Kmart filing for Chapter 11 in January 2002.\n\n \n\n \n\n \n\n1970 1975 1980 1985 1990 1995 2\n\nsees Wal-Mart \u2014\u2014Kmart\n\f"}, "002996.png": {"text": "FIGURE 5.3\nWal-Mart and Kmart operating margins 1970-2000\n\nThe graph reveal a second pattern, potentially more revealing than the Wal-Mart-Kmart comparison. Wal-Mart\u2019s most\nprofitable years, measured by return on sales and on invested capital, ended sometime in the mid 1980s. Its operating margins\nreached a peak of 7.8 percent in 1985 and then fell continually to a low of 4.2 percent in 1997. Return on invested capital followed\nsuit. The years of truly high returns on investment ended in the early 1990s. After that, Wal-Mart\u2019s ROIC eroded, to stabilize ina\nrange from 14 to 20 percent, pretax, respectable but not exceptional. Given this decline, we need to ask not only what set Wal-Mart\napart from its competitors, but also what changed in its own operations that shifted it from an outstanding company to a less ex-\nceptional, though enormous, one. We start by looking first at Wal-Mart in its golden years around 1985, when its profitability was\n\nat apeak.\n\f"}, "002997.png": {"text": " \n\n1970 1975 1980 1985 1990 1995\n\nwoe Wal-Mart \u2014 Kmart\n\nFIGURE 5.4\n\n\u2018Wal-Mart and Kmart pretax return on invested capital, 1970-2000\n\nWal-Mart in the 1980s\n\f"}, "002998.png": {"text": "In these years Wal-Mart was a regional powerhouse. It ended the year 1985 operating 859 discount centers in twenty-two states.\nMore than 80 percent of the stores were located in eleven states radiating from its Arkansas headquarters. Wal-Mart serviced them\nfrom five warehouses; few of the stores were more than three hundred miles from any distribution center. It used its own trucks\nto pick up much of the merchandise it purchased and transport the goods to the distributions centers, from which they were\ndispersed on other trucks to the stores. The system was efficient. The concentration of stores allowed one truck to serve several of\nthem on the same trip, and to pick up new merchandise from vendors while returning to the warehouse.\n\n\u2018Wal-Mart\u2019s expansion in the ten years to 1985 was aided by the rapid population growth of its region, especially in the smaller\ntowns and cities that were its choice locations. The company was sailing with the wind. But Kmart and other retailers could read\ndemographic statistics. They were determined to share in some of the opportunities that a growing population affords. By 1985,\nKmart stores were competing in more than half of Wal-Mart towns. Still, even at that date, one-third of Wal-Mart\u2019s stores had no\nlocal competition from other major discounters; they captured 10-20 percent of total retail sales in the area, an exceptional share.\n\nIn 1976 Wal-Mart had sales of $340 million. Over the prior five years it had grown at a compounded rate of 50 percent per year.\nIn 1981, sales were $1.6 billion, and the growth rate had been 37 percent. For 1986, the comparable figures were $8.4 billion and\n39 percent. This is rapid growth, and the decline in the rate after 1976 is hardly surprising, given how large the company had be-\ncome and how much of its region it had penetrated.\n\n\u2018Wal-Mart\u2019s executives, molded in the image of legendary founder Sam Walton, were men on a mission. Though they could not\novercome the gravitational drag that increased mass puts on the pace of expansion, they tried to grow their firm using one old and\none new strategy. The old strategy was geographical extension: spread from the center into adjacent territories, and build new dis-\ntribution centers to service the stores. This move would take the company eastward into Georgia, Florida, and the Carolinas, and\nwest and north into New Mexico, Nebraska, Iowa, and even Wisconsin.\n\nThe new strategy was diversification. Wal-Mart made a minor effort with hardware, drug, and arts and crafts stores, none of\nwhich developed into a significant part of its business. The real push came with a warehouse club format, which Wal-Mart called\n\n\u201cSam\u2019s Club.\u201d The concept did not originate with Wal-Mart, nor was it the only retailer to find the format attractive. A warehouse\n\f"}, "002999.png": {"text": "club store was\u2014and is\u2014very large, it had bare-bones fixtures, it stocked a limited number of items in depth, and it sold its goods\nfor 20 percent less than supermarkets and discounters. To be profitable, the store needed to sell its merchandise very quickly,\neven before the bill was due. Only metropolitan areas with at least 400,000 people, of which there were around one hundred in\nthe country, could support that kind of turnover. As early as 1985, warehouse stores began to compete with one another in these\nchoice locations. Wal-Mart had twenty-three of them by the end of 1985, and had leased real estate to open seventeen more in\n1986. Because the Sam\u2019s Club financial results were not broken out in Wal-Mart\u2019s statements, it was difficult to tell how profitable\n\nthey were.\n\nFrom Net Sales to Operating Income\n\nDuring these years, Wal-Mart generated more income for each dollar of sales than did its competitors. To find out exactly where its\nadvantages lay, we should compare in detail the financial results of Wal-Mart with those of other discounters. Though the entries\non the income statement are the consequences, not the cause, of the differences in operations, they tell us where to look for expla-\nnations of Wal-Mart\u2019s superior performance.\n\nLet\u2019s begin with a side-by-side look at Wal-Mart and Kmart (table 5.1). For the three years ending January 31, 1987, Wal-Mart\nhad average operating margins of 7.4 percent; Kmart\u2019s were 4.8 percent. The difference was due entirely to much lower overhead\ncosts. As a percentage of sales, Kmart had a lower cost of goods sold, largely because its prices were higher than Wal-Mart's. But it\ndissipated this advantage by spending more, per dollar of sales, on selling, general, and administrative expenses (SGA).\n\nAreport on the discount retailing industry in 1984 gives us a more precise look at the components of operating costs and helps\npinpoint Wal-Mart\u2019s advantages (table 5.2). Since Wal-Mart itself was included in the industry totals, the differences between it\nand the other firms are understated. Still, the pattern here is similar to the comparison with Kmart. As a percentage of sales, Wal-\nMart paid more to buy and receive its merchandise than did the competition, again because it offered consumers lower prices. The\n\nother retailers brought in more revenue from licensed departments. Yet Wal-Mart ended up with higher operating profits thanks\n\f"}, "003000.png": {"text": "to its lower costs for all the activities that make up selling, general, and administrative expenses. Compared to the others, it rana\n\nvery tight ship.\n\nTABLE 5.1\n\nAverage operating margins, 1985-87 (percentage of sales)\n\nKmart Wal-Mart Wal-Mart's Difference\nNet sales 100.0% 100.0% 0.0%\nCost of goods sold 70.5% 74.3% 3.8% higher\nSGA total 24.7% 18.3% 6.4% lower\nOperating income 4.8% 74% 2.6% higher\n\nWhat accounts for this thrift? Can we attribute it to great management and a disciplined corporate culture? Was it simply the\nlower costs of doing business outside of major metropolitan areas and largely in the American South? Or should we look at more\nstructural economic factors that may be less subject to managerial control?\n\nIf the answer is management and corporate culture, then there is nothing that inhibits Wal-Mart from replicating its success\nanywhere, and from extending it beyond the discount center format into a number of other similar businesses. If it is the cost\ndifferentials of small-town and southern locations, then Wal-Mart should forget about moving into other parts of the country and\nlimit its growth to filling in its historical region. If, on the other hand, the explanation lies in some structural economic factors\nthat give Wal-Mart its competitive advantage, it ought to understand exactly what those are and design an expansion strategy that\ntargets regions and retailing formats where those advantages can be reproduced. And its competitors, current or potential, or any-\n\none in a business with similar characteristics, should clearly do the same thing.\n\f"}, "003001.png": {"text": "TABLE 5.2\n\nIndustry-wide comparisons, 1984 (percentage of sales)\n\n \n\nIndustry Wal-Mart jart\u2019s Difference\n\nNet sales 100.0% 100.0%\n\nLicense fees and other income 1.1% 0.8% 0.3% lower\nCost of goods sold 71.9% 73.7% 1.8% higher\nPayroll expenses 11.2% 10.1% 1.1% lower\nAdvertising expenses 2.3% 1.1% 1.2% lower\nRental expenses 2.2% 1.9% 0.3% lower\nMiscellaneous expenses 7.6% 5.3% 2.3% lower\nSGA total 23.3% 18.4% 4.9% lower\nOperating income 5.9% 8.7% 2.8% higher\n\nAN ABUNDANCE OF EXPLANATIONS\n\nNo company with a history like Wal-Mart\u2019s escapes attention. Over the years, a number of explanations have been offered to ac-\ncount for its success. Some are clearly mistaken, some are more plausible but don\u2019t hold up under examination, and one dominates\n\nthe others. We will look at some of the most reasonable.\n\nExplanation 1: Beat Up on the Vendors\n\f"}, "003002.png": {"text": "Wal-Mart has had a reputation for using its muscle as a very big customer to wrest price concessions from its suppliers. A lower\ncost of goods might translate into higher profit margins. But we have already seen that Wal-Mart had a higher cost of goods sold\nthan its competitors, so we should be skeptical about this explanation. Also, Wal-Mart's gross profit margins did not increase as\nit grew larger. They were at their peak, at 28.3 percent, in 1983, and fell more or less steadily to rest under 22 percent in the mid\n1990s. So the bully factor does not seem to have been at work.\n\nThe amount a retailer spends on purchasing merchandise is the major part of the cost of goods sold figure, but there are\nother expenses that are also included (table 5.3). One is the cost of getting the goods from the vendor to the company\u2019s stores or\nwarehouses, known as \u201cfreight in\u201d or \u201cinbound logistics.\u201d The fact is that Wal-Mart was more efficient in this area than its competi-\ntors; it spent 2.8 percent of sales versus an industry average of 4.1 percent. It also lost less to \u201cshrinkage,\u201d a catch-all expression to\naccount for items that get lost, broken, or pilfered. The industry average was 2.2 percent against 1.3 percent for Wal-Mart. When\nwe incorporate these components into our analysis of cost of goods sold, they reveal that Wal-Mart was spending even more on\nmerchandise, as a percentage of sales, than the industry norms.\n\nThat Wal-Mart paid more for purchases as a percentage of sales does not entirely invalidate the argument that Wal-Mart used\nits bargaining power to extract lower prices from its suppliers. But if it indeed had the power to extract concessions, it passed those\nsavings and more on to its own customers. Given the variety of pricing in different markets, it is impossible to offer a solid figure\non how much less, overall, Wal-Mart charged relative to the other discount chains. When it went head-to-head with Kmart or Tar-\nget, its prices may have been 1-2 percent lower. When the stores were spaced at least five miles away, the differences were larger,\naround 8-10 percent. With two-thirds of Wal-Mart\u2019s stores in competitive markets, an overall pricing difference of around 4-5 per-\ncent seems reasonable. That figure happens to be very close to our estimate of how much more Wal-Mart paid for its purchases, as\na percentage of sales. If we make the realistic assumption that Wal-Mart paid the same, per item, as its major competitors, then its\npricing strategy accounts for its higher cost of goods sold figure. So lower prices from suppliers were not a source of greater profit\nmargins. Also, the fact that its costs of good sold went up even as Wal-Mart doubled in size every few years, and that early in this\n\nprocess, Kmart and other stores should have had much more clout with suppliers, undermines this argument.\n\f"}, "003003.png": {"text": "TABLE 5.3\n\nCost of goods sold comparison (percentage of sales)\n\nIndustry Wal-Mart Wal-Mart's difference\nCost of goods sold 71.9% 73.7% 1.8% higher\nInbound logistics 4.1% 2.8% 1.3% lower\nShrinkage 2.2% 1.3% 0.9% lower\nPurchases 65.6% 69.6% 4.0% higher\n\nFinally, it is not plausible to argue that Wal-Mart could muscle Coca-Cola or Procter & Gamble into giving better pricing to it\nthan other retailers. Imagine the soda buyer threatening to drop Coca-Cola unless Wal-Mart got a larger discount than its competi-\ntors. When Coke turns him down, how much leverage does he have left with Pepsi? With smaller, more regionally based suppliers,\n\u2018Wal-Mart probably did have bargaining power, and might have squeezed concessions from these vendors. But so could Kmart and\n\nthe others. The \u201cbargaining with the suppliers\u201d explanation for Wal-Mart's superior profitability doesn\u2019t stand up.\n\nExplanation 2: Small-Town Monopolist\n\nDid Wal-Mart owe its success to the fact that in many of its locations, it was the only store in town? Did it make these customers\npay higher prices and boost its earnings with these monopoly proceeds? To address this question, we ought to look at the com-\npany\u2019s pricing strategy and see how it differed from that of its competitors.\n\nFrom its beginning as a discount retailer, Wal-Mart prided itself on its low prices. All its discount stores proclaimed its slogan,\n\u201cWe Sell for Less.\u201d And so it did, especially in towns where it competed directly against Kmart, Target, and other discounters. A\n\n1984 survey found that in the Dallas-Fort Worth market, where the stores were separated by five miles or so, Wal-Mart's prices\n\f"}, "003004.png": {"text": "were 10 percent less than Kmart\u2019s, and 7-8 percent lower than Target\u2019s. In a St. Louis suburb, the difference with an adjacent\nKmart was 1.3 percent. But in those towns where it had the field to itself, Wal-Mart was less generous with its customers. It\ncharged 6 percent more in Franklin, Tennessee, than it did in Nashville, where a Kmart offered shoppers an alternative. Kmart\u2019s\ndifferential between the towns in which it competed and those it had to itself was even greater, around 9 percent. But while Kmart\nand the other discounters operating in Wal-Mart country had around 12 percent of their stores in single-store towns, Wal-Mart\nhad 33 percent. See table 5.4.\n\nIf we put all these differences together, it becomes clear Wal-Mart did milk some income out of the higher prices it charged in\nits monopolized towns. The overall differences with Kmart added around 0.9 percent to Wal-Mart\u2019s operating margin advantage.\nThis was around one-third of its total operating margin advantage of 2.8 percent (see table 5.2). It is part of the explanation, but\nfar from the whole. Moreover, as we noted earlier, Wal-Mart\u2019s average prices were 4-5 percent below those of its competitors. The\nextra 1 percent margin Wal-Mart extracted from one-store towns accounts for only a fraction of this gap. On balance, the one-\nstore-town advantages were more than offset by Wal-Mart\u2019s \u201ceveryday low price\u201d policy. They do not explain Wal-Mart\u2019s overall su-\n\nperiority in performance.\n\nTABLE 5.4\n\nBenefits of monopoly\n\nKmart Wal-Mart Wal-Mart's\n\nDifference\nExtra margin company charged in single-store towns 9.0% 6.0%\n\nPercentage of company\u2019s stores in single-store towns 12.0% 33.0%\nTotal margin increase from single-store towns 1.1% 2.0% 0.9% higher\n\f"}, "003005.png": {"text": "Explanation 3: Better Management, Better Systems\n\n\u2018Wal-Mart has had a well-deserved reputation for excellent management. It was an early adopter of technologies like bar-code\nscanning, a major productivity tool. Using scanners reduced the lines at checkout counters while helping to control inventory and\nautomate the reordering process. The heavy capital investment of $500,000 per store did not stop Wal-Mart from moving quickly\nto install these machines in new stores and fitting them into existing ones. Investments like this had helped to lower the cost of\nlabor, both salary and wages, from 11.5 percent in the late 1970s to 10.1 percent in 1985.\n\nBut electronic scanning was an industry-wide technology. Kmart moved almost as rapidly to introduce scanners, and also\nplanned to have them throughout its stores by 1989. Target and the other discounters used the machines. So whatever benefits\n\u2018Wal-Mart achieved from its investments here did not account for its advantages over its competitors. The same was true of other\nsophisticated systems it introduced, like software to plan the merchandise mix in each store or machinery to automate warehouse\noperations. Wal-Mart was a purchaser of these technologies, not a developer of them. Anything it bought, its rivals could buy as\nwell. Its progressive stance may have given it some short-term leads over the others, but they may have benefited by hiring the\nsame consultants to do the installations, who now had Wal-Mart\u2019s experience, including the inevitable mistakes, on which to\ndraw.\n\nIn the area of human resources management, Wal-Mart did have a claim to superiority. Its executives spent much of their time\nin the stores. They solicited the opinions of employees\u2014called associates, to reflect the \u201cwe're all on the same team\u201d philosophy\nof the company\u2014on what goods to carry and how to display them. It had incentive programs that rewarded store managers for\nexceeding profit targets, and it lowered the rate of pilferage and shoplifting by sharing any reductions with the employees. The\nemployees responded by endorsing Wal-Mart as a good place to work, despite salaries that were modest, even by the standards of\nthe industry. Part of Wal-Mart\u2019s lower payroll expenses was probably attributable to these good human resource practices.\n\nSo while it is unwise to ignore the importance of better management in accounting for Wal-Mart\u2019s success, we should not make\n\ntoo much of it. Did management deteriorate after the golden days of the mid 1980s, or did its tasks become more difficult? Why\n\f"}, "003006.png": {"text": "did their management techniques not work when applied to hardware, drug, and arts and crafts stores? And Sam\u2019s Club stores,\nalthough they have multiplied in number, have not produced the same stellar results as the traditional discount centers. When\n\u2018Wal-Mart began to report financial information by segment, in the mid 1990s, Sam\u2019s Clubs were considerably less profitable. They\nearned about 45 percent less per dollar of assets allocated to them than did the discount centers. And this was after fifteen years of\n\nexperience with this format, time enough to work out the kinks.\n\nExplanation 4: Things Are Cheaper in the South\n\n\u2018Wal-Mart had lower rental (by 0.3 percent of sales) and payroll expenses (by 1.1 percent of sales) than the industry averages. Part\nof these advantages may have been due to its concentration in the South, and in the smaller towns and cities of that region. Real\nestate was cheaper to develop and property taxes were lower there. None of Wal-Mart\u2019s workers was represented by a union, also a\nSouthern characteristic. The savings on these two items represented 1.4 percent of sales, a hefty portion of Wal-Mart\u2019s total advan-\ntage of 4.9 percent for all SGA expenses. On the other hand, prices as well as costs tended to be lower in the South.\n\nIt is impossible to refine the analysis enough to say how much was due to the southern factor. Clearly location had something\nto do with these differences. But so did good management, as we have seen. The problem for Wal-Mart, circa 1986, was that op-\nportunities for expansion in this lower-cost part of the country were limited. It had already begun to move into larger towns and\ncities. After 1986, much of its growth was in states far removed from its southern roots. By 2001, California, Ohio, Pennsylvania,\nIndiana, New York, and Wisconsin accounted for six of the top eleven states measured by the number of discount stores and\n\nsupercenters.\n\nExplanation 5: The Potent Advantages of Regional Dominance\n\n\u2018Wal-Mart did have geography working for it, the geography of market concentration. We have seen that in 1985, more than 80\npercent of its stores were in Arkansas, adjacent states, or their immediate neighbors. Though much smaller than Kmart overall, it\n\nwas far larger in its home territory. Kmart had its own area of concentration in the Midwest, but any benefits it might have derived\n\f"}, "003007.png": {"text": "from this regional strength were diluted by its lower density in other parts of the country. Wal-Mart, by contrast, was able to make\nthe most of its strategy of concentration, which accounts for most of its superior profitability.\n\n\u2018Wal-Mart enjoyed a competitive advantage in this period, based largely on the combination of economies of scale with some\nlimited customer captivity. Both the economies and the captivity are regional, not national or global. For retailing, distribution,\nand other industries in which most of the costs of reaching the final consumers are at the local and regional levels, these are the\neconomies and preferences that matter.\n\nThe lower costs derived from Wal-Mart\u2019s concentration strategy came primarily from three functions of the business. First, it\nspent less on inbound logistics, the costs of bringing goods into its warehouses and sending them on to the discount centers. We\nhave described Wal-Mart\u2019s system of locating warehouses to supply stores within a three-hundred-mile radius and of using its\nown trucks to pick up merchandise from vendors who had placed their own distribution centers in the region to serve Wal-Mart.\nThe density of Wal-Mart stores, as well as their proximity to a distribution center, reduced the distances its trucks had to travel and\nallowed them to carry goods on both routes, from vendors to distribution centers and from the centers to the stores. Wal-Mart\u2019s\nadvantage in this area, over the industry average (which included Wal-Mart\u2019s results and thus reduced the difference), was 1.3 per-\ncent of sales.:\n\nSecond, Wal-Mart's advertising expenses were lower than the average, by 1.2 percent of sales, corresponding to a relative cost\nadvantage of over 60 percent. For retailers, advertising is local. The newspaper ads, the inserts and circulars, and the television\nspots were all targeted at potential customers for the stores in their vicinity. If we make the reasonable assumption that Wal-\nMart and the other discounters did roughly the same amount of advertising, measured by frequency of newspapers ads, television\nspots, and circulars, then Wal-Mart\u2019s lower costs as a percentage of sales were due to the greater density of its stores and its cus-\ntomer base in the markets in which it did advertise. The television station running a thirty-second spot in Nashville charges the\nsame whether there are three Wal-Mart stores in the area or thirty. The same arithmetic holds true for newspaper ads or circulars\nsent to all residents in the vicinity. The media sell their services on the basis of cost per thousand people reached. For a retailer, the\n\nmore relevant number is cost per customer, or potential customer, and that depends on penetration in the market. Since Wal-Mart\n\f"}, "003008.png": {"text": "had almost three times the level of local sales of its competitors, its advertising cost per dollar of sales would have been one-third\nthat of the competitors. The same strategy of concentration that served Wal-Mart well by keeping down its inbound logistics costs\nalso worked to contain advertising expenses. It got more bang for its buck because its advertising targeted its customers more\neffectively than did its competitors\u2019.\n\nThe final function in which Wal-Mart had a cost advantage over competitors was managerial oversight and supervision.\n\nFrom the start, Sam Walton and his executives paid close and continual attention to the stores with frequent visits. By 1985, the\ncompany employed twelve area vice presidents; each had seven or eight district managers reporting to them. The vice presidents\nlived near company headquarters in Bentonville, Arkansas, where they attended meetings every Friday and Saturday to review\nresults and plan for the next week. Every Monday morning, all the vice presidents flew into their respective territories, where they\nworked the next four days visiting the stores for which they were responsible. The system functioned well for Wal-Mart. It pro-\nvided abundant communication between the center and the periphery. The concentrated territories meant that the managers had\nmore time to spend in the stores rather than driving between them. The flow of information moved in both directions. Company\npolicy ensured that the store managers and employees even further down the chain of command could make their views and ideas\nknown to management.\n\nThe system depended on the density of Wal-Mart stores and their proximity to Bentonville. To supervise the same number of\noutlets, a Kmart or Target executive had to cover a territory three or four times as large. They could not visit their stores so fre-\nquently or spend as much time when they were there. They had to live in the area and needed support from a regional office. The\nadditional expense may have consumed 2 percent of net sales, an enormous bite when operating profits were only around 6 per-\ncent. The difference between Wal-Mart and the others (found on the \u201cMiscellaneous expenses\u201d line of table 5.2) is about 30 percent\n(2.3 percent divided by 7.6 percent), again a strikingly large relative cost advantage. Wal-Mart was able to do more with less, the\noften stated but seldom realized goal of managers everywhere.\n\nThe superior efficiencies Wal-Mart achieved in these three functions\u2014inbound logistics, advertising, and executive supervi-\n\nsion\u2014taken together, gave the company an operating margin advantage of 4-5 percent of net sales. Wal-Mart\u2019s total advantage was\n\f"}, "003009.png": {"text": "only around 3 percent. Because the lower prices it charged pushed up Wal-Mart\u2019s purchases, in percentage terms, various operat-\ning savings could account for more than the entire difference in margins.\n\nThe superior efficiencies in these three functions were due to local economies of scale. The relevant localities are the areas in\nwhich Wal-Mart and its competitors had their stores, their warehouses, their advertising campaigns, and their managers. It made\nno difference that Kmart\u2019s total sales were three times those of Wal-Mart in these years (1984-85). Those were numbers national\nand international, and thus not relevant. They had little bearing on the physical movement of goods, on advertising designed to\nreach the customers who shopped in their stores, or on the supervision the company employed to manage its retail operations. For\neach of these, what mattered in achieving economies of scale were the number of stores and customers within the relevant bound-\naries. Measured in this way, Wal-Mart was bigger than its competitors. It had more stores and customers in its region than they\ndid, without doubt, and it had a higher density of stores and customers in its region than its competitors had in theirs. So even\n\nwhen it was still relatively small, high geographic concentration meant high profitability for Wal-Mart.\n\nRETAILING, CUSTOMERS, AND ECONOMIES OF SCALE\n\nIn our discussion of the competitive advantage of economies of scale, we noted that two conditions have to hold in order for a com-\npany to reap benefits from these economies. First, the fixed costs it incurs must account for a large share of total costs, with the\nmeasure of \u201clarge\u201d related to the size of the market in which the company operates. These fixed costs can be capital investments\nlike plant, equipment, or information technology. They can be operating expenses like advertising or managerial supervision. As\nthese fixed costs are spread over more sales, average costs continue to decline. The company selling the most is ahead of the game.\nBut if the market is sufficiently big, the share of fixed costs in each unit can become so small that the average costs stop de-\nclining. Then other companies, although their sales do not equal those of the largest firm, can come close to matching its average\n\ncost, and the advantage dissipates. Clearly, economies of scale persist only so long as the decline in fixed costs for the last unit sold\n\f"}, "003010.png": {"text": "is still significant. In bigger total markets, there are fewer relative economies of scale. In this sense, growth may be the enemy of\nprofitability.\n\nSecond, the competitive advantage of economies of scale has to be combined with some customer captivity in order to keep\ncompetitors at bay. Kmart could have duplicated Wal-Mart's retailing infrastructure\u2014its stores, distribution centers, and man-\nagement\u2014within Wal-Mart\u2019s home territory, but it would not have achieved the same economies of scale unless it attracted an\nequivalent number of customers. That required taking customers away from Wal-Mart. Not an easy task, provided that Wal-Mart\nhad not undermined its customers\u2019 loyalty with shoddy service, high prices, or other bad practices. Otherwise, customers had\nno reason to switch to Kmart, everything else being equal. If Kmart tried to compete on price by cutting its margins to the bone,\nor even into the bone, Wal-Mart would match the reductions. Given the larger share of customers with which it started, its costs\nwould be lower and its pain more manageable. More advertising, in-store promotions, 0 percent interest charges on its own credit\ncards\u2014any competitive move Kmart might devise, Wal-Mart could match, and at lower cost. Unless it decided on a scorched-earth\nstrategy of winning market share no matter what damage it might inflict on itself, in the hope that Wal-Mart would blink and cede\ncustomers before Kmart was permanently crippled, there was nothing Kmart could do that would make it the equal of Wal-Mart\n\nwithin the region.\n\n\u2018WHAT DID HAPPEN?\n\nWhat happened is clear. Wal-Mart continued to grow after 1985 until it became the largest retailer on earth, the company feared\nand admired by firms around the world. But it also became considerably less profitable, measured by return on invested capital\nor the operating margins it earned on its revenue. The only explanation we find convincing to account for the shrinking returns\nis that, as it expanded across the country and overseas, it was unable to replicate the most significant competitive advantage it\nenjoyed in these early years: local economies of scale combined with enough customer loyalty to make it difficult for competitors\n\nto cut into this base.\n\f"}, "003011.png": {"text": "When it moved into California and the rest of the Pacific Coast, it had to compete directly with Target, another successful\ndiscounter with an established presence in the area. In the Midwest, Kmart was strong. In the Northeast, Caldor had a number\nof stores, and although it ultimately disappeared, that was a consequence of its own expansion strategy. At best, Wal-Mart had\nto compete on a level playing field when it moved beyond its home region; at worst, it was the player against whom the field was\nslanted.\n\nFrom the start, Wal-Mart has had excellent management, certainly better than Kmart, Sears, and JCPenney, other giants during\nthis era, and better by far than Caldor, Ames, E. J. Korvette, W.T. Grant, Bradlees, and other one-time successes that have vanished.\nThe executives adopted and implemented new technology; they spent much of their time in the stores, listening to employees and\ncustomers; they kept overhead costs low; they rarely needed to take \u201cspecial charges\u201d on their income statements, which area sign\nof prior mistakes growing too large to ignore. But management of this quality, sustained over four decades, could not keep margins\nor return on capital at the levels they reached during the mid 1980s. They did not earn exceptional returns on Sam\u2019s Clubs, the\nleast geographically concentrated of the wholesale club chains, or the other diversification efforts. By the late 1990s, Wal-Mart\u2019s\nmargins and return on capital were no better than those of Target, another successful discount merchant with one strong region\nof its own.\n\nThe pattern of Wal-Mart\u2019s returns both over time and across market segments tends to confirm this story. As Wal-Mart began\nits aggressive national expansion in the mid 1980s, returns on sales and on capital declined steadily. By the mid 1990s, when Wal-\nMart was a national institution, but with less regional concentration than it had had in its golden days, returns bottomed out at\n\naround 15 percent on invested capital. Then, as Wal-Mart added density by filling in the gaps, returns began to recover. The ex-\n\n  \n\nception to this pattern was the international division, where Wal-Mart was widely dispersed across many countries. As we would\nexpect, international returns on sales and capital appear to have been only about one-half to one-third those of the core U.S. super-\ncenter business.\n\nWhat might Wal-Mart have done in 1985 to maintain the high level of profitability and still grow its business? Probably not\n\nmuch. At the time, product line diversifications held little promise, although Wal-Mart has since been successful in adding gro-\n\f"}, "003012.png": {"text": "ceries. As to geographic expansion, it would have had a difficult task finding a territory that had the same important features as\nits Arkansas-centered stronghold. The small-town and rural demography were not directly significant; Wal-Mart and Target drew\ncustomers in metropolitan areas. What did matter was the absence of established competitors. These companies had overlooked\nArkansas and the region because they did not think it could support large discount stores. They did not overlook the West Coast,\nthe Southeast, or New England, making those regions less hospitable for Wal-Mart. If it had wanted to replicate its early expe-\nrience, Wal-Mart might have targeted a foreign country that was in the process of economic development but that had not yet\nattracted much attention from established retailers. Perhaps Brazil in the 1980s, or South Korea, would have fit the bill, provided\nthere were not insurmountable obstacles designed to protect local interests. But in the absence of the right virgin territory, Wal-\nMart seemed consigned to a \u201cgrowth at a price\u201d strategy, the price in this case being the lower returns it earned from its new in-\nvestments. We should not exaggerate the decline. Wal-Mart's return on investment has remained competitive. If it did not create\n\nenormous value for its investors, at least it did not destroy wealth by operating at a competitive disadvantage.\n\nTHE STRATEGIC DIMENSION AND LOCAL DOMINANCE\n\nAsummary look at the special qualities of Wal-Mart during its most profitable period allows us to compare the significance of the\ndifferent attributes that made for success (table 5.5).\n\nThere are several lessons to draw from this review:\n\n1. Efficiency always matters. Good management kept payroll costs and shrinkage substantially below the industry\n\naverages.\n\f"}, "003013.png": {"text": "2. Competitive advantages, in this case local economies of scale coupled with customer captivity, matter more. Good\nmanagement could not make Sam\u2019s Clubs a runaway success, nor could it prevent the deterioration of Wal-Mart\u2019s\n\nprofitability after 1985, nor assure success in international markets.\n\n\u00bb\n\n. Competitive advantages can enhance good management. In this case, Wal-Mart utilized its advantage of local\neconomies of scale by passing on a portion of its savings to its customers and by running a very tightship. It made\nefficient use of management\u2019s time, the scarcest of all company resources. Good management was welded to a\ngood strategy.\n\n4. Competitive advantages need to be defended. Wal-Mart's low-price approach was an intrinsic part of the local\n\neconomies of scale strategy, and not a separate policy choice. Other discounters like Kmart, Caldor, and Korvette\n\nall had profitable periods during which they took advantage of their local economies of scale. But in their drive\nto expand beyond their home turf, itself an ill-chosen strategy, they let competitors move uncontested into their\n\nlocal areas and lost on two fronts.\n\nTABLE 5.5\n\nSummary of Wal-Mart\u2019s cost advantages (as a percentage of sales)\n\f"}, "003014.png": {"text": "Income\nAttribute Statement Entry\nLower prices Purchase\nwith embedded costs\nlocal monopolies\nBetter Payroll costs,\nmanagement shrinkage\nLocal economies \u2014_ Distribution,\nof scale with advertising,\ncustomer other\npreference management\nTotal advantage\n\nIndustry\nAverage\n\n65.6%\n\n13.4%\n\n14.0%\n\nWal-Mart\n\n69.6%\n\n11.4%\n\n9.2%\n\nWal-Mart's\nDifference\n\n4.0%\nhigher\n\n2.0%\nlower\n\n4.8%\nlower\n\n2.8% lower\n\nThe significance of the Wal-Mart example is due to more than its size and prominence. What appears to have been true for Wal-\n\nMart\u2014that the crucial competitive advantage lies in local economies of scale\u2014applies to retail industries in general. Supermarket\n\nprofitability tracks closely with local market share. Successful chains like Kroger tend to be geographically concentrated. In drug-\n\nstores, Walgreen\u2019s\u2014the Wal-Mart of that industry\u2014has had a highly focused geographic strategy, and its returns appear to have\n\nfallen when it has relaxed that discipline. In home furnishings, even single-store operations, like Nebraska Furniture Mart, that\n\ndominate local areas are economic standouts.\n\nThe importance of geographic concentration applies beyond pure retail into services, at least to the extent that they are locally\n\nsupplied. Regional banks tend to be more profitable than national ones. HMOs like Oxford Health, with strong regional positions,\n\noutperform larger competitors with customers and providers dispersed nationally. In telecommunications, locally focused com-\n\f"}, "003015.png": {"text": "petitors in both landline and wireless, like Verizon, Bell South, and Cingular, have outperformed national competitors with more\ndispersed customer bases like AT&T, Sprint, MCI, and Nextel. If services are the wave of the future in economic evolution, then\n\nfirms would do well to make geographical dominance a key component of their strategy.\n\nCOORS GOES NATIONAL\n\nIn 1975, the year in which it became a public company, the Adolph Coors Company of Golden, Colorado, was near the top of its\ngame. It earned almost $60 million on sales of $520 million, a margin in excess of 11 percent. By comparison, that was more than\ntwice the net income margin of Anheuser-Busch (AB), which earned $85 million on sales of $1.65 billion. Unlike AB, which served\nanational market from ten breweries spread across the country, Coors operated one enormous brewery from which it sold its beer\nin Colorado and ten neighboring states. But the beer industry was evolving, and Coors decided to change with the times. Motivated\nin part by a ruling from the Federal Trade Commission, which charged it with restricting distribution, Coors began a geographical\nexpansion that brought it into forty-four states by 1985. That strategy was not a success.\n\nCoors did many things differently from the other large brewing companies. It ran a more integrated enterprise than its com-\npetitors. It made its own cans, grew its own grain, used water from its own sources, and generated electricity from its own coal.\nIts labor force was not unionized, and it put heavy emphasis on operating control and efficiency at its single, mammoth brewery.\nThe beer that it canned and bottled was unpasteurized, intended to give it a fresher, draftlike quality taste. Some of these features\ncontributed to a mystique that enticed celebrities like Paul Newman and Henry Kissinger to drink Coors despite the extra effort\nthey needed, as easterners, to get their hands on the beer. What marketing director would not pray for endorsements like this?\n\nCoors was different; that much seems certain. But did these differences make Coors better, not as a drink but as a business? And\nif they worked when Coors was a regional brewer in 1975, would they continue to provide Coors with advantages as it moved into\n\nanational market?\n\f"}, "003016.png": {"text": "From the vantage point of 1985, the answer to the second question is clear. Coors\u2019s sales more than doubled during the period;\nits earnings, on the other hand, did not keep pace. They were lower in 1985 than they had been in 1975, and its net income margin\nhad fallen to around 4 percent. During this same period, AB\u2019s position relative to Coors improved dramatically. Its sales increased\nmore than fourfold, and its net income margin expanded from 5 percent to 6 percent. And 1985 was not an aberration. Coors has\nnever been able to recover its competitive position. In 2000, it earned $123 million on sales of $2.4 billion, a 5 percent return. AB\u2019s\nprofits of $1.5 billion were more than 12 percent of its much larger revenue.\n\nWhat went wrong? What happened to Coors\u2019s operating efficiencies, its labor cost advantages? What about its mystique and\nits marketing expertise? Did they disappear as the company expanded, or had they been less significant contributors to its profits\nthan everyone, including the company, had assumed? And did Coors have an alternative? Could it have maintained its high level of\nprofitability by keeping its regional concentration, or would the forces of consolidation that rolled through the beer industry have\n\nreduced it to a small and inconsequential player, if it survived at all?\n\nTHE TASTE FOR BEER\n\nIn the forty years between 1945 and 1985, total beer consumption in the United States rose from 77 to 183 million barrels, a rate\nof slightly more than 3 percent per year. Population growth at around 2.5 annually percent accounts for most of the increase. This\nmodest rate suggests an intense competitive environment for brewers, not quite a constant-sum situation but close enough to\nmake one player\u2019s gain someone else\u2019s loss.\n\nThe organization of the brewing industry changed dramatically in the forty years from 1945 to 1985, with consolidation\nthe dominant feature. In 1950, the top four companies as a group had around 20 percent of the market. In 1985, they controlled\n\naround 70 percent. Most of the other movements were related to consolidation:\n\f"}, "003017.png": {"text": "+ Home consumption. At the end of World War II, kegs accounted for more than one-third of all beer sales. By 1985,\nthat figure had fallen to 13 percent of the total. Bottled beer and especially beer in cans had become much more\npopular. Part of this move reflected a decline in the tavern trade, as Americans left the bar stool for the domestic\ncomfort of the den. Coincident with this change, the many local breweries that had emerged after the end of\nProhibition were increasingly pushed aside by regional and national firms. It was the local beer makers who sold\nmore of their output in kegs, without pasteurization, to bars and restaurants. As that part of the market declined,\nso did the fortune of the locals. Many names disappeared entirely; others were bought and sustained for a time by\nsurvivors.\n\n+ Bigger plants. Advances in packaging technology raised the size of an efficient integrated plant (brewing and\npackaging) from 100,000 barrels per year in 1950 to 5 million in 1985. The smaller brewers could not justify\nbuilding plants of this size, and so lost out to their large competitors, especially AB and Miller, who built ever\nlarger plants, and more of them. By 1985, AB had eleven breweries, each of them able to brew at least 4.5 million\nbarrels annually.\n\n+ More advertising. In the struggle for share of the beer market, the brewers increased their spending on advertising.\nIt rose from $50 million in 1945, or 2.6 percent of gross sales, to $1.2 billion in 1985, a whopping 10 percent of\nsales. Television, which barely existed in 1945, gave the brewers a new place to sink their advertising dollars.\nThey took advantage of the medium and competed lustily to promote the advantage of their particular brand.\nThe advertising had little sustainable effect in winning customers, though it was popular with viewers and with\nthe networks. And it gave the national brewers one more advantage over the locals, in that the fixed advertising\n\ncosts were spread over a larger revenue base.\n\f"}, "003018.png": {"text": "+ More brands. In 1975 Miller introduced its Lite brand, lower in alcohol and calories than its premium High Life\nbeer. Before long all the other major breweries had their versions, and some also came out with superpremium or\nother variants of the flagship brand. Though the segmentation strategy did little to increase overall consumption,\nit did provide one more advantage to the big brewers over their small, local, and increasingly marginal competi-\ntors. The big players could afford the advertising costs of launching and maintaining the brand, and they had\n\nmore powerful names to exploit.\n\nThere were only two big winners in the consolidation process, Anheuser-Busch and Miller. In 1965 Miller\u2019s share of the indus-\ntry was an insignificant 3 percent. Twenty years later, with the brewer now run by the marketing geniuses at Philip Morris, it had\nlifted that portion to 20 percent. AB, the largest firm in 1965 with around 12 percent of the market, controlled 37 percent in 1985.\n\nThe rest of the beer makers had either disappeared altogether or played musical chairs with what was left.\n\nTHE COORS DIFFERENCES\n\nDuring this period of consolidation, Coors\u2019s share of the market remained stable at around 8 percent. It maintained its position\ndespite\u2014or perhaps because of\u2014an approach to the business that set it apart from all the other brewers. When it went national\nafter 1977, Coors counted on many of these differences to secure its success in the anticipated beer wars. First, Coors was vertically\nintegrated to a staggering degree. It had its own strain of barley grown for it by farmers under contract and it processed for itself a\nlarge portion of the other grains that went into the beer. It designed an all-aluminum can, which it purchased from a captive man-\nufacturer. In 1977, it bought its bottle supplier. It built much of its brewing and bottling equipment. Its much heralded \u201cRocky\nMountain spring water,\u201d which, it claimed, gave its beer superior drinking properties, came from land the company controlled. It\n\ndeveloped its own coal-field to supply its energy requirements.\n\f"}, "003019.png": {"text": "This vertical integration may have been symptomatic of a frontier preference for self-reliance. It did not produce a permanent\ncost advantage. In 1977, Coors\u2019s production costs were $29 per barrel, compared with $36.60 for AB. By 1985, Coors cost had risen\nto $49.50. AB, still not integrated, spent $51.80, not a major difference. In retrospect, it is difficult to imagine that any of these\nfunctions gave Coors a competitive advantage over the other brewers. In areas like packaging equipment, cans and bottles, and en-\nergy sources, Coors probably operated at a disadvantage, its smaller size allowing others to benefit from economies of scale. Also,\nthe attention of its managers, responsible for all these functions, was spread thin.\n\nSecond, Coors operated only one brewery, with an annual capacity that it had expanded from 7 million barrels in 1970 to 13\nmillion in 1975 and finally to 16 million in 1985. This giant plant had the potential for scale economies, at least in theory. Yet with\nthe efficient brewery size at around 5 million, it is unlikely that Coors reaped many economies of scale advantages from its behe-\nmoth that were not available to the other brewers. And its relative production cost figures confirm that whatever scale advantages\nexisted in theory did not materialize. Also, beer is heavy (even when it is Lite). The cost of transportation from one location, which\nwas not a problem when Coors was a regional firm, increased as Coors\u2019s distribution territory expanded. AB, with eleven breweries\naround the country, had shorter distances to travel and lower distributions costs.\n\nThird, unlike the other major brewers, Coors did not pasteurize even the beer it canned and bottled. It claimed that by selling\nonly \u201cdraft\u201d beer, it provided its devotees with a fresher-tasting drink. It also saved some money on the energy needed for pasteur-\nization, although that was balanced by the costs of keeping the beer cold and the facility sterile. Coors\u2019s nonpasteurization strategy\nmandated that it keep a tighter control over its beer as it passed from the brewery through the distribution channel to the con-\nsumer. Whatever the taste advantages, bottles and cans of Coors had a shorter shelf life than those of its rivals, and they had to be\nkept chilled, at least until they left the wholesalers\u2019 warehouses. These requirements added to its costs.\n\nFinally, there was in the 1970s a mystique about Coors that set it apart from its competitors. Perhaps it was the Rocky Mountain\nwater, perhaps the absence of pasteurization, perhaps the difficulty of getting the beer on the East Coast. For whatever reason,\nA-list people like Henry Kissinger, President Gerald Ford, and actors Paul Newman and Clint Eastwood made Coors their beer of\n\nchoice and took pains (or had pains taken) to keep a supply on hand. Their preference for the beer overcame whatever aversion\n\f"}, "003020.png": {"text": "Newman, at least, may have had for Coors\u2019s antiunion labor practices. What makes Coors\u2019s aura all the more impressive is that\nthere is so little to distinguish its taste from those of Budweiser, Miller High Life, or even some of the lower-priced local brands.\nThe aura did not encourage or allow Coors to charge more. It collected $41.50 per barrel in 1977; AB took in $46. And AB was still\n\ngetting slightly more in 1985.\n\nDISTRIBUTION WIDENS, PROFITS SHRINK\n\nBy 1985, beer drinkers could buy Coors in forty-four states. Broadening its geographical reach was expensive. All the beer still\ncame from Golden, Colorado; to keep it fresh, the company used refrigerated railcars and trucks. The longer shipping distance,\nfrom a median of eight hundred miles in 1977 to fifteen hundred in 1985, cost the brewer money that it could not pass on to con-\nsumers. It also needed a wholesaler network in its new territories. Because Coors had a much lower share of these new local mar-\nkets than its established competitors, it had to settle for weaker wholesalers, the only ones who would agree to carry Coors as their\nleading brand. They were more of a drag than a source of strength as Coors tried to compete in new regions with AB and Miller. The\nbrewer also had to ratchet up its marketing expenses, spending more for promotions and advertising to help it get established and\nalso to keep up with the other companies, who were raising their marketing budgets. Unfortunately for Coors, this effort was di-\nluted by being spread over a much larger geographical base. It was spending more to accomplish less.\n\nTable 5.6 indicates the extent to which Coors transformed itself from a regional powerhouse to a diffused and weakened also-\nran. In 1977, it controlled 8 percent of the national beer market by concentrating its forces in three regions. In two of these, it\nwas the biggest seller. In the three Pacific Coast states, it competed more or less evenly with AB. Since Coors sold virtually no beer\nin Oregon or Washington, it was almost certainly the largest presence in California. Eight years later, its national market share\nwas still 8 percent, but now it trailed AB in every region, including its home base in the mountain states. The three top regions\naccounted for 58 percent of its sales, down from 93 percent in 1977. Expansion meant dispersion, and dispersion was a blow to\n\nprofitability. Part of the problem was slow sales growth. It sold 14 percent more beer in 1985 than in 1977. AB's sales, by contrast,\n\f"}, "003021.png": {"text": "\u2018were up more than 80 percent. But here again, dispersion hurt Coors. Its three biggest regions in 1977 had grown by 23 percent in\nthese years. Coors had not even kept pace.\n\nThe price of expansion is evident in even a cursory look at Coors\u2019s income statements for 1977 and 1985. Again, the compari-\nson with AB is telling (table 5.7). Even though its cost of goods sold declined in these years, from 70 percent to 67 percent of sales,\nadvertising and other overhead costs increased enough to reduce Coors\u2019s operating income from 20 percent of sales to 9 percent\nin 1985. For AB, profitability went up. It lowered its cost of goods sold enough to move its operating income up to 15 percent. The\nentire difference between AB and Coors lies in advertising. AB spent almost three times as much in total, but $4 less per barrel, a\nsignificant advantage thanks to an economy of scale. It\u2019s good to be the king of beer.\n\nRegional economies of scale in the beer business are potent. Advertising costs tend to be fixed on a regional basis. There are\nsmall discounts to the national advertiser\u2014around 10 percent\u2014but they do not compensate for the difference in advertising costs\nper barrel between a brewer with a 20 percent local market share and one with an 8 percent local share. Distribution costs also\nhave a significant fixed regional component. Truck routes are shorter and warehouse use is more intensive for a company with\na large local share. These costs, embedded in the cost of goods sold line, are especially significant for a heavy product like beer.\nIndeed, of the $200 retail cost per barrel in 1985, the beer itself accounted for $70. Distribution costs, including profits for whole-\nsalers and retailers, were $110. And there were no secret production technologies that might have allowed one brewer to gain any\n\nmeasurable advantage over the competition.\n\nTABLE 5.6\n\nAnheuser-Busch and Coors, market share by region, 1977 and 1985 (sales by millions of barrels)\n\f"}, "003022.png": {"text": "197\n\n% of\nTotal AB's AB's % Of AB's Coors's Cocrs\u2019s Coors's\nSales Sales Share Sales Sales Share Sales\n\nNew England 74 20-27% \u00abBM % 0%\nSoutheast 182 64 \u00ab5% 17% % =\nEastNorth Centrl 22.8 3.6 16% = 10% A 0%\nWestNorh Central 122 2.7 2% > O89 Me 7%\nWestScuth Central 173 3.0 17% == BT 219 28H\nMountain 84 22 28% 6% 31 7% 24\nPacific 214 6.08% \u00ab16% 2440\nNoereperting\n\nand export 538 109 20% 30% Pe O%\nTotal 161.6 968 23% 100% 128 9% 100%\n\u2018Top 3 regions Bs 6% = 11.9 99%\n\n1995\n% of\nTotal AB's AB's %OfAB's Coors\u2019s Cocrs's Coors's\nSales Sales Share Sales Sales __Share_ Sales\n\nNew England 78 35 \u00ab45% =H 1H\nSoutheast 255 114 45% \u00ab17% LT MOH\nEnstNorth Central 24.0 68 = 24% MH HHH\nWestNonh Central 19.0 44 94% =. HTH\nWestScuth Central 22.1 75 34% \u00ab11% = 321422\nMountain 10.7 44 41% = 6% 20% 149\nPacific 253 (118 45% 17% 32 19% 22%\nNoreperting and\n\n\u2018epor 58.0 195 34% 2% 20H 14%\nTotal 196.4 68.0 98% 100% 14.7 8% 100%\n\n\u2018Top 3 regions 424 6m \u00ab85 58%\n\f"}, "003023.png": {"text": "TABLE 5.7\n\nAnheuser-Busch and Coors income statements, 1977 and 1985\n\n1977\nAB coors\nBorrele cold (million) 363 128\n\u2018Saloo ($ milion) $1,604 $ seo\n\u2018Saleo/barrel $46.01 100% $41.56 100%\nCost of goods sold (COGS) $1,340 $ 71\n(COGSibarrel $98.61 80% $28.68 70%\nAdvertising coote: $ 7 $ 14\nAdwrtining costeibanel $ 1.90 4% $ 1.08 Eo\nOther SGA $ 102 $ 2\nSGAvbarral $2.79 6% $ 2.97 7%\nOperating incomes $ 169 $ 109\nOpsratingincemaybarrel $ 4.62 10% $ 982 20%\n1985\nAB Coors\nBarrele cokd (million) 680 147\n\u2018Saleo ($ milion) $5,260 $1,079\n\u2018Saloa/barrel $776 100% $73.40 100%\nCost of goods seld (COGS) $3,524 $ 727\nCOGSibarrel $51.02 7% $49.48 6%\nAdvertiaing costs $471 $ 165\nAdvertising coste/barel $ 6.80 9% $11.22 15%\nOther SGA $ 491 $ 94\nSGAvbarral $72 9% $ 6.99 a\nOperating inccme $ 774 $ 2\nOperating inccenm/barrel $11.99 15% $a Fe\n\n[source Te data & tom the Hanard erase Schoct casa cted Inthe raktenes, and apes cyto he boar\n\u2018making cpsratore ofthese coordina, xciudhg tek cher tras of buenas]\n\f"}, "003024.png": {"text": "In the twenty-five years starting in 1971, AB\u2019s operating margin moved up steadily, doubling over the period as it increased its\nleading market position (figure 5.4). For Coors, margins deteriorated from the start, falling below 5 percent in the 1990s, and only\nrecovering somewhat after the company divested itself of extraneous assets and focused on efficiency. In hindsight, the decision\n\nto go national seems like a major error. But did Coors have an alternative, one that might have been recognized at the time?\n\nSTAYING HOME\n\nCoors may have served itself better had it followed the most hallowed principle in military strategy, von Clausewitz\u2019s advice to\nconcentrate your forces in the center of the line. For Coors, the center of the line was the eleven states in which it did business in\n1975, plus a few others contiguous to them, like Washington and Oregon. Had Coors been able to maintain its market share in its\nthree regions of strength, ignoring the seductive pleas of Coors-deprived beer drinkers in the East, it would have sold more beer in\n1985 than it did by spreading into forty-four states. And even if the Federal Trade Commission had pushed hard to have Coors sell\nits beer across the nation, the company could have satisfied the requirement formally, while charging so much for the beer to keep\nactual demand at a miniscule level. Its advertising expenses need not have ballooned as they did because it would not have had to\nspread them across the country. The freight costs would have been considerably less, and it could have maintained a network of\nstrong wholesalers, who would have happily carried Coors exclusively, given its local popularity. Had it needed more capacity, it\ncould have built another brewery in California, a growing market where it had a strong presence.\n\nFIGURE 5.5\n\nOperating margin, Coors and Anheuser-Busch, 1975-2000\n\f"}, "003025.png": {"text": "w%\n\n2%\n\n10%\n\nma\n\n1975 1980 198s 190 1995 2000\n\n \n\n\u2014 Anheuser-Busch\n\nWith a strong regional position, Coors would have been better able to defend itself against the AB juggernaut. Its beer sold in\nthe region for less than Budweiser, and it could have met any effort by AB to win customers by lowering prices, offering other\npromotions, and advertising heavily. Had AB persisted, Coors could have taken some aggressive moves of its own, like contracting\n\nwith some wholesalers in the Midwest to sell Coors at a deep discount. It still had the hard-to-get mystique, and a price war with\n\f"}, "003026.png": {"text": "Budweiser on Bud\u2019s home turf would have cost Coors much less than AB. Perhaps AB would have thought twice about building a\n\nbrewery in Fort Collins, Colorado.\n\nTABLE 5.8\nCoors in 1985 with 1977 market share\n\nTotal Coors % Barrels (millions)\nNew England 78 O% 0\nSouthesst 25.5 096 \u00b0\nEast North Central 24.0 096 \u00b0\nWest North Central 13.0 MH 1.0\nWest South Central 224 21% 47\nMountain 10.7 37% 3.9\nPacific 25.3 24% 6.0\nNonraporting and export 58.0 O% 0\nTotal 186.4 8% 15.7\n\nThere is no certainty that this \u201cthink local\u201d strategy would have succeeded. Beer drinkers are fickle, and AB\u2019s success in growing\nat the expense of its competitors indicates it was doing something right. Still, the approach of concentrating its efforts where it\nwas already powerful had the promise of maintaining the company\u2019s profitability by capitalizing on its strengths, rather than dis-\nsipating them. Coors did survive, which was more than one could say for Schlitz, Blatz, and a host of regional brewers that fell by\n\nthe wayside during these years. But despite the cachet, it did not prosper.\n\f"}, "003027.png": {"text": "In the end, brewing beer is a business about marketing and distribution, and Coors is, in some essential ways, a Wal-Mart in dis-\nguise. Its history has been drastically different, however, for several reasons. First, because it had to lock horns with some strong\nnational competitors, especially Anheuser-Busch, its expansion out of its regional stronghold was a more painful experience, for\nthe family, the managers, and the shareholders. Perhaps if Kmart had been as well run as AB was, Wal-Mart\u2019s success would have\nbeen more modest. Second, Wal-Mart had a better strategy than Coors. It did not jump from Arkansas into California or the North-\neast, but expanded at its periphery, where it could more readily establish the customer captivity and economies of scale that made\nit dominant. And it defended its base, something Coors was unable to do. Had Coors recognized the local nature of its strength, it\n\nmight have done a better job sustaining its profitability.\n\nBRICKS OR CLICKS? THE INTERNET AND COMPETITIVE ADVANTAGES\n\nAn alternative view of the future highlights the importance of the Internet. One of the articles of faith that drove the Internet\nmania during the last half of the 1990s was that this new medium would transform the way consumers bought books, computers,\nDVDs, groceries, pet supplies, drugs, banking services, fine art, and virtually everything else. Any traditional retailer that did not\ncompletely revise its business model was going to end up as roadkill on the information superhighway. The dominant merchants\nin this new economy would be dot-coms like Amazon, Webvan, Pets.com, Drugstore.com, and Wingspanbank.com, leaving Wal-\nMart, Kroger, and Citibank in their wake.\n\nAfter the mania subsided, it became obvious how excessive those predictions were about the rate at which online commerce\nwould supplant traditional shopping. The expectation that the newly hatched, Internet-only retailers would displace their brick-\nand-mortar competitors also proved mistaken. The bankruptcy courts were soon littered with the remaining assets of failed B-\nto-C (business-to-consumer) innovators. There were some significant survivors, Amazon most prominent among them, but their\n\npath to profitability proved considerably longer than the proponents of the new economy thesis had anticipated.\n\f"}, "003028.png": {"text": "The imbalance between many bankruptcies only partially offset by a few roaring successes does not mean that the Internet is\ninsignificant as a medium of retail commerce. It takes little courage to predict that over time, more people will buy more goods and\nmore services online, and that online transactions will encroach on old-fashioned shopping, banking, and other services. For our\nconcerns with the economics of strategy, the question is not how big online business will become, but whether it will be profitable,\nand if so, for whom.\n\nThe main sources of competitive advantages are customer captivity, production advantages, and economies of scale, especially\nona local level. None of them is readily compatible with Internet commerce, except in special circumstances. A customer can com-\npare prices and services more easily on the Internet than in traditional retailers. The competition is a click away, and there are sites\nthat list comparative prices. The open standards of the Internet make some proprietary technology inapplicable. Otherwise, the\nbest new ideas have had a short life span before something even better has come along; think of search engines; customer service\nsystems, like online stock trading, banking, and package shipping and customized home pages.\n\nFinally, it is virtually impossible for any competitor to profit from economies of scale on the Internet. Internet merchants\nbragged about all the money they had saved by not having to build physical locations from which to sell their wares. But\neconomies of scale entail substantial fixed costs that can then be spread over a large customer base. With minimal required invest-\nments, the incumbent has no advantage. It takes so little to get into the game that virtually anyone can play. And there are no local\nboundaries to delimit the territory in which the firms operate, another element in the economies of scale equation. Also, nothing\nprevents traditional retailers, banks, brokers, insurance companies, newspapers, and everyone else from establishing their own\nInternet presence. Instead of barriers to entry, the information superhighway provided myriad on-ramps for anyone who wanted\n\naccess. It has been an enormous boon to customers, but for the businesses selling to them, the destroyer of profit.:\n\f"}, "003029.png": {"text": "CHAPTER 6\n\nNiche Advantages and the Dilemma of Growth\n\nCompaq and Apple in the Personal Computer Industry\n\nA DISRUPTIVE TECHNOLOGY\n\nIBM introduced its personal computer in 1981. Though not the first company to move into this burgeoning industry, it was the\nmost important. IBM\u2019s commitment to these little machines gave legitimacy to a device that had been the domain of self-taught\nprogrammers, hobbyists, and adventurous adopters of whatever new technology perched on the cutting edge. The company made\nseveral decisions at the start that defined the structure of the industry for years to come.\n\nFirst, to speed development, it adopted an open architecture for the personal computer, buying off-the-shelf components from\nother companies and operating without patent protection. This approach meant that once the initial machines were available,\nanyone could produce a duplicate by buying a central processing unit (CPU), memory chips, a power supply, a motherboard, a disk\n\ndrive, a chassis, an operating system, and the other elements that made up the first generation of PCs. Second, the two most impor-\n\f"}, "003030.png": {"text": "tant and profitable pieces, the CPU and the operating system, were proprietary to other companies. By selecting its CPU from Intel\nand its operating system from Microsoft, IBM created enormous wealth for the owners and many employees of these two firms. It\nis difficult to think of a single decision in the history of business\u2014or anywhere else\u2014that equals IBM\u2019s generosity in this instance.\n\nAlthough it owned neither the operating system nor the microprocessor design, IBM\u2019s endorsement of MS-DOS and the Intel\nchip established standards in a previously anarchic environment. Writers of application software, relieved of the burden of provid-\ning multiple versions, began to offer better word processing, spreadsheet, and database programs that quickly became business es-\nsentials. With an open architecture and components readily available, IBM was soon joined by other PC manufacturers, including\nanumber of start-up companies that saw opportunity in what they rightly predicted would be a rapidly growing industry. Most of\nthese machines were compatible with the IBM standard.\n\nThe explosive rise of the desktop computer was as pure an instance of creative destruction as we are likely to see. It established\nMicrosoft and Intel as two of the largest and most profitable companies on the globe. At the same time, it weakened and eventually\ndestroyed most established manufacturers who had built mainframes and minicomputers, the ghosts of Route 128 like Digital\nEquipment and Prime among them. It made Silicon Valley in California and other places like Seattle and Austin into centers of\ncomputing technology. Moore\u2019s Law\u2014Intel cofounder Gordon Moore\u2019s prediction that transistor density and hence computing\npower would double every year or two\u2014became the driver of a perpetually dynamic industry. Any firm striving to flourish in this\n\nshifting universe\u2014including at times even Microsoft and Intel\u2014would need a talent for adaptation.\n\nENGINEERING A START-UP\n\nCompag had its origins on the back of the proverbial napkin\u2014at most a placemat\u2014on which Rod Canion and two other engineers\nfrom Texas Instruments outlined their business plan for venture capitalist Ben Rosen. The meeting took place in 1981, the year\n\nIBM began to ship its PC. The Canion plan was straightforward. It would produce a computer totally compatible with IBM\u2019s but bet-\n\f"}, "003031.png": {"text": "ter: with higher quality, superior technology, and portability (early units were the size of small sewing machines, weighed thirty-\nfour pounds, and were soon referred to as \u201cluggable\u201d rather than portable). It would sell these machines through large resellers to\ncorporate customers willing to pay a premium price for a more dependable and feature-rich computer. Rosen had been impressed\nwith Canion and his colleagues in an earlier meeting, even though he dissuaded them from their original intent to produce hard\ndrives for PCs. When they changed their focus, he agreed to help raise the money to get the Compaq Computer Company off the\nground.\n\nIt soon took wing. In 1983, its first full year of operations, Compaq had sales of over $100 million. By 1987, five years in, its\nsales had grown to more than $1 billion, a milestone it reached faster than any company in history. And it was profitable, earning\n$137 million in 1987. All this happened in a field crowded with both new and seasoned firms that had moved to take advantage\nof the exploding market created by IBM\u2019s PC venture. Compaq\u2019s plan of total compatibility, high quality, and premium prices set it\napart from the others.\n\nCompanies like Digital Equipment and Hewlett-Packard, rich in engineering talent and with proud heritages of building excel-\nlent minicomputers, created fine machines. But because their products were not compatible, were too expensive, and were late to\nthe game, neither firm fared well.: Other start-ups did not match Compaq in quality and reliability. But they did have some breath-\ning room, at first, because IBM was unable to meet the demand for the new machines, which far exceeded even its most optimistic\nprojections. By the end of 1983, IBM had shipped over a million units, but that represented only 26 percent of the market, leaving\nplenty of space for some of the other firms.\n\nWith essentially no barriers to entry, there are bound to be shakeouts in an industry as dynamic as personal computers. Some\nof the early IBM-compatible makers like Eagle, Corona, and Leading Edge, gained an early foothold but were unable to survive once\nIBM caught up with its backlog and lowered its own prices. There were also shakeins. Michael Dell used his college dorm room as a\njust-in-time manufacturing center to sell PCs to his schoolmates. Two years later, in 1986, he produced a printed catalog and had\nsales of more than $150 million. Gateway 2000 copied his direct sales approach, established itself in the heartland, and designed\n\nits cartons to look like cowhides. It reached the billion-dollar sales plateau in its sixth year.\n\f"}, "003032.png": {"text": "INDUSTRY ANALYSIS\n\nGrowth was the dominant feature of the personal computer industry. The machines became more powerful, more useful, and\nless expensive, a potent combination of features that put them into millions of offices and homes, both in the United States and\nabroad. An industry survey put sales in 1986 at $30 billion (figure 6.1). Nine years later they had increased to $159 billion, acom-\npounded annual growth rate of 23 percent. With growth like this, there was room for many players.\n\nThe absence of barriers to entry\u2014footloose customers, widespread access to multiple channels of distribution, simple and\ncommonly available technologies, relatively low investment requirements, and limited economies of scale\u2014ensured that the play-\ners arrived and competed aggressively for customers. Throughout the period, the market share of the top twenty vendors averaged\naround 56 percent. IBM, the early leader, owned 24 percent of the market in 1986. By 1995, that had fallen to 8 percent, a figure\nmatched by Compaq and Apple. The large number of manufacturers\u2014box makers, in the jargon of the trade\u2014and the shifting\n\nmarket share are strong indications that this was a highly competitive industry with ease of entry and ease of exit.\n\f"}, "003033.png": {"text": " \n\nS180 100%\n\n$160 0M\ns140 a\n70%\n$120\ni m4\n2 sio0\na sm 3\n4 seo 3\nz \u201c4\nseo a\n30%\naa 20%\n$20 10%,\nso om\n\n1985 \u00ab1987 1983 1989 19890 1991 1992 1993 1984 1998S\nGR Compag share I) Percentage of top 20 \u2014<ntal Sales\n\nFIGURE 6.1\nTotal sales of the PC industry, share of top 20 PC makers, and Compaq share, 1986-95\n\f"}, "003034.png": {"text": "The personal computer world considered as a whole is actually composed of a group of discrete markets, with a limited\noverlap of players (figure 6.2). At the center are the box makers, building their machines out of components supplied mainly by\nother companies. The component makers are also specialists, concentrating in power supplies, memory chips, CPUs, disk drives,\nmotherboards, keyboards, monitors, and the other pieces out of which the machines are assembled. The machines also ship with\nsoftware, almost always with an operating system, and often, since the 1990s, with some core applications, like word processing\nand spreadsheets. Finally, there are the sales channels through which the computers reach the ultimate users. Some go to large\nretailers. Some go to wholesale distributors who service smaller computer stores and value-added resellers, people who combine\nservice with delivery of machines. Dell and Gateway 2000 popularized the direct sales channel, bypassing all the intermediate\nsteps between manufacturer and user. Their success bred emulation from Compagq, Apple, IBM, and most of the other major play-\ners, but they had to tread carefully for fear of undermining their existing channel partners.\n\nAlthough the lists of players within the various market segments were subject to frequent changes\u2014the cast of characters in\nfigure 6.2 comes from the late 1980s\u2014the basic structure of the industry has been remarkably stable. The only significant sector\nchange was the emergence of network service providers like AOL in the middle to late 1990s, when the new driver of growth be-\ncame the promise of the Internet and all the advantages of connectivity.\n\nThere are two important features of the structure of the PC universe that deserve comment.\n\nFirst, there was only limited spillover between the box makers and the other segments. The different names of the leading\ncompetitors in each sector indicate the absence of effective joint economies. Intel dominates CPU production, but it neither manu-\nfactures PCs nor sells much software. With few exceptions, like keyboards and mice, Microsoft has avoided hardware manufacture.\nIts foray into game consoles with its Xbox system put it into competition with Sony and Nintendo, not Dell, and the jury is still out\non its success in this venture. The major disk drive makers like Seagate, Maxtor, Quantum, and Iomega have seldom strayed from\ntheir niche, where intense competition has been difficult enough. Even IBM, the initial PC giant, found itself restricted to box mak-\ning. It tried to separate itself from the Microsoft-using crowd by developing its own variant of MS-DOS, but the experiment with its\n\nOS-2 was unsuccessful and short-lived. IBM also made CPUs, including the PowerPC developed in partnership with Motorola and\n\f"}, "003035.png": {"text": "Apple. Yet its own machines had Intel inside. Compaq, which initially designed and even manufactured some of the components\n\nthat other box makers bought outright did not produce chips or software.\n\n \n\n\u2018Non-Silicon Components\nPomer aupplics\n\nDrives\n\nMonitors\n\nKeyboards\n\nMotherboards\n\n\u2018And others\n\n \n\n \n\nSilicon Components\nMicroprocessors\n\nIntel\n\nAMD\n\nMotorela\nMemory\n\nHic\n\nPajitou\n\nMicron\nBios\n\nPhoenix\n\n \n\n \n\nSoftware\nOperating Systems\nMicrosoft\n\nApple\nIBM\n\nApplications\nMicrosoft\nApple\nLom\nAdobe\nQuicken\nAnd others\n\n \n\n \n\n \n\f"}, "003036.png": {"text": "FIGURE 6.2\nMap of the PC industry:\n\nSecond, the only segments within the PC world with features suggesting that there are barriers to entry protecting incumbent\nfirms from new entrants are operating systems and CPUs. In both there are a small number of competitors and stable market\nshare. While the ranking of companies in the box-making segment changed frequently, Microsoft has owned the operating system\nbusiness since the IBM PC was introduced. In the CPU segment, Intel has always dwarfed the other manufacturers. AMD was given\na boost early on when box makers forced Intel to license its design to another chip company so that they might have a second\nsource. AMD has occasionally been able to pressure Intel and force it to reduce prices or offer a lower-cost alternative to its top-of-\nthe-line chip. But Intel has always been the leader, and by a wide margin.\n\nThe three basic sources of competitive advantage all help to account for the barriers to entry in these two market segments.\n\n1. Customers prefer to stick with what they know, especially regarding software. Switching costs can be prohibitive\nwhen many users have to be taught to use unfamiliar programs. Search costs also inhibit change because the\nbuyer has to have confidence in the reliability of the new system and the survivability of its creators.\n\n2. Intel devotes major resources to production technology, aggressively defending patents and developing its exper-\ntise to keep yields high and defects low.\n\n3. The most important advantage is economies of scale. Writing complicated software and designing advanced mi-\ncroprocessors keeps talented and expensive engineers at their terminals and benches for hundreds of thousands\n\nof work hours. On the other hand, the marginal costs of the next unit of the operating system can be as low as\n\f"}, "003037.png": {"text": "zero and seldom more than a few dollars, even when burned on a CD and boxed with a manual. A similar though\n\nless extreme contrast holds for the next microprocessor to come off the line.\n\nBecause they can spread their investments over millions of units, Microsoft and Intel are by far the lowest-cost producers.\nMicrosoft has had virtually no competition in the desktop PC market. Intel has had Advanced Micro Devices as a distant second.\nIts research and development spending has always been larger on an absolute basis, while smaller as a percentage of sales, than\nAMD's. In 1988 through 1990, for example, Intel spent twice as many dollars on R&D as AMD, but only two-thirds as much per dol-\nlar of sales (twelve cents versus eighteen cents).\n\nNetwork effects enhance both customer captivity and economies of scale. For programmers, computer designers, and typists\nin large firms, costs are reduced when users have to learn and interact only with the single software system that others are also\nusing. The many PC manufacturers, each perpetually introducing new models, also benefit in cost, speed, and mutual compatibil-\nity by having a single chip standard on which to work. The bold innovator, seeking to separate himself from the pack, has to spend\nenormous sums to come up with something significantly different whose future value will be, by definition, highly speculative.\nAll these barriers to entry have been impregnable, at least so far. It will probably take another major technological disruption to\nchange this situation.\n\nThe contrast with the box makers could not be more extreme. There has been along and shifting list of players throughout our\nprime period, with firms entering and leaving regularly. The top twenty firms accounted for rarely more than 60 percent of this\nmarket. This fluidity is an indicator of a highly competitive business, not one in which incumbents have powerful advantages.\n\nIf there were an advantage, what would be the source? Captive customers hardly seems likely. Even when the demand for more\npowerful microprocessors to run more complicated and graphics-intensive programs led existing users to replace older machines,\n\nthe purchases were not frequent enough to be habit-forming. The standards that mattered were the operating system and the CPU,\n\f"}, "003038.png": {"text": "so there were no switching costs to buying a different brand. Perhaps the issue of reliability made search costs a factor, but one that\nwas easily overcome by all the available reviews that tested and ranked machines.\n\nAtechnological advantage is also unlikely. The box makers are basically assemblers, buying off-the-shelf parts and putting\nthem together. Most of the technology is in the chips, both the microprocessors and the memory chips. There were also advances\nin storage systems, in battery life for portables, in screen technology, and in other components, all sparked by the industry mantra\nof faster, smaller, and cheaper. These were not, for the most part, the work of the box makers, who simply bought and installed\nthem.\n\nFinally, the box makers did not have the high-fixed-cost/low-marginal-cost structure that gives rise to economies of scale. Each\ncomputer they shipped had to have a microprocessor, an operating system, a power supply, and all the other parts that made them\nwork. Though there may have been some volume discounts offered by their suppliers, the component cost of the last machine to\ncome off the line was not much lower than of the first, and components accounted for most of the costs. It is rare to find economies\nof scale in industries with cost structures like this. Research and development costs were low. In the years when Intel was spend-\n\ning 12 percent of sales on R&D, Compaq spent 4.5 percent, and Dell 3.1 percent.\n\nTHE COMPAQ ADVANTAGE\n\nAs a box maker, Compaq was located squarely in one of the most competitive segments within the PC universe. In no year from\n1983 through 1995 did it own as much as 9 percent of the market, nor did it ever make it to the very top of the list. And yet for\nmost of our prime period (1986-95), it was solidly profitable. Its operating margins averaged over 13 percent, its return on in-\nvested capital over 22 percent. Compaq\u2019s approach to the business\u2014high quality at a premium price for corporate buyers who\ncared more about reliability than the best bargain\u2014worked well through several generations of machines. Measured by both\n\ngrowth and profitability, it outperformed IBM\u2019s PC operations.\n\f"}, "003039.png": {"text": "But its history was anything but smooth. In 1984, it introduced its first line of desktop computers to complement the early\nportables that had been the model responsible for its early success. The machines did not sell quickly, inventory backed up, and the\ncompany had to borrow $75 million, at a costly interest rate, to pay its bills. The problem was solved with the introduction of In-\ntel\u2019s 80386 microprocessor. The 386 was a much more powerful CPU than the 286 that had preceded it (and which Microsoft's Bill\nGates referred to as \u201cbrain dead\u201d). The demand for the 386 was strong and the supply initially limited. Compaq was among the first\nto market with a 386 computer, beating IBM by some months, and it had mobilized its extensive engineering resources to produce\na well-functioning machine. Its only competitors in the early months of the 386 roll-out were several smaller firms that did not\nhave Compaq\u2019s reputation for quality or the features it offered.\n\nThe next major challenge came two years later, when IBM attempted to alter the design of the PC with its PS/2,a computer\nthat would not accept boards (holding additional memory and other features) designed for the old standard. It also introduced\nmicrochannel architecture, a faster way to move data within the machine (known as a system bus). These moves were a belated\neffort by IBM to regain some of the proprietary advantage it had given up when it introduced its original, easily copied, computers.\nAlthough IBM\u2019s effort did not ultimately succeed, Compaq felt that the challenge was genuine. Executives went so far as to explore\na sale of the entire company to Tandy, another box maker with a strong distribution channel through its Radio Shack stores. Once\nagain, however, Compaq\u2019s engineering muscle came to its rescue. The company added new features to its desktop line. It put to-\ngether a consortium of box makers committed to a nonproprietary system bus. It also moved into the emerging laptop market,\nwhere it sold to corporations who saw the advantages of true portability and wanted the assurance provided by Compaq\u2019s reputa-\ntion for quality.\n\nAthird and potentially more lethal problem emerged suddenly in the early part of 1991. After a strong year in 1990 anda good.\nfirst quarter of 1991, sales of Compaq\u2019s computers started to slow. The initial information came from the retailers, who saw their\ninventory of Compags start to build. The company attributed the slowdown to the economy, which had become part of a global\n\nrecession, and to the strong dollar, which made imports less expensive. Compaq responded with price cuts of up to 30 percent, but\n\f"}, "003040.png": {"text": "that did not help. The drop in sales continued, and operating income plummeted (see figure 6.3). The company was in trouble, and\nits management and directors were compelled to seek an explanation.\n\nBen Rosen, the venture capitalist who had helped launch the company, was still its nonexecutive chairman. He assembled a\nsmall team to investigate the situation, particularly the market into which Compaq sold its computers. They learned from Com-\npaq\u2019s own sales force that the corporate customers were no longer willing to pay the premium for a Compaq because the quality\ndifferential had been reduced or eliminated entirely. Even more troubling, the salespeople had been giving senior management the\nsame message for nearly a year. Unfortunately management, composed primarily of the engineers who had founded the company\nand grown it so successfully, had not responded. They believed that Compag could once again design its way out of the crisis, that\nby introducing new features and better technology than the competition, they would win back their corporate customers whose\nhesitance to pay the Compaq premium was temporary. Rather than reduce their overhead to meet their competitors\u2019 price, they\n\nwould maintain their technological edge and continue to produce superior machines.\n\f"}, "003041.png": {"text": "$2,500\n\n$2,000\n\n$1,500\n\nSales\n\n$1,000\n\n$500\n\n30\nDec-89 Dec-90 Dec-91 Dec-92\n\nmeee Sales Operating Income\n\n \n\nFIGURE 6.3\nCompagq\u2019s sales and operating income, quarterly, 1989-93 ($ million)\n\nDec-93\n\n$250\n\n$200\n\n$150\n\n\u2018$100\n\nOperating Income\n\f"}, "003042.png": {"text": "The engineers, led by founder and CEO Rod Canion, had history on their side. Compaq had engineered its way through rough\npatches before, and until at least the middle of 1991, it was doing better than its low-cost rivals like Dell and AST. But Rosen and\nhis allies felt that the medicine that had worked in the past was no longer the right prescription for the current difficulties. In the\nfall of 1991, Rosen and his group made an incognito visit to Comdex, the computer industry's premier trade show.\n\nWhat they saw confirmed their belief that even Compagq\u2019s engineers would not be able to pull one more technological rabbit out\nof the hat. They found that many of the crucial components like keyboards, power supplies, and electronic controllers that Com-\npaq designed or even built for itself were available from independent manufacturers for much less than it cost Compaq. Also, these\ncomponents were equal to or better than those Compaq produced. Compaq\u2019s competitive edge at the top end of the market had\nbeen eliminated, and it was left with nothing to show for its higher overhead expenses. Just as Ford\u2019s plant at River Rouge, where\niron ore entered at one end and finished automobiles emerged from the other end, became a victim of vertical integration as the\nautomobile industry matured and external suppliers became more dependable and efficient, so Compaq was being hurt by doing\n\ninternally too many of the steps that went into turning out a personal computer.\n\nECONOMIES OF SCALE IN A GROWTH INDUSTRY\n\nCompaq\u2019s original approach to the PC industry, targeting corporate customers with higher-quality machines for which they would\nbe willing to pay a premium, was undoubtedly a success, even though it had to work its way through several serious challenges.\nIn the early years of the IBM-compatible business, Compag was able to distinguish itself from its rivals and appeal to a particular\nsegment of the overall market. It had little competition in this end of the business. Even though by 1987 or 1988 there may have\nbeen little that set a Compaq PC apart from the others, what little there was still made a difference. Compag had the size, relative to\ncompetitors in its niche, to outspend them on engineering and assure its customers that all the components going into a Compaq\nmachine were the best available. Within this small segment of the PC world, it had the advantage of economies of scale coupled\n\nwith a small but crucial dose of customer captivity.\n\f"}, "003043.png": {"text": "A few years later that advantage had disappeared for Compaq. As personal computer sales grew from $30 billion in 1986 to\nmore than $90 billion in 1991, demand for all the components, including the high-quality ones, increased. Companies specializing\nin high-end power supplies, keyboards, and the other pieces were now making so many units of their single component that they\ncould spread their engineering and manufacturing costs across a base that was comparable in size to Compagq\u2019s. And their quality\nimproved with experience even as their prices fell, thanks to the advantages of specialization. Compaq could not keep up. The sixty\nengineers it employed to work on power supplies had become an expensive luxury. With 5 percent of total global sales for personal\ncomputers, it simply did not have the volume advantage over those specialized component makers, who now had 2-3 percent of\nthe now expanded market, to benefit from economies of scale. So long as it persisted in a \u201cdo-it-ourselves\u201d policy, it would be at a\ncompetitive disadvantage.\n\nRosen and his marketing-oriented supporters within the firm had to wrestle with Canion and the engineers over the strategy\nCompaq should take. Rosen\u2019s side won, and Canion was forced out in a bitter dispute. He was replaced by Eckhart Pfeiffer, who had\nbeen head of European operations and was chief operating officer in 1991. Pfeiffer immediately began to chop away at Compaq\u2019s\ncost structure. The firm followed the path of Dell, AST, and other box makers and began to buy most of its components from spe-\ncialized manufacturers. By 1995, after the transition had been completed, Compaq\u2019s cost structure looked much more like Dell\u2019s\nthan like the Compaq of 1990 (table 6.1). Its return on invested capital was lower than Dell\u2019s largely because Dell\u2019s direct model of\nsales allowed it to turn both receivables and inventory more frequently. Another good measure of efficiency\u2014sales per employee\n\u2014corroborated the extent of Compaq\u2019s new direction. In 1990, that figure was only slightly above $300,000. By 1995, it reached\n$865,000 and compared favorably with Dell, whose sales per employee were $630,000. Compaq\u2019s specialization in basic PC pro-\nduction, coupled with a sharp reduction in overhead, allowed it to more than double its operating income between 1990 and 1995.\n\nRosen\u2019s genius had been to recognize that the quality and economies of scale advantages Compaq benefited from in the 1980s\nwere now history, and that unless Compaq changed its business plan, it was going to be struggling uphill against lower-cost but\nqualitatively equal competitors. He and his team decided to pursue the only strategy that makes sense in the absence of a competi-\n\ntive advantage; the determined pursuit of operational efficiency.\n\f"}, "003044.png": {"text": "TABLE 6.1\n\nCompaq and Dell, 1990 and 1995 ($ million, costs as a percentage of sales)\n\ni\n\n$\nSales $3,599\nCost of goods sold $2,058\nSGA $ 706\nRaD $ 186\nEBT $ 649\n\nCOMPAQ,\n\ni\n\n% $\n\n100% = $14,755\n\n57% $11,367\n\n20% $ 1,353\n\n5% $ 511\n\n18% $1,524\n27%\n\n100%\n77%\n9%\n3%\n10%\n21%\n\nDELL\n\n1995\n$ %\n$5,206 100%\n$4,229 80%\n$ 639\u00b0 12%\n$ 51 1%\n$ 377 7\n3a%\n\f"}, "003045.png": {"text": "120% 24%\n\n10086 20%\na 16%\n\n5\n\noF am 2\n\ng i\n\ns 40% 8% .\n\nz\n\nDe 4% &\n(Re = Mm\n\n \n\n \n\n4%\n1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000\n\n \n\nmeee ROIC \u2018Operating Income Margin\n\n \n\nFIGURE 6.4\n\nCompaq\u2019s return on invested capital and operating income margin, 1990-2001\n\f"}, "003046.png": {"text": "For a time, the approach was successful, as the company combined strong sales growth with decent operating margins and\nhigh return on invested capital (figure 6.4).:\n\nBut ingrained cultures are difficult to uproot. The engineering mentality and love of technology that was part of Compaq\u2019s\ntradition did not disappear, even after Rod Canion left. In 1997 the company bought Tandem Computers, a firm that specialized in\nproducing fault-tolerant machines designed for uninterruptible transaction processing. A year later it bought Digital Equipment\nCorporation, a former engineering star in the computing world which had fallen from grace as its minicomputer bastion was un-\ndermined by the personal computer revolution. At the time of the purchase, Compaq wanted DEC for its consulting business, its\nAltaVista Internet search engine, and some in-process research. Technology acquisitions are notoriously hard to digest, and Tan-\ndem and DEC were no exceptions. Compag lost its focus on operational efficiency, its own profitability plummeted, and in 2002, it\nsold itself to Hewlett-Packard.\n\nThe Compag story is so intertwined with the history of the PC that it is easy to miss the more general significance. It lost its\ncompetitive advantage and the resulting high levels of profitability as the markets grew and allowed competitors to develop equiv-\nalent economies of scale.\n\nThis is a recurrent phenomenon. Globalization has taught this lesson in a number of industries. Take automobiles. When the\nUnited States was separated from the world automobile market, Ford and General Motors had such enormous scale, relative to\nthe size of the domestic market, that their positions were unassailable. This dominance was especially true in the luxury car field.\nWith globalization, due largely to the reduction of both trade barriers and transportation costs, competitors from abroad were able\nto expand the scale of their operations and ultimately to challenge GM and Ford within the United States. There are similar exam-\nples from other industries, like consumer appliances, machine tools, and electronic components.\n\nFor profitability, growth is a double-edged sword. It always requires additional investment, and the prospects of earning more\nthan the cost of capital depend on the position of the firm in its industry. For companies with competitive advantages that they\n\ncan maintain even as the market gets bigger, growth is an unambiguous benefit. But when markets enlarge, they often allow com-\n\f"}, "003047.png": {"text": "petitors to achieve comparable economies of scale and thereby undermine a major barrier to entry. Unprotected by barriers, com-\n\npanies do not produce exceptional returns.\n\nTHE APPLE VERSION\n\nAyear or so before Ben Rosen realized that Compaq needed a major recasting of its business strategy, John Sculley began to enter-\ntain similar thoughts about Apple. A marketing wiz at PepsiCo, Sculley had been recruited in 1983 to become Apple\u2019s CEO by Steve\nJobs, one of the company\u2019s founders. Jobs was forced out two years later, leaving Sculley as undisputed leader of the company most\nemotionally identified with the PC revolution. In 1990, Apple was still one of the leaders in the business. It had more than 10 per-\ncent of the global marketplace, measured by revenue, the highest share it had ever enjoyed since IBM\u2019s PC was introduced in 1981.\nIts operating margins exceeded 13 percent, down from an earlier peak though still healthy by the standards of the industry. But\nSculley was looking forward, and what he saw convinced him that Apple needed to take action.\n\nThe company Sculley analyzed in 1990 stood apart from the other firms in its segment of the industry. Alone among the major\nbox makers, it used its own operating systems, both a text-based system for its Apple II line and the more exciting graphical user\ninterface (GUI) operating system for its Macintosh line. It also manufactured or designed all of the important components and pe-\nripherals that made up a complete personal computer system. The Apple II line was targeted at the K-12 education market, where\nApple had a large installed base. The Macintosh line sold into the education market, but it was also popular with home users and\ngraphics professionals.\n\nMacintosh machines had some important advantages when compared to their PC counterparts. They were easier to use\nbecause of the more intuitive interface. They had plug-and-play compatibility with printers and other peripherals, largely because\nApple had tight control of the components and component standards. They were easier to network together than MS-DOS ma-\n\nchines because of the operating system. They were far superior for all graphics applications, including desktop publishing and pic-\n\f"}, "003048.png": {"text": "ture editing. In the still tiny but promising field of multimedia applications, where sound, images, and data would all be combined,\nthe Macintosh was far ahead of the field. And they had devoted users, loyal to the technology and the company that had made it\ncommercially available.\n\nOn the other hand, Sculley realized that the company and its flagship Macintosh line faced certain disadvantages that would\nprobably outweigh its strengths. First, Macintosh machines were considerably more expensive than their PC competitors. Mo-\ntorola, the sole supplier of the Macintosh microprocessor, had missed an upgrade deadline for a more powerful version of the chip,\nleaving the Mac both underpowered and overpriced. Second, the Mac, despite its superior features, had never made important\ninroads into the corporate world other than in the graphics area. It confronted the dismal end of the chicken-and-egg dilemma. Be-\ncause it owned a much smaller share of the corporate market, independent software companies did not write specialized programs\nfor its platform. With fewer packaged applications programs available, new buyers chose PCs over Macs, pushing Mac further to\nthe rear. Third, its strength in the educational market was probably a wasting asset. At some point, the students or their instruc-\ntors were going to realize that one of the things they should be getting from computers in the classroom was proficiency on the\nmachines and systems\u2014overwhelmingly PCs\u2014that they would be using after graduation.\n\nFinally, by 1990 Microsoft had worked out enough kinks in Windows to make it workable. It released version 3.0 in that year\nand sold 10 million copies in the first twenty-one months. Though inferior to Macintosh OS 7.0 in almost every respect, the pro-\ngram\u2019s success at the box office put Apple on notice that its lead in the graphics world was under assault. Windows 3.0 was made\npossible in part by the faster Intel microprocessors now found in new PCs. As these continued to add muscle, the future of Win-\ndows looked bright. And the machines had the added appeal of being able to run all the legacy programs written for the MS-DOS\nsystem.\n\nSo Sculley had reason to be worried. But in the steps he took and the vision of Apple\u2019s future he articulated, he seemed to miss\nthe larger, structural situation that Apple confronted, for which his cures and his vision were inappropriate. The most funda-\nmental economic feature of the PC universe was that in two market segments\u2014microprocessors and operating systems\u2014there\n\nwere powerful competitive advantages, enjoyed by Intel and Microsoft, based on economies of scale, supplemented by captive\n\f"}, "003049.png": {"text": "customers and some proprietary production technologies. The other segments were highly competitive. Apple earned its money\nin the most competitive segment, box making, where it had no competitive advantage and where its penchant for designing and\nmanufacturing many of its own components put it at a competitive disadvantage. It spent money in writing and maintaining\noperating systems, where it was also at a competitive disadvantage. It depended on Motorola for its microprocessors, and Motorola\noperated at a competitive disadvantage to Intel, the dominant company in the segment. Microsoft also wrote some applications\nprograms for the Macintosh, especially the spreadsheet Excel and the Word word processor, which were more popular than any-\nthing Apple produced.\n\nAsecond look at our industry map, modified to focus on Apple\u2019s position in the segments in which it operated, makes clear the\nunfavorable position it occupied (table 6.2).\n\nApple operated, either by itself or in partnership with Motorola, in five market segments within the PC universe. In none of\nthese segments did Apple possess a competitive advantage. At best, in box making, it operated on a level playing field. Some of\nSculley\u2019s changes were directed at improving its position in this core business. He decided to cut costs drastically by permanently\nlowering the head count, by eliminating some of the perks that had made Apple\u2019s work environment so pleasurable, by moving\njobs out of high-priced Silicon Valley, by cutting out some projects and activities that did not promise economic returns, and by\nabandoning the \u201cnot invented here\u201d prejudice in manufacturing in favor of going to outside suppliers wherever possible.\n\nThis attack on costs allowed Apple to offer lower-priced versions of the Macintosh that were competitive with many IBM-\ncompatible PCs. But Sculley did not take Apple out of the applications software business, nor did he alleviate the two greatest dis-\nadvantages confronting the company.\n\nOne, despite superior technology, the Macintosh operating system was a distant second to Microsoft\u2019s offerings and would\nlikely be a millstone around the company\u2019s neck unless something changed dramatically in the industry. Two, in the race for\ngreater processor performance, Motorola would inevitably lag behind Intel, whose larger market share would permit it to spend\n\nmuch more on the essential ingredient: research and development.\n\f"}, "003050.png": {"text": "The argument for keeping all these distinct segments tied together was \u201csynergy.\u201d Yet it is not immediately clear where the\nadvantages of synergy lay, especially in the long run. Microsoft and Intel collaborated regularly and could reproduce any impor-\ntant joint economies that Apple might identify. Also, the evolution of the industry toward separate major players in each segment\n\nargued strongly against the existence of significant advantages from vertical integration.\n\nTABLE 6.2\n\nApple's\n\u2018Stain Prontatity Postion?\n\n \n\nthe bare\nwit Mec\ntee We\nsantnge\nWe te Feitape\n-erte\n(ould do wal\nMinkovsed en\ntency and\nesi\na\npes sepine deme cutie\nSyaeme (OS) \u201ccustomers de os Sethe\ntohigh emiching costs was acond ploy\nsocnomien of vole ep)\nUotol erry thee oars\nchip get mere pom\nsretwork etereaion\nTatewer Mieot ew We\n\u2018pplcesone \u2014 setencedthe forte dantage\n(Giice ten, Werome 05 \u2018fice ter\nintone co ut, \u2018orice\nFublohing te (Lobe (ner on\nGeabece\u201d nd WordPerfect, snrtucter product,\nImansgerent, ware the vers) \u2018ot Windows)\ncaptive caster ndtor\n\u2018voticelrnatet)\u201ceccramion of cae \u2018eho\nche pare lente\n\f"}, "003051.png": {"text": "Sculley\u2019s other moves were more questionable. He committed the company to introducing a series of \u201chit products,\u201d either new\nor refashioned offerings, on a very tight schedule. Some were successful, like the PowerBook, Apple's first competitive notebook\ncomputer. Some were innovative, like QuickTime, a multimedia software package that established Apple's leadership position in\nthat field. The strategy did refresh Apple\u2019s product line, but it also required the company to maintain a large staff of programmers\nand product designers.\n\nSculley also decided that Apple needed alliances with other companies in the industry in order to capitalize on its software\nstrengths. His first three ventures were announced in 1991. All involved IBM, formerly Apple\u2019s most important competitor in\nthe PC world. The first was IBM\u2019s new RS6000 line of microprocessors. Apple would switch to chips built on this technology, and\nMotorola, also an ally, would be a second source of the new PowerPC chips. In the Taligent joint venture, the two companies would\ndevelop a new operating system to run on the old Motorola 68000 microprocessors, or Intel\u2019s line of X86 chips, or on the new Pow-\nerPC CPUs. A clever effort intended to make it easier for programmers to write applications for the system, it was also going to be\nenormously costly. A third venture with IBM had the goal of establishing standards for multimedia software.\n\nAn underlying rationale for these alliances was Sculley\u2019s sense that Apple was a small player on a large playing field and that\nby forming joint ventures with bigger allies, it could use their muscle to leverage its unique strengths. He was, he said, trying to\ntransform the whole industry, to get some relief from the relentless margin pressure that competition was putting on the PC man-\nufacturers. With only 10 percent of the PC market, Apple did not have the essential clout on its own. And none of these moves chal-\nlenged the dominance of the Microsoft-Intel standard. IBM had not been successful in its own attempt at a competing operating\nsystem, and there was little to suggest that the Taligent venture would gain wider acceptance. It was Apple who had experience in\nmultimedia software; what they would gain from IBM was not immediately apparent.\n\nSculley was a visionary. These alliances were motivated not only by his desire to restructure the personal computer industry,\nbut also by his sense of the imminent emergence of a digital information universe. Every firm that created, published, transmit-\nted, processed, or displayed information would be a part of this interconnected world. Long-established boundaries between\n\ntelephone companies at one end and movie studios and newspapers at the other would be broken down and reorganized. This was\n\f"}, "003052.png": {"text": "a bold and in many ways prescient picture of the future when Sculley laid it out in 1991, a few years before the explosive growth\nof the World Wide Web that became the connective thread for many of these industries (see figure 4.5 on page 75 for Sculley\u2019s\nvision).\n\nThe question for Apple was how it might fit into this picture profitably. It might try to position itself as the indispensable center\nof this cosmos, the owner of a software standard essential for all multimedia processing. But here it would be directly confronted\nby Microsoft, with its powerful competitive advantages. If new technology should vitiate Microsoft\u2019s advantages, Apple would be\njust one player in a highly competitive arena in which no one was going to hand it a central position. Alternatively, Apple could try\nto be a leader in new products that fit into this digital universe, like a personal information manager (now called personal digital\nassistant) that was pocket-sized, recognized handwriting, and integrated with existing hardware. The playing field for these new\nproducts was almost certainly going to be level, without major barriers to entry. It is hard to see what competitive advantage Apple\nmight enjoy. Finally, Apple could concentrate in one or two niches, like graphics and multimedia software, in which it might capi-\ntalize on its existing superior technology. Even here it might be confronted by the Microsoft-Intel steamroller, once better software\nand more powerful chips became available.\n\nThere was no easy answer to the dangers Sculley identified. None of the choices were sure successes for Apple. Each of them\npresented challenges, given the large number of powerful competitors, the uncertain path toward a digital information world, and\nApple\u2019s existing vulnerabilities due to its position outside the mainstream of personal computing technology. Correct in recogniz-\ning the shoals toward which Apple was moving in 1990, while it was still quite profitable, Sculley could not find a course that put\nthe company on a profitable path. He was removed in 1993, and his successor lasted only three years before he, too, was ousted.\n\nApple seemed to change strategies every six months. In 1994 it announced that it would license the Macintosh operating\nsystem, allowing other companies to produce clones of its machines. This program lasted three years before it was discontinued\nduring the second tenure of Steve Jobs, who returned to the company not long after he sold his NeXT computing business to Apple\nfor millions of shares. Jobs did manage to return Apple to profitability, centering it once again in the personal computer business,\n\nwhere its elegant designs and easier-to-use operating system kept it the favorite of hard-core Apple devotees. Though its sales in\n\f"}, "003053.png": {"text": "the year ending September 2000 were down almost 30 percent from the high of 1995, Jobs had managed to restore operating mar-\ngins to the same 5 percent level they had been. Apple survived; it had hardly prospered. Its future does not look bright. See figure\n\n6.5.\n312,000 25%\n20%\n310,000\n19%\n$8,000 }\n= 10%\na\n=\n2 $6,000 5% i\nj =i\nwe i\n5%\n$2,000\n-10%\n\u00bb \u201c1%\n1980 198s 1990 1995 2000\n\ney Sales \u2014 Operating Income Margin\n\f"}, "003054.png": {"text": "FIGURE 6.5\nApple\u2019s sales and operating income margin, 1980-2000\n\nThe contrast between Sculley\u2019s musings and Rosen\u2019s lucid prescriptions for Compaq is striking. By concentrating on operating\nefficiency in an environment without competitive advantages, Compaq grew larger than Apple and enjoyed some profitable years.\nApple floundered (table6.3). Even with a marketing genius of Steve Jobs\u2019s caliber, Apple\u2019s unfocused pursuit of broad but illusory\ncompetitive advantages denied it the benefits of specialization and clarity of managerial focus. As we have seen, Compaq\u2019s revival\nwas short-lived. It could not sustain the cost discipline that returned it to profitability, and ultimately it was absorbed by Hewlett-\nPackard.\n\nTABLE 6.3\nCompaq and Apple, 1991 and 1997\n\nCompaq Apple\nSales in $ billions, 1991 $3.6 $6.3\nSales in $ billions, 1997 $24.6 $7.1\n\nAverage operating margin 10.2% 1.7%\n\f"}, "003055.png": {"text": "CHAPTER7\n\nProduction Advantages Lost\n\nCompact Discs, Data Switches, and Toasters\n\nPHILIPS DEVELOPS THE COMPACT DISC\n\nPhilips NV., a multinational conglomerate based in the Netherlands, has a long history in the consumer electronics business. It\npioneered the audiotape cassette as an alternative to the long-playing record. In the late 1960s, some engineers in its research\nlaboratories began to work on using lasers for digital reproduction, a technology initiated at MIT in the previous decade. Philips\u2019s\nfirst result was a video system based on optical scanning of analog, rather than digital, images engraved on discs. Though superior\nin reproduction quality to videotapes, the product did not gain broad acceptance, largely because this system could only play back\nprerecorded discs. But the engineers were impressed with the promise of laser scanning, especially when combined with digital\nencoding of audio and visual information. In 1979, executives in the consumer electronics division started to analyze the poten-\n\ntial for using this technology to record music for home consumption on compact discs.\n\f"}, "003056.png": {"text": "THE RECORDED MUSIC INDUSTRY IN THE UNITED STATES, CIRCA 1979\n\nArecord or tape passed through many steps between the artist in the recording studio and the customer listening to music in his\nhome. Most market segments of the industry were highly competitive\u2014many firms each with a small share of the market. The\nonly exception was in the center of the music world, where a few record companies, who hired the artists and produced and mar-\nketed the records, controlled most of the business (figure 7.1).\n\nPhilips itself operated in two of these segments. It was one of many manufacturers of audio components, where it occupied no\nspecial place based on quality, design, or price. It also owned 50 percent of the record company Polygram; the German conglom-\nerate Siemens owned the other half. One of the most assertive proponents of developing a compact disc was actually Polygram\u2019s\ndirector of marketing. Polygram was a member of the second tier of firms, behind the leaders CBS and Warner. Aside from Philips,\nthere was little overlap between segments. Toshiba had some ties to EMI, and Sony was connected to CBS Records, but only in Japan\n(Sony would eventually buy CBS Records in 1988). Otherwise, each segment stood on its own. For the Philips executives, the ques-\n\ntion was\u2014or should have been\u2014where, within this fragmented array, they were going to make a profit from the compact disc.\n\nTHE STATE OF PLAY(BACK)\n\nSomeone wanting to buy recorded music in 1979 had essentially two choices, either long-playing vinyl records (LPs) or prere-\ncorded tapes. Tapes came in two varieties, eight-track cartridges or cassettes. Reel-to-reel tape, which had been the original format,\nhad disappeared as a prerecorded form, although it still was the recording technology of choice for professionals and even amateur\naficionados. LPs sold over 300 million units in 1979, eight-tracks 100 million, and cassettes 83 million; they were fast catching up\nto the eight-track. Unlike eight-track, users could buy and record on blank cassettes, making the format more versatile even as it\n\nthreatened the record companies and their contract artists with bootleg alternatives to the prerecorded originals.\n\f"}, "003057.png": {"text": "The Philips executives saw the compact disc as an opportunity for the company, but only if several obstacles could be overcome.\nOne was the issue of a standard, both for the disc itself and the disc player that would be required to make music at home. The\nvideocassette industry, in which the Sony Betamax format competed with JVC\u2019s VHS system\u2014and both for a while with videodiscs\nfrom RCA and Philips\u2014was a contemporaneous example of how competing standards made it difficult for anyone to operate\n\nprofitably. Also, the contest between eight-track and cassettes was still in progress with a similar consequence.\n\n \n\n      \n    \n\n \n\n             \n \n\nPerforming artists Record pressers and Record companies\nh . including tape processors Top 5\nsome famous names Reoord companies, CBS Records\nIndependent Warner Electra/A tlantic\ncontractors EMI\nPolygram\nRCA Reoords\nMany others\nDistributors\u2018retailers\nMany: top distributor\nhad 10% share\nParts Manufacturers Audio component Distributors/retailers\nMany et Many\ny nian y\n\n \n\n \n \n\f"}, "003058.png": {"text": "FIGURE 7.1\n\nMap of the recorded music industry\n\nThough Philips had a head start in laser-based audio, its executives knew that Telefunken, JVC, and Sony were also working on\nincompatible versions of the product. Without an agreed-upon standard, the pace of adoption would be much slower. The record\ncompanies would not want to produce multiple versions of the same music, nor would the potential manufacturers of disc players\nbe as eager to get involved without some guarantee of a large market, another mandate for a single format. So part of Philips\u2019s plan\nwas to get a standard\u2014its own\u2014adopted by all the players in the industry.\n\nThe second potential obstacle was the relationship between cost and price. To be successful, the compact disc would have to be\noffered at a price that would be sufficiently competitive with the alternatives to attract enough customers to make the business\nprofitable. The disc player would also have to be available at a price consumers would pay, even if it cost more than the turntable\nit was replacing. Philips executives believed, with some support from consumer surveys, that compact discs and players could\ncommand a premium price from at least a segment of the market, thanks to superior sound quality and increased durability. They\nwere also certain that the disc players could be produced for very little more than turntables of comparable quality once volumes\nhad grown large enough. The more difficult question was the cost of putting the music on a compact disc and moving it down the\ndistribution channel until it reached the ultimate buyer.\n\nA third issue that was not directly addressed by Philips executives was how, as the market for compact discs developed, Philips\ncould distinguish itself from the legion of potential alternative disc and player suppliers. Without something setting it apart,\nPhilips would be competing on a level economic playing field. Profits would be driven to competitive levels, leaving little or no\nroom for Philips to benefit from its pioneering development efforts. The ultimate financial success of Philips\u2019s strategy would\n\nhinge on how well this last challenge was addressed.\n\f"}, "003059.png": {"text": "DEMAND AND SUPPLY\n\nIn estimating the demand for compact discs, Philips executives focused on buyers of jazz and classical LPs. These consumers\nappreciated the added sound quality of compact discs because their preferred music had a broader dynamic range than rock,\npop, country, or other genres. Within the U.S. market, they bought around 25 million records in 1979, less than 10 percent of the\ntotal number of LPs sold. As a group, these listeners had already shown a willingness to pay a 30 percent premium for digitally\nremastered records, where the improvement in sound was substantially less than between vinyl and compact disc. The executives\nestimated that it would take around five years before even half of this market made the move to compact disc. On the other hand,\nthey knew that some portion of the rest of the music-buying public, accounting for over 90 percent of the total, would ultimately\ntransition to the new technology. They figured that annual demand would exceed 18 million discs by the third year after introduc-\ntion and 120 million by the seventh year. And those figures were for the United States only. If that represented half the global de-\nmand, the global pace might be double that.\n\nBecause of their relationship with Polygram, the Philips executives knew with some accuracy how much it cost to produce an\nLP and a cassette. They estimated that by 1982, the date at which they thought they could begin turning out discs, the variable\ncost structure of an LP or cassette, excluding manufacturing and packaging, would look like the figure shown in table 7.1. Costs for\nthe CD, they believed, would be no different. The royalty paid to artists did not vary from LP to cassettes, and there was no reason\nto assume discs would be any different. The promotion figure of $1.33 also included a charge for profit. Distributors and retailers\ntogether marked the product up around $3.00 before it was sold to the customer. So excluding manufacturing and packaging, the\ncost to the consumer would be around $7.\n\nIn 1979, LP records sold for around $6.75. Assuming inflation ran at 10 percent a year through 1982 (which it did), then in\nthree years the price might rise to around $9 per record. If customers were willing to pay a 30 percent premium for higher-quality\n\nsound, a CD might retail for between $11 and $12. With $7 committed to all costs other than manufacturing and packaging, that\n\f"}, "003060.png": {"text": "left at least $4 to spend making and housing the discs. If Philips could produce discs with packaging below this price, then the\nprice-cost issue would be solved.\n\nHans Gout, the Polygram executive whose enthusiasm for the compact disc project was a driving force within Philips, wanted\neach CD distributed inside a snap-open plastic case referred to as a \u201cjewel box.\u201d At $1.18 per box, the units were costly, considerably\nmore than the cardboard record jacket used for LPs. Gout saw the extra expense for the jewel box as worthwhile to accentuate the\nquality features of the CD. Paying $1.18 for the package left $2.82 to spend on manufacturing.\n\nTABLE 7.1\n\nCost estimates for unit of prerecorded music in 1982\n\nArtists $2.65\nPromotion (including a charge for profits) $1.33\nDistribution $3.00\nTotal $6.98\n\nIn estimating what it would cost to produce a compact disc, the Philips executives did not have much experience to guide\nthem. They knew that in the production of videodiscs, it took several years to get a line operating efficiently; yields improve as the\nsources of contamination are eliminated. They estimated that yields would increase and costs decline until a cumulative 50 mil-\nlions units had been produced, at which point the cost per disc would stabilize at around $0.69 (table 7.2). The first firm to enter\nthe business might profit from moving down the learning curve ahead of its tardy competitors.\n\nThese variable production costs were only one part of the manufacturing equation. The other piece was the cost of the plant\nand equipment necessary to inscribe the music onto the discs. The Philips engineers estimated that it would cost $25 million and\ntake eighteen months to build the first manufacturing line with a capacity of 2 million discs per year. After that, the time would\n\ndrop to one year and the equipment would improve and become less expensive. These reductions would continue for at least five\n\f"}, "003061.png": {"text": "years as each generation of machinery outdid its predecessor. Assuming a cost of capital of 10 percent and a 10-year depreciation\nschedule, the annual equipment cost per disc would drop from $2.50 in 1981 to $0.33 in 1986 (table 7.3). Further increases in\nplant size beyond the 2-million-disc capacity would not lead to significant cost-per-disc reductions.\n\nTABLE 7.2\n\nVariable cost per CD for cumulative units produced\n\nCumulative Units Produced (millions) Cost per Unit\n0-5 $3.00\n5-10 $2.34\n10-50 $1.77 over 50 $0.69\n\nPutting both parts of manufacturing costs together, it is clear that after three or four years, the cost of producing a disc with the\nlatest-generation equipment would drop well below $2.80, the amount that Philips executives calculated record companies could\nafford to spend and still turn out a product their customers would purchase. Economies of scale in production were quite limited.\nFor example, a fourth-generation machine would represent capital investment of $3.73 per unit of disc capacity, or a capital cost\nper disc of roughly $0.75. If cumulative disc output by year four had reached 50 million units, then the variable costs per disc\nwould be another $0.69, bringing the total cost of a disc to $1.44. From the cost side, the compact disc project looked feasible.\n\nLEARNING CURVE OR SLIPPERY SLOPE?\n\nThe picture must have looked rosy for Philips. It solved the standards problem by collaborating with Sony, combining the best\nfeatures of each. It was Sony that insisted on a disc twelve centimeters in diameter, large enough to hold seventy-five minutes of\n\nmusic\u2014enough for Beethoven's Ninth Symphony\u2014a decision classical music lovers have applauded ever since. Although JVC con-\n\f"}, "003062.png": {"text": "tinued for a time with its own format, there was sufficient agreement on the Philips-Sony standard to begin production in 1982.\nThe first music to appear on CD was Billy Joel\u2019s 52nd Street. The Ninth Symphony followed shortly. By the end of the year, more\n\nthan one hundred titles were available.\n\nTABLE 7.3\nEquipment cost per CD\n\nEquipment cost per disc Annual equipment cost per disc at 20% (COC and 10-year depreciation)\n\n1982 $12.50 $2.50\n1983 $8.35 $1.67\n1984 $5.58 $1.12\n1985 $3.73 $0.75\n1986 $2.39 $0.48\n1987 $1.67 $0.33\n\nThe question remained, where was Philips going to make its money? Polygram and CBS/Sony were the first record companies to\nadopt the new medium; they were partners with Philips and Sony in the development effort. The other record companies quickly\nfollowed suit. But none paid a royalty to Philips for its technology. Quite the opposite. Philips and Sony had to persuade them to\ntake up the new product; they were not about to reduce their returns for the favor. No patents protected the technology. It had\nbeen developed at MIT in the 1950s. And the large record companies were the only players in the whole industry who were concen-\ntrated enough to wield some bargaining power. Philips was not in a position to coerce them.\n\nPerhaps it could prosper as a manufacturer of compact discs. As the first mover into the field, might Philips have been able to\n\ntake advantage of its earlier start down the learning curve, producing the discs at a much lower variable cost than companies just\n\f"}, "003063.png": {"text": "beginning to learn the intricacies of achieving high yields by keeping contamination to a minimum? Maybe the first mover could\nachieve a learning-curve advantage sufficient to stay permanently ahead of any competitor. There were a few problems with this\nplan. Although experience did help in raising yields and lowering variable costs, it was offset by the disadvantage of being the first\nto invest in a production line. Here, costs were lower for the latecomer, who did not have to pay the penalty for taking the lead.\n\nThe balance between these two forces would depend on how rapidly the market for CDs developed. Consider the situation of\nan entrant producing discs using a third-generation (year three) technology. Its capital costs per disc would be $1.12, or $1.38\nless than Philips\u2019s first-generation cost of $2.50. (See table 7.3.) If Philips\u2019s cumulative volume of output over the first two years\namounted to 10 million discs, its variable cost at $1.77 per unit (see table 7.2) would be $1.33 below that of the new entrant\n($3.00 in table 7.2). The gains and losses from being the first mover would basically offset one another. If it used third-generation\nequipment, Philips would be level on capital costs and enjoy the full $1.33 advantage on variable costs. On balance, then, Philips\ncould expect to benefit from an initial learning-curve advantage over new entrants. However, as an entrant gained experience and\nmoved down the learning curve, this advantage would start to shrink and would disappear entirely once the entrant had produced\nacumulative volume of 50 million discs. Because it was using later-generation equipment, its capital costs would be lower than\nPhilips\u2019s.\n\nIf the CD market exploded to 200 million or more units per year, then at least some new entrants could rapidly reach a cumu-\nlative output of 50 million. It is unlikely that Philips would benefit from customer captivity, since its important customers were\nthe large, sophisticated, and powerful major record companies. Thus, Philips\u2019s cost advantage would last for less than two years.\nParadoxically, the only condition that might sustain Philips\u2019s learning curve advantage would be a slowly growing CD market, so\nthat it would take years before competitors could reach the 50 million cumulative milestone and complete their passage down the\nlearning curve.\n\nFrom this perspective, the problem with the market for discs was not that it would be too small; it would be too large. Even if\nit had a head start, Philips was not going to sustain an advantage based on being the first mover for more than a few years. Unless\n\nit achieved some measure of customer captivity, there was no reason to think that Philips could keep current customers from\n\f"}, "003064.png": {"text": "taking their business elsewhere. And since plants could be efficiently operated at a scale of only 2 million discs per year, economies\nof scale in production would not be a deterrent to entry. Without captive customers, durable production advantages, or relative\neconomies of scale, Philips would benefit from no competitive advantages as a producer of compact discs.\n\nThe situation was, or should have been, no more encouraging to Philips as a maker of audio components. Philips and Sony were\nthe first to market with CD players, but it took very little time for every other firm in the industry to have a unit available. Since\nall the players used the same technology, they could only differentiate themselves by design, secondary features, and price. These\nattributes are rarely a recipe for profitable investment, especially for a company like Philips, which prided itself on its research and\ntechnology and paid the price in overhead costs.\n\nWith the wisdom of hindsight, it is easy to chide Philips for its compact disc strategy. However, its dream of profiting from\nbeing the first mover in a rapidly developing market is one that has been shared by a number of manufacturing firms. Most have\ndone no better than Philips. Its experience indicates why.\n\nBeing a first mover is very much a double-edged sword. On the one hand, learning curve effects benefit a first mover as its vari-\nable costs decline with cumulative production volume. On the other hand, vintage effects\u2014the fact that plants built later are more\nefficient than earlier ones\u2014count against the first mover. In a large, rapidly growing market like CDs, cumulative volume growth\nand learning are rapid for both first movers and later entrants. A law of diminishing returns to learning shrinks any first-mover\nadvantage, so that the adverse vintage effects come to predominate. At that point, it was certain that the successful compact disc\nbusiness would attract competitors. Philips\u2019s profitability suffered. It might actually have been better off if CDs had been restricted\ntoa niche market in which it would have had the field to itself for perhaps five to seven years. During this interim period, it might\n\nhave been able to earn above average returns, maybe enough to compensate it for its initial development expense.\n\nCISCO LEARNS TO CONNECT\n\f"}, "003065.png": {"text": "Philips\u2019s effort to be a pioneer in the CD market as a manufacturer of discs and players worked out very well for consumers, but\nnot so well for Philips and the other companies that followed it into the market. With the exception of some vinyl-addicted audio-\nphiles, most serious music lovers have been delighted with the convenience and durability of the CD, and the system has replaced\nthe long-playing record as their medium of choice. Though its permanence will be challenged by digital formats and file-sharing\n(piracy), the CD has clearly earned a place in the history of technology, entertainment, and computer storage media.\n\nIn many ways, the experience of Cisco in the networking business has been the mirror opposite of Philips and the CD. Cisco de-\nveloped a product\u2014the router\u2014that could tie together disparate computing systems operating within an organization. Its initial\ncustomers were not consumers buying music, but businesses, government agencies, universities, and other institutions. Almost\nfrom the start, there were other firms in its industry; Cisco was not the only company trying to be a first mover. But Cisco was al-\nways the largest, most profitable, and fastest-growing.\n\nCisco managed to create competitive advantages for itself, which became stronger as its business grew. The advantage of\neconomies of scale never became important for Philips because the CD market was large relative to the efficient plant size of 2 mil-\nlion discs per year. Cisco, by contrast, because of the high software content and attendant high-fixed costs for its routers, enjoyed\neconomies of scale advantages. It managed this advantage brilliantly. Unlike Philips, Cisco earned billions of dollars from its new\nventure, and it made fortunes for those shareholders who got in early enough and got out before the tumultuous decline in its\n\nshare price, which began in the middle of 2000.\n\nNICHE PLAYER\n\nCisco grew and prospered by solving a problem. As computers and computer manufacturers proliferated in the 1970s and 1980s,\ndisparate languages and protocols impeded the ability of systems to communicate with one another. Cisco was founded in 1984\nby engineers at Stanford University who wanted to send e-mail to one another across department networks. They found, however,\n\nthat although the business school and the computer science department both used machines from Hewlett-Packard, they were\n\f"}, "003066.png": {"text": "different models, used different protocols, and could not read each other\u2019s files. So the engineers developed the router, a specialized\ncomputer that could take the output of one system and send it on in translated form so that it could be read by other kinds of sys-\ntems. (Routers actually connect networks, but that detail is not significant here.) As is often the case, solving a problem can be a\npath to riches, provided the problem is widely shared. It turned out that by removing the language barriers between computer sys-\ntems, Cisco made networking throughout the enterprise a reality.\n\nCisco caught another wave that propelled it forward. The same routers that worked within the organization to tie all the\nseparate networks together also enabled communication over the still nascent but rapidly expanding Internet, again between ma-\nchines that were not inherently compatible. Cisco routers allowed companies like Boeing to tie all their systems together in what\nbecame known as an intranet, using the Internet as a transmission mechanism for company data. The impact on Boeing\u2019s work\nprocess was significant, and other companies sought Cisco out to upgrade their own networks.\n\nAcompany that makes life much better for its customers gets handsomely rewarded, provided it can separate itself from\ncompetitors offering similar benefits. In Cisco\u2019s case, the rewards came in sales growth, growth in earnings, and a valuation in the\nstock market that outdistanced both the increase in revenue and income (figure 7.2). In 1990, Cisco had sales of $70 million. By\n2000, revenue had increased to $19 billion, a compound annual rate of 66 percent. Operating income grew at 63 percent per year.\nThe market value of its equity went from $350 million to $450 billion (figures at the end of the fiscal year, which for Cisco has been\nin July), a compound return in excess of 90 percent per year. For a brief period in 1999, Cisco was the largest company in the world,\nmeasured by market capitalization. Unlike Philips, it had not been undermined by competitive entrants.\n\nUnderlying the growth in sales, the high operating margins, the extraordinary return on invested capital, and the enormous\nincrease in its market value was Cisco's dominant position in an expanding market and the competitive advantages on which this\nposition depended. As the creator of the first router, for a while Cisco was the only player in the field. But competitors like Wellfleet\nand 3Com soon appeared. Cisco\u2019s market share fell from 100 percent at the beginning of 1989 to 70 percent in the first quarter of\n\n1994. However, within two years it was back up to 80 percent.\n\f"}, "003067.png": {"text": "Cisco\u2019s market had two elements missing from the CD market\u2014substantial customer captivity and economies of scale. Routers\nare sophisticated pieces of equipment, a complex fusion of hardware and software. A high level of technological expertise was\nrequired to install and maintain the systems, an expertise not widely available except for those customers with large and skilled IT\ndepartments. The others relied on Cisco or its competitors. As they expanded their own internal networks, they naturally turned\nfirst to the vendor whose equipment they already owned, not wanting to incur the risks and costs of developing a relationship\nwith a new supplier. This asymmetry of familiarity was abetted by another feature of routers that made it difficult for customers\nto switch: the routers themselves were not compatible. Cisco routers did not like to talk with their Wellfleet or 3Com cousins, so\n\nthe company or agency that started with Cisco stayed with Cisco. Customers were made captive by complexity.\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n$500 20\n$450 s18\ns400 | a6\n, 8\n2 $350 si4 z\n3 s00 2 2\n$ | S\n\u2018\u201c 3\nz $250 I si0 5\n= 20 Ss os\n\u00abi\n| 3\ns 6\nsso 2 @\n\u00bb \u00bb\n\n1999 \u00ab1991 1992 1993 j99g 1995 1996 1997 1998 1999 2000\n\n \n\nwas Market value, end of fiscal year Revenue summ= Operating income\n\f"}, "003068.png": {"text": "FIGURE 7.2\n\nCisco\u2019s market value, sales, and operating income, 1990-2000 ($ billions)\n\nLike other digital machines, the performance of routers improved rapidly. The hardware and the software got better, faster, and\ncapable of handling more data. Cisco\u2019s larger market share gave it a powerful economies of scale advantage over its competitors in\nwriting the software code and designing upgraded models of the router. Having access to a stable base of customers who made up\nmost of the market for routers, Cisco was in a position to disseminate new technologies far more efficiently than its competitors.\nThis privileged position meant that Cisco could afford to spend more than its rivals to acquire that technology, whether through\nhigher R&D spending or the acquisition of smaller competitors. Cisco pursued both courses aggressively. In its fiscal years 1993-\n96, it bought or took minority stakes in fifteen companies, and in the next quarter, October 1997, it added an additional eight. Not\nall of them worked out, and some were too expensive even using the inflated currency of its own shares, but Cisco was able to keep\nahead of the competition by purchasing what it could not build on its own.\n\nThanks to its economies of scale advantages in distribution, maintenance, and R&D, whether internal or acquired, Cisco was\nable to extend its franchise beyond its original router competence. Sometime in the mid 1990s, local area network (LAN) switch-\ning began to challenge routers as the networking hardware of choice within the enterprise. Cisco bought its way into LAN switches\nand soon became the biggest supplier. In the first quarter of 1994, 3Com had 45 percent of the market, Cisco 35 percent. By the end\nof 1996, 3Com\u2019s share had fallen to 21 percent, and Cisco\u2019s had risen to 58 percent.\n\nCisco\u2019s average pretax return on invested capital during the period 1990-2000 was a giddy 142 percent (figure 7.3).: A heavy\nuser of stock options, Cisco undoubtedly understated its costs by keeping a large share of salary expenses off the income state-\nment. Some skeptics have suggested that if the options had been expensed, Cisco may never have been really profitable. That\ncritique is undoubtedly exaggerated. In July 2000, Cisco had $5.5 billion in cash (up from $50 million in 1990), and investments in\n\nnear cash securities of $14 billion. It had issued no debt over the period, and sold less than $3 billion in net new equity. So however\n\f"}, "003069.png": {"text": "it might have dressed up its income statement by masking the true costs of employment, Cisco profits certainly exceeded its cost\n\nof capital throughout the 1990s.\n\n300%\n\n250%\n\n200%\n\n150%\n\n100%\n\n50%\n\nom%\n1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003\n\f"}, "003070.png": {"text": "FIGURE 7.3\n\nCisco\u2019s pretax return on invested capital, 1990-2003\n\nThe extent of Cisco's profitability throughout the period is apparent from figure 7.3. Even in the year ending July 2000, when\nthe recession had already begun and the stock market experienced a severe decline from its March highs, Cisco was still flourish-\ning. Its revenue of almost $19 billion was up 56 percent from the prior year, and its operating income of $3.2 billion had risen 13\npercent as compared with 1999. Part of these gains were due to a number of acquisitions. Still, there were some troubling signs.\nIts operating margin, at 17 percent, was down below 20 percent for the first time and was only half of what they had been in 1996.\n\nThe problem lay on virtually every line of Cisco\u2019s income statement, but the main culprits were research and development.\n\nTABLE 7.4\n\nCisco\u2019s increased costs as a percentage of sales, 1996-2000\n\nCost of sales Total Change 1996-2000\nCost of goods sold 1.2%\n\nResearch and development 4.5%\n\nSales and marketing 3.1%\n\nGeneral and administrative 0.6%\n\nAmortization of goodwill and purchased intangible assets 1.5%\nIn-process research and development 7.3%\n\nTotal 17.0%\n\f"}, "003071.png": {"text": "CHANGING CLASS\n\nCisco did not one day decide that it should spend more on research and development because it had all these talented engineers\nand wanted to keep them busy. Beneath the decline in margins lay a major change in the nature of Cisco\u2019s business. From in-\nception, it had dominated the market for networking systems within the enterprise. Its original entry was the router, which it\nhad invented. But as the demand for increasing scale and bandwidth grew within companies and other organizations, Cisco had\nbeen able to adapt to new technologies, like the LAN switch. By the late 1990s, the market for enterprise networking systems\n\nhad become relatively mature. Most of the organizations that wanted a network already had one in place, and the advantages of\nupgrading the systems began to diminish. Cisco was not in a position to expand by taking business from its competitors, since it\nalready owned the lion\u2019s share of the market. If it wanted to grow\u2014and a company with a history of growth like Cisco\u2019s is not going\nto be content just maintaining its sales level\u2014it would have to find new markets.\n\nFrom where Cisco stood in the late 1990s, the natural move was to get outside the confines of corporate, university, and other\nuser organizations and into the larger world of the telecommunications service providers. These firms included the traditional\ntelephone companies (especially the former Bell operating companies), their recently hatched competitors (including WorldCom,\nSprint, MCI, and the competitive local exchange carriers), the Internet service provider firms (AOL, Earthlink, and countless oth-\ners), and other companies whose essential business it was to move voice and data across distances for their customers. They were\nall in the process of building up the communications infrastructure to handle an unprecedented increase in data transmission\nthat was anticipated by virtually everyone. The demand of this \u201ccarrier class\u201d of companies for networking equipment was going\nto be enormous, dwarfing the needs of the enterprises that Cisco served so profitably.\n\nCisco took its technological expertise, its marketing talents, and its enormous hoard of cash into the world of carrier-class cus-\ntomers. It ran into rough going very quickly because the differences between the enterprise market and the service provider arena\nwere much greater than Cisco had anticipated. First, there were entrenched and sophisticated competitors. Lucent, Northern\n\nTelecom, and others had been providing switching equipment to telephone companies for decades. They were large, experienced,\n\f"}, "003072.png": {"text": "and had established relationships with their customers. Although they did need to move their product offerings to data transmis-\nsion and packet switching from their traditional analog switched equipment, they gave every indication that they were up to the\ntask. In addition to the usual suspects, Cisco also had to face firms younger than itself, eager to exploit their own technological\nprowess, and backed by IPO money from an enthusiastic investing public. As a new entrant into this market, Cisco was without\nthe critical competitive advantages it enjoyed in the enterprise market. It had no captive customers; so far as established customer\nrelationships were concerned, it was the outsider looking in. Without this kind of customer base, Cisco had no economies of scale\nin distribution or service support. Because Cisco was working on new products for new customers, it had no economies of scale ad-\nvantages in research and development either.\n\nUnder these circumstances, the best Cisco could expect was to operate on a level playing field. The established telecommuni-\ncations providers were big, powerful, wealthy, and technologically sophisticated. Cisco would not be able to re-create the relation-\nships it had with many of its enterprise customers, where it was the expert and they were only too happy to have a supplier take\nthe technology burden off their shoulders. The new companies in the telecom world, the fiber-optic carriers and Internet service\nproviders, were large and technologically sophisticated even though they were neither profitable nor established. Like the major\nrecord companies in the CD market, these customers were unlikely to allow themselves to be captive to any single supplier. Even\nif they had, Cisco would not have benefited, since it was the existing telecommunications equipment firms, like Lucent, Nortel,\nSiemens, and Erickson, not Cisco the entrant, who had the relationships with the carriers.\n\nCisco entered the carrier-class business the old-fashioned way: it bought its way in. It was aggressive on pricing and generous\non financing. It gave its carrier class customers easy credit terms to pay for their equipment. Cisco was rolling in cash and seemed\nable to afford the financing costs. But like many large, well-financed companies willing to use their balance sheets to overcome\ninitial competitive disadvantages, Cisco\u2019s experience was not a happy one. Kodak\u2019s entry into copiers, AT&T\u2019s move into data-pro-\ncessing services and computers, Xerox\u2019s pursuit of office automation, IBM\u2019s attempts to unseat Microsoft in software and Xerox in\ncopiers are all examples of highly regarded, deep-pocketed companies failing in markets that they decided to enter despite obvious\n\ncompetitive disadvantages. As Cisco learned, deep pockets are seldom a competitive advantage.\n\f"}, "003073.png": {"text": "The speed and brutality with which this message was conveyed to Cisco were amplified by historical circumstances. In what\nseems obvious after the fact but was overlooked by almost everyone at the time, Cisco\u2019s carrier customers as a group were adding\ntoo much capacity. Not only were they seduced by an unduly optimistic forecast in the growth of demand\u2014Internet use was pro-\njected to double every three months\u2014but they ignored all the other people in the business who were also building an infrastruc-\nture to supply this anticipated demand. The great stock bubble of the late 1990s and the collapse of 2000-2002 were led up and\nled down by telecommunications and associated businesses. When some of the nascent ISP and telecommunications firms went\nbust, Cisco was left holding large and unsecured debt. More troubling still, some brand-new pieces of Cisco equipment found their\nway, via liquidations of bankrupt firms and the eBay auction platform, into the gray market. Cisco had to compete against its own\nproducts for what limited business remained in the carrier sector. Its strong balance sheet, which had allowed it to be so generous\nwith credit, had come back to haunt it.\n\nHow bad did things get? Cisco\u2019s worst year was 2001, when it reported an operating loss of $2 billion, before taxes. Some of that\nstemmed from a restructuring charge of slightly more than $1 billion. For a company accustomed to making as much money as\nCisco, with enormous margins on sales, assets, and invested capital, reporting a loss like that was a blow, even if Cisco had plenty\nof company in 2001, a dismal year for technology firms. Cisco\u2019s results were an amalgam of its old business, network equipment to\nenterprises, and its new venture into equipment for carriers. The true extent of its losses on the carrier side of the business, much\n\ngreater than the total of $2 billion it reported, were masked by its continued profitability in the enterprise market.\n\nMAKING A COMEBACK\n\nBefore the steep decline in its share price and the corresponding drop in earnings, Cisco\u2019s management had won top marks from.\n\u2018Wall Street analysts and other industry observers for its ability to handle profitable growth and maintain its dominant position in\nan expanding industry. Now John Chambers and his team had to shift gears and manage during an economic and industry down-\n\nturn. It took them several quarters to make the adjustment, but they were able to turn things around. Recognizing that the decline\n\f"}, "003074.png": {"text": "in revenue was more than just a minor cyclical incident, they moved to cut expenses and restore operating margins. They pulled\nCisco back from the parts of the carrier-level networking equipment business in which it operated at a competitive disadvantage,\nwhere in order to make its original dent Cisco had had to buy its way in. Cisco did retain much of the router business. Even though\nJuniper Networks made some inroads here and became a legitimate competitor, Cisco continued to hold over half the market.: Its\n\ncost of goods sold began to shrink as the unprofitable parts of its carrier business were eliminated. (See figure 7.4.)\n\n$8\n\n~\n8\n\n30%\n\nRevenue\n2 8 8 \u00a3\u00a3 & &\n\npo\neo = eo he &\n233 3 3\nOperating Income Margin\n\n \n\n  \n\nJul-01\nOct-Ol\nJan-0;\nApr-02\n\nJul\nOct.\nJan-0.\nApr03\n\nJul-0:\n\nwees Reverie\n\n \n\nOperating Income Margin\n\f"}, "003075.png": {"text": "FIGURE 7.4\n\nCisco\u2019s quarterly revenue and operating income margin, October 1999 through July 2003\n\nManagement also cut into overhead expenses. These had ballooned as a portion of revenue when sales declined, starting in the\nApril 2001 quarter. It took almost a year to bring these costs down below 45 percent of revenue, and another six quarters to get\nthem down near 40 percent, which was still higher than they had been in the heady days before sales dropped. Including one-time\ncharges, Cisco\u2019s operating margins fell from 17 percent in 2000 to a loss in 2001 but recovered up to 26 percent in 2003. This was\nCisco\u2019s best year since 1999, and though it might never return to the glory days of the mid 1990s, its management had proved that\n\nit could operate in rough waters more successfully than AT&T, Kodak, or Xerox.\n\nTOASTERS?\n\nAlmost everybody makes toasters, even Philips (though not Cisco). There are more than fifty brands of toasters available in the\nUnited States. The models vary from simple and intentionally retro in design to futuristic, feature-laden, and whimsical. At a\nminimum, all are supposed to take a slice of bread and brown it without burning. Since most of the toasters come from compa-\nnies with extensive small appliance lines, and a few from diversified giants like Philips and GE, the financial statements do not\nreveal how profitable toasters are to their manufacturers. But with no barriers to entry here, it is unreasonable to assume that any\nmanufacturer is earning an exceptional return on its toaster assets. Though they differ from one another in functional and design\nfeatures, one toaster is pretty much like another. If there were a sudden spurt in demand for one style or one functional element\n\n\u2014toasters that sing when the bread is ready\u2014then it would not be long before every manufacturer was offering a crooning toaster.\n\f"}, "003076.png": {"text": "How different is a complicated and expensive piece of network equipment\u2014a router, smart hub, or LAN switch\u2014from a\ntoaster? Initially very different, but ultimately, not so different at all. The success of Cisco in its original business attracted new\nentrants, most of whom could not put a dent in Cisco\u2019s performance during the first fifteen years of operations. Cisco\u2019s customers\ncould not operate its equipment effectively without extensive technical and maintenance support. They were not sophisticated\nenough to mix and match communications equipment the way families do with household appliances. Also, the need to develop\nsuccessive new generations of software and hardware makes fixed costs a permanently large part of total costs, and thus a source\nof economies of scale. (In contrast, in CD manufacturing, plant and equipment were a once-and-for-all expense. Economies of\nscale topped out at a two-million-disc-per-year plant.) All these factors created competitive advantages for Cisco, and put up barri-\ners to entry in its enterprise-class business.\n\nBut it seems clear that these advantages diminish over time. Equipment becomes more reliable and easier to use. Support\nand service costs decline. Compatibility across company product lines increases as equipment functions become standardized.\nResearch and development costs decline as product lines mature. Customers become more confident in their use of equipment\nand more willing to try new, lower-cost suppliers. Some of these changes have already affected Cisco. Newer companies, especially\nJuniper Networks, have started to take small chunks out of Cisco\u2019s business by offering even more cutting-edge technology, and\nolder, established companies like Lucent, Alcatel, and Nortel, despite myriad problems, did not disappear.\n\nThough Cisco recovered nicely from the telecom bust of 2001, it did not return to its glory days of the mid 1990s, when its rate\nof growth and enormous returns on investment propelled it briefly to the top of the market capitalization ranks. If the experience\nof other industries is indicative, the trends identified above will ultimately eliminate Cisco\u2019s competitive advantages entirely. No\nmatter how complex and unique a product seems at the start, in the long run they are all toasters.\n\nIn the CD market, Philips never had the kind of honeymoon that Cisco enjoyed. It never established customer captivity; its cus-\ntomers were large and sophisticated, and its product did not require significant support. It also never benefited from economies\nof scale. Distribution and service support for raw, unrecorded CDs accounted for a tiny share of the costs, and while the original\n\ndevelopment costs may have been high, continuing R&D expenditures were negligible. Learning curve\u2014related cost advantages,\n\f"}, "003077.png": {"text": "Philips\u2019s only remaining hope of competitive advantage, were undermined by the rapid-growth CD market, which allowed its com-\npetitors also to move quickly down the experience curve. Philips confronted a toaster world almost immediately.\n\nIn both these instances, the standard measures of market attractiveness are not what mattered for success. Neither huge size\nnor rapid growth were critical characteristics for strategy formulation. Nor were core competences the issue. Both Philips and\nCisco brought high levels of relevant technical capabilities to the CD and network equipment markets, and only one of them suc-\nceeded, for a time, in producing exceptional returns.\n\nWhat matters in a market are defensible competitive advantages, which size and growth may actually undermine. Size without\ncompetitive advantages was of no use to Cisco in the market for carrier-class equipment. Rapid growth in the CD market actually\nundercut the possibility of competitive advantages for Philips. Nor is differentiation a competitive advantage. Toasters are highly\ndifferentiated, but there are no barriers to entry and no competitive advantages in the toaster market. When products come to take\n\non these characteristics of toasters, as most of them do over time, exceptional returns disappear.\n\f"}, "003078.png": {"text": "CHAPTER 8\n\nGames Companies Play\n\nA Structured Approach to Competitive Strategy\n\nPART I: THE PRISONER'S DILEMMA GAME\n\nOur discussion so far has centered on competitive advantages: what they are; how to decide whether any firms in an industry\nenjoy them; how to exploit them.\n\nFor markets where there are no competitive advantages, the only strategy is a relentless focus on operational efficiency. The\npersonal computer industry after 1990 and Philips\u2019s foray into the compact disc market are examples of companies that took this\npath, or should have.\n\nBusinesses like Wal-Mart in retailing and Coors in brewing did enjoy competitive advantages in their local markets. Their\nstrategic challenge was to sustain and, if possible, to extend them. As we have seen, Wal-Mart was more successful than Coors at\n\ndoing this. (These single dominant firms are at location 2 in figure 8.1.)\n\f"}, "003079.png": {"text": "\u2018We turn now to more interesting and difficult situations, those in which a few firms enjoy competitive advantages within the\nsame industry or market. Though one may be bigger than the others, the size and power distinctions are not great enough to make\neven the largest of them immune from assault by its competitors. These conditions are likely found in local service industries, like\nbanking, retailing, and health-care systems, in consumer product markets, and often in entertainment and the media\u2014the major\nTV networks, movie studios, and record companies. These circumstances are thorny to analyze and challenging to manage effec-\ntively. Strategic success depends on the deft handling of conscious mutual interactions among firms, which can encompass both\ncompetition and tacit cooperation. (These situations are at location 3 in Figure 8.1. The Cooperating/Bargaining elements will be\ntreated in a later chapter.)\n\nAn examination of the rivalry between retailers Home Depot and Lowe\u2019s can reveal the range of issues that are involved when a\nsmall number of competitors interact with one another. The dimensions of that rivalry include decisions about individual pricing\nat the store level, particularly when a Home Depot and a Lowe\u2019s are near one another, about product line extensions, about store\nlocations, about supplier relationships, and about levels of advertising. For every issue, the outcome of any action by Lowe\u2019s de-\npends upon how Home Depot chooses to respond, and vice versa.\n\nTo see how complicated the strategy is for making these decisions, consider an ostensibly simple case. If Lowe\u2019s opens a store\nin a market that Home Depot has previously had to itself, an aggressive price response by Home Depot will have serious conse-\nquences for the new store\u2019s profitability. Home Depot could decide to carry its response further by opening stores in markets where\nLowe\u2019s has been unchallenged. Lowe's initial foray into Home Depot's territory would turn out to have been a very unfortunate\nmove. But the countermeasures could themselves be costly for Home Depot, especially if Lowe's decides to retaliate in kind with\n\nlower prices and more store openings. Anticipating these responses from Lowe\u2019s might temper Home Depot'\u2019s behavior.\n\f"}, "003080.png": {"text": "   \n  \n\nManage Competitive\nAdvantage @)\n\nGame Structure!\nSimulation\n\nSingle Dominant Firm?\n\nYES Prisoner\u2019s Dilemma\nEntry/Preemption\nCooperation!\nee\nCOMPETITIVE @) raining\nADVANTAGE?\n\n \n\n(Many Competitors)\nOperational Effectiveness:\nEfficiency, Efficiency, Efficiency\n\nFIGURE 8.1\n\nCompetitive interactions within the competitive universe\n\nYet Home Depot might calculate that any restraint on its part would only encourage Lowe's in its penetration of Home Depot\u2019s\nmarkets, leading to price and location wars everywhere, which would be painful for both companies. Indeed, Home Depot, by\nadopting a truly fierce competitive stance, might even succeed in deterring Lowe's original expansion and never actually need to\n\nlower prices and open stores whose principal purpose is retaliation.\n\f"}, "003081.png": {"text": "On its part, Lowe\u2019s might consider an entirely different set of strategies, avoiding a direct confrontation with Home Depot\nand limiting competition by having each chain concentrate in nonoverlapping market areas. By not engaging in a price war and\nby avoiding duplicative store overhead costs in a number of markets, both companies might walk away with significantly richer\nprofit margins.\n\nBut, to look at the interactions one more time, what if Home Depot were to interpret Lowe's restraint as weakness? Might it take\nrestraint as an invitation to be more aggressive and to move into all of the markets Lowe's had to itself? If that were the case, then\nLowe\u2019s strategy of restraint might prove to have been an unmitigated disaster.\n\nThis situation is frustrating in its complexity. Lowe\u2019s must worry about what Home Depot is likely to do, which depends, in\nturn, on how Home Depot interprets Lowe\u2019s actions. This interpretation depends on how Lowe's reacts to Home Depot\u2019s behavior,\nthe signals that Lowe\u2019s sends, and Home Depot\u2019s own readings of the business imperatives, which are influenced by Home Depot\u2019s\nculture. Moreover, all of these same factors apply identically to Lowe's readings of the signals Home Depot sends and on Lowe\u2019s\nculture. There is the danger here of infinite regress, mirrors reflecting mirrors ad infinitum. To bust out of this trap requires a clear\n\nfocus and some useful simplifying assumptions.\n\nPRICE COMPETITION AND THE PRISONER'S DILEMMA\n\nFortunately, the essential dynamics of most competitive interactions revolve around one of two issues: price or quantity. Of these,\nprice competition is the most common form of interaction among a small number of competitors. There is a familiar dynamic to\nmost of these situations, which we can get a sense of from this simplified, schematic case.\n\nAssume that the offerings of these competing firms are basically equivalent. Then, so long as they charge the same for their\nproduct, the competitors divide the market equally. If they all charge a high price, relative to their costs, then they all earn high\n\nprofits. If they all charge a low price, they still divide the market, but now each of them earns less. However, if one firm decides to\n\f"}, "003082.png": {"text": "charge a low price while others charge more, we can assume that the firm with the low price captures a disproportionately large\nshare of the market. If the additional volume more than compensates for the smaller profit per unit due to the lower price, then the\nfirm that dropped its price will see its total profits increase. At the same time, the firms that continue to charge a high price should\nsee their volume drop so much that their profits will be less than if they also charged the low price. The essence of price competi-\ntion among a restricted number of companies is that although there are large joint benefits to cooperation in setting high prices,\nthere are strong individual incentives for firms to undermine this cooperation by offering lower prices and taking business away\nfrom the other competitors.\n\nCompetitive situations\u2014games\u2014of this sort take the name prisoner\u2019s dilemma because they imitate the choices faced by two or\nmore accused felons who participate in a criminal activity, are caught, and are then interrogated separately. If they all cooperate\nwith one another and refuse to confess, there is a strong probability that they will beat the charge, and they can expect a light\nsentence. But each of them can negotiate a deal with the police for even less jail time if he confesses and testifies against his con-\nfederates. The worst case is for an accused to maintain his innocence but have one of his confederates confess. Given these alterna-\ntives, there is a powerful temptation to abandon the group interest and confess. The incentive is both positive (get less jail time by\nconfessing) and defensive (you had better confess because your friends can hang you out to dry if they confess and you don\u2019t). So\nit is no wonder that maintaining the cooperative position is difficult, both for accused felons and for competitive firms. The usual\n\noutcome is what is referred to in game theory as a \u201cnoncooperative equilibrium.\u201d\n\nFORMAL DESCRIPTIONS OF COMPETITIVE INTERACTIONS\n\nTwo models are widely used for formal presentations of the information relevant to describing competitive interactions. The\nfirst, known as the \u201cnormal\u201d form in the language of game theory, is to present the information in a matrix. The second, called the\n\u201cextensive\u201d form, lays out the elements of the competitive interaction within a tree structure (this model is described in chapter\n\n11). Although a prisoner\u2019s dilemma game can be modeled using the extensive form, it is more appropriate to use the matrix form.\n\f"}, "003083.png": {"text": "In price competition, the sequence of moves is not significant. The situation does not evolve over time in a way that requires long-\nrange planning or a long-lived commitment of assets. Changing prices can be done at any time by competitors in any sequence.\nThe matrix form of a game presents a picture that is appropriate to these kinds of simultaneous, repeatable changes.\n\nBecause of its two-dimensional design, a single matrix can only represent two competitors, one on the horizontal side, one\non the vertical. The interaction between Lowe's and Home Depot is depicted in figure 8.2. In this example, Lowe\u2019s occupies the\ntop side (horizontal dimension) of the matrix, Home Depot the left side (vertical dimension). Across the top is information about\npossible courses of action for Lowe\u2019s; in this example, the information is the price levels Lowe\u2019s may charge for a typical shopping\nbasket of products. If the relevant price choices are $115 and $105 per basket, then each column in figure 8.2 represents a possible\nprice for Lowe's.\n\nHome Depot's corresponding choices are displayed on the left-hand side of the matrix (assuming that it is limited to the same\n\ntwo alternative prices as Lowe's, $115 and $105), with each row representing Home Depot's pricing decisions.\n\f"}, "003084.png": {"text": "LOWE'S\n\n$115 $105\n\n$210\n\nSUS\n\n$120\nHOME DEPOT\n\n$150\n\n$105\n\n$150\n\n \n\nFIGURE 8.2\n\nThe matrix (or normal) form of the prisoner\u2019s dilemma\n\n \n\f"}, "003085.png": {"text": "Each box in the matrix corresponds to one particular outcome of the actions; it is an intersection of a decision by Lowe\u2019s and\none by Home Depot. Since these are pricing decisions, the outcomes are the levels of income (in this case, gross profit) for each\ncompany when certain prices are chosen. If both companies decide to price the goods in a typical shopping basket at $115, then\nthe outcome in box A is that each earns $200 in gross profit per ten customers in the market. (The outcome for the player at the\ntop, in this case Lowe\u2019s, is customarily located in the upper right-hand corner of the box; that for the player on the side, in the lower\nleft-hand corner.) The other boxes represent outcomes from the other possible combinations of pricing decisions.\n\nThe outcomes themselves depend on the economics of this business. We are assuming that the cost of goods sold for the basket\nis $75. If both charge $115, they realize a gross profit of $40 per basket. If they divide the customers equally, then for every ten\ncustomers in the market, each firm captures five of them and earns $200 in gross profit. But if one firm charges $105 and the other\n$115, the firm with the lower price wins 70 percent of the customers, leaving only 30 percent for its competitor. If Lowe\u2019s price is\n$105 and Home Depot's is $115, as in box B, then Lowe's sells seven baskets to these ten customers and earns $30 gross profit on\neach basket, for a total of $210. Home Depot, with 30 percent of the market, earns $120 in gross profit ($40 per basket times three\ncustomers). In box C, the pricing and profitability are reversed, with Home Depot coming off best. If both firms charge $105, then\neach has a gross profit of $30 per basket, sells to five customers, and earns a gross profit of $150, as in box D.\n\nThe four boxes of the matrix represent the economic consequences of each of these combined pricing decisions. But profit may\nnot be the only thing that concerns management. They may, as an example, care more about the absolute level of sales. Or they\nmay focus on relative performance, either market share or profits, because beating Home Depot may be a deeply ingrained part of\nLowe\u2019s culture (or vice versa). It is naive to think that the bottom line is everybody\u2019s primary concern. The outcomes in the matrix\nshould be adjusted, wherever possible, to account for these other motivations. It would be easier if all the actors were economically\nrational and never deviated from a focus on profitability. In fact they are not, and the payoffs really need to be calculated to reflect\nthe motivations driving the people making the decisions. Ultimately, it is the culture of Home Depot that determines the values of\n\ndifferent outcomes for Home Depot, the culture of Lowe\u2019s that determines the values of outcomes for Lowe's.\n\f"}, "003086.png": {"text": "As we said, the matrix form is helpful for presenting a static picture of the consequences of choices. It is less helpful in depict-\ning the sequence in which those choices are made. When choices are made virtually simultaneously\u2014one-shot situations\u2014the\nmatrix is a useful model. It is also good for representing situations that repeat themselves: Home Depot lowers prices in round one\nand Lowe's responds; Lowe's lowers prices in round two and Home Depot responds; and so on.\n\nAfter a few rounds of playing the prisoner\u2019s dilemma, intelligent competitors should be able to anticipate how the rival will\nreact, and adjust their actions accordingly. The matrix is useful because it focuses on the consequences of choices, and allows the\ncompetitors to compare the outcomes.\n\nThe dynamic of this situation is clear. Although there are substantial benefits to cooperation\u2014everyone charges a high price\n\u2014there are also powerful incentives for individual competitors to deviate from this cooperation by reducing prices, gaining addi-\ntional volume, and increasing their profits. This incentive is offensive\u2014the deviating firm benefits from its lower price if the other\ncompanies continue to cooperate and maintain a high price. It is also defensive\u2014if other firms are going to lower their prices, then\neach firm needs to protect itself by matching or even anticipating the lower price. The benefits of cooperation are constantly being\nundermined by the temptations to deviate and take market share. The equilibrium outcome of this game, in theory and often in\npractice, is a breakdown of cooperation and an industry mired in low prices. And once this low-priced equilibrium is reached, it is\nhard to escape from it. Any individual firm that tries to raise prices will lose so much of its business to low-priced competitors that\n\nits pioneering efforts lead to lower, not higher, profits.\n\nREACHING EQUILIBRIUMS\n\nThe matrix form is ideal for examining equilibriums\u2014outcomes that are stable because no competitor has an obvious incentive to\n\nchange its action. These equilibriums depend on two conditions:\n\f"}, "003087.png": {"text": "+ Stability of expectations. Each competitor believes that the other competitors will continue to adhere to their\npresent choices among the possible courses of action.\n+ Stability of behavior. Given the stability of expectations, no competitor can improve its outcome by choosing an\n\nalternative course of action.\n\nThe two conditions work together; if no competitor has a motive to change its current course of action (stability of behavior),\nthen no change will occur, confirming the stability of expectations.\n\nThis concept of the likely outcome to a competitive situation is referred to in game theory as a \u201cNash equilibrium,\u201d after its\ndeveloper John Nash of A Beautiful Mind and Nobel Prize fame. In the Lowe\u2019s-Home Depot example, imagine that the current\noutcome has Lowe\u2019s at $115 per basket, Home Depot at $105 per basket (box C). If Lowe\u2019s expects Home Depot to keep its price at\n$105, Lowe\u2019s can improve its position by lowering its price to match Home Depot. With both at $105, they split the market and\nLowe's gross profit rises from $120 to $150. Clearly, with Lowe's able to improve its situation by changing its price, the original\nsituation is not an equilibrium. If Lowe\u2019s were to remain at $115, Home Depot would have no motivation to change from $105, so\nits position would be stable. But why would Lowe's not lower its price? For an equilibrium to exist, all the competitors must be sat-\nisfied with the status quo.\n\nThe situation is also unstable in box B, in which it is Home Depot that is charging $115 and capturing only 30 percent of the\nmarket. The more interesting situation is in box A. Here both competitors charge $115, split the market, and earn $200 in gross\nprofits. Their joint total of $400 is the highest of the four possibilities. But if each believes that the other will maintain a price of\n$115, it makes sense for it to lower its price to $105, win 70 percent of the market, and pocket $210 rather than $200. So this situa-\ntion is also not an equilibrium, since our second condition\u2014stability of behavior\u2014is not in place. The only equilibrium outcome is\n\nin box D, where both companies charge $105 per basket and earn $150 in gross profit for ten customers in the market. It makes no\n\f"}, "003088.png": {"text": "sense for either of them to deviate from this position and charge $115, because their gross profit would drop from $150 to $120.\nSince neither has an incentive to change, the first condition\u2014stability of expectations\u2014is also fulfilled.\n\nThe problem for our competitors is that neither does particularly well in this position, and their joint incomes are the lowest of\nthe four alternatives. It is possible for them to achieve higher profits, but that requires more sophisticated strategies than simply\npursuing their own most profitable course without regard to the competition. We will turn to these strategies later in the book. But\neven with more profitable approaches available, there will always be an incentive for individual competitors to deviate from these\nostensibly superior outcomes.\n\nThe matrix form for presenting competitive information provides a straightforward approach to analyzing whether the\ncurrent action choices and resulting outcomes are likely to be stable. Firms in situations with a few identifiable competitors can\nconstruct a matrix, place themselves and the other players into the matrix, and see whether the current situation is an equilib-\nrium. If the answer is no, if it is clear that any player has an incentive to change its current action choices, then the firm doing\nthe analysis can anticipate and prepare for such change. If the change has unfavorable implications, then the company can look\nfor ways to alter the current situation to prevent such changes. For example, in our Lowe\u2019s\u2014Home Depot case, if Lowe\u2019s thinks\nthat Home Depot is preparing to lower its price to gain market share (move from box A to box C), Lowe\u2019s can announce that it will\nmatch whatever price Home Depot offers. That announcement will alert Home Depot that its expectations of stability on Lowe\u2019s\npart are mistaken, and it should reconsider its price cut.\n\nThe current outcome may look stable but not desirable. Instead of anticipating change, the company can look to induce its\ncompetitors to alter their actions and produce a more favorable outcome. In either case, and for competitive situations in general,\n\nan important step in strategic thinking is to examine the current situation to determine the extent to which it is an equilibrium.\n\nADDITIONAL PULLS ON EQUILIBRIUM\n\f"}, "003089.png": {"text": "Situations like this one, in which there are large joint benefits from cooperation but strong individual incentives to deviate, are the\nmost common form of competitive interactions. Our informal impression is that 80 to 90 percent of competitive interactions fit\nwithin the scope of this model. They almost invariably arise when there is direct competition among a restricted number of firms.\nWhen prices are very low and margins are small, the benefits of capturing additional business may not be large enough to make\nindividual price cutting a profitable strategy. At that point, cooperation on pricing will be relatively easy to achieve and self-rein-\nforcing. But as prices and profit margins rise, the gains from adding volume by cutting prices becomes more attractive. At some\npoint, individual competitors will not be able to resist temptation, which is why sustaining cooperation on pricing is difficult.\nBecause these situations are so common and troublesome, handling them well\u2014achieving and maintaining the cooperative out-\ncome, where everybody charges the higher price\u2014is the most important skill that interacting competitors can develop.\n\nCompetition with these characteristics can take many forms other than cutting prices. In pursuit of market share, firms can\nspend more on advertising, on deploying a sales force, on enhancing the product, on longer warranties, on additional special fea-\ntures, and on anything else that makes the product more saleable, all of which are costly deals with the customers. In each case,\nan individual firm is willing to cut its margins in the expectation that the additional volume it wins will more than make up the\nforgone profits by charging less or spending more. And in each case, the firms as a group would benefit by forgoing the aggressive\nmove to increase volume at the expense of the others. Still, the incentives for the individual firm are real and powerful, provided\nthe margins are large, which is why it is difficult to sustain cooperation for controlling the costs of unconstrained competitive\nspending.\n\nCompetition for resources often follows a similar pattern. Baseball owners as a whole benefited from mutual restraints on\nbidding for players, restraints embedded in the \u201creserve clause\u201d that kept players from leaving teams at the end of their contracts.\nBut with the advent of television and additional sources of revenue, the restraint began to fade. Even before the reserve clause was\neliminated in 1976, the owners had competed with one another by offering large bonuses for new players. After \u201cfree agency\u201d be-\ncame the rule, the demand for players who had played out their contracts became intense and salaries exploded, doing miraculous\n\nthings for the investment accounts of star players but taking a large bite out of the teams\u2019 collective profitability.\n\f"}, "003090.png": {"text": "TAMING THE DILEMMA\n\nDespite the incentives to deviate and the ease with which competitors arrive at a negative equilibrium, there are steps that can be\ntaken to reduce the impact of the prisoner\u2019s dilemma, if not eliminate it entirely. Fortunately, competitive interactions evolve over\ntime. So it is possible to change the environment by making adjustments that support cooperation and control noncooperative be-\nhavior. These adjustments work by making deviant behavior less rewarding and cooperation less costly.\n\nAdjustments\u2014changing the rules, the payoffs, the players, or any of the other key factors\u2014fall into two categories: structural\nand tactical. Structural adjustments are prior arrangements that directly limit the consequences of deviant behavior. Tactical\nadjustments are prior commitments to respond to deviations by a single firm. Their purpose is to reduce the benefits of deviation\n\nand lead the transgressor back to cooperation.\n\nADJUSTING THE STRUCTURE\n\nGiven the emphasis we have put on local dominance, it should be no surprise that the most elegant structural adjustment is for\ncompetitors to arrange their businesses to stay out of each other\u2019s way by occupying separate and distinct niches in the market.\nThese niches can be defined by geography, by field specialization, even by times of the day. A striking example of distinguishing\nbetween segments of the same market was Pan Am\u2019s scheduling decision when it entered the New York-Boston air shuttle busi-\nness, where Eastern Airlines had previously operated alone. Pan Am organized its flights to depart at the bottom of the hour, thirty\nminutes away from Eastern\u2019s. The move discouraged Eastern from trying to win Pan Am customers by cutting its prices, since a\nbusiness traveler deciding to fly on the half hour was less likely to wait the extra time, even for a lower fare (for which his or her\ncompany, not the traveler, was paying). If Eastern did drop its fares, it would lose much more revenue by giving discounts to cus-\n\ntomers who would fly with it in any case than it would capture by wooing a few from Pan Am. The subsequent history of shuttle\n\f"}, "003091.png": {"text": "competition has born out the wisdom of Pan Am\u2019s strategy. Even as ownership has shifted from Eastern to USAir and from Pan Am\nto Trump to Delta, fares have been high and stable, and the offset departure times have been maintained.\n\nRetailers and other service providers who cluster within a geographic region and avoid major overlaps with competitors are\nliterally staying out of each other\u2019s way. Wal-Mart\u2019s initial concentration on markets it could dominate led both to economies of\nscale advantages and to limiting the temptation of price wars with other retail chains that have only a small presence on Wal-\nMart\u2019s turf.\n\nConcentration on nonoverlapping product niches serves the same purpose. Sotheby\u2019s and Christie\u2019s missed an opportunity to\ndivide up the auction art market into areas of specialization, like Greek and Roman antiquities for one and Egyptian and Middle\nEastern for the other, Italian Renaissance and Northern Renaissance, and so on. Had they pursued that strategy, each would have\ndeveloped expertise, contacts, and reputation in its areas and been the natural choice for a seller of art within that special field.\nEach would have had little to gain and much to lose by cutting prices, since their clientele would not overlap. They would not have\novertly colluded on setting prices, which damaged their business and their reputations and created a literal prisoner\u2019s dilemma for\nsome of them. (We discuss the auction houses in more detail in chapter 15.)\n\nThe first structural adjustment to make, then, to escape the prisoner\u2019s dilemma is to avoid direct product competition. The\nadjustment can actually increase consumer choice, as in the Pan Am decision to fly on the half hour. It also can cut duplicative\noverhead, as in the case of the expertise needed in the auction houses, and enhance economies of scale, as in the examples of Wal-\nMart and Coors, where their advantages diminished as they moved further afield.\n\nCustomer loyalty programs, if properly designed, are a second structural adjustment to limit the consequences of competitive\nprice reductions. For example, frequent-flier programs offer customers benefits like free flights or upgrades as they accumulate\nmiles flown on a particular airline. Two critical aspects in the design of these programs are generally absent: first, rewards must be\ntied to cumulative, not merely current, purchases so that they build customer loyalty over time; second, the rate at which rewards\naccumulate should increase with increasing volume. This last point is important, because if each mile flown earns the same unit\n\nof reward, the program is simply a general price discount. But if fliers earn rewards at an accelerating rate as they accumulate more\n\f"}, "003092.png": {"text": "miles, the incentive to book on their primary airline\u2014to be loyal customers\u2014is strengthened. They become less susceptible to the\nlure of discount flights on other carriers, and competing airlines are less likely to offer the lower-priced fares, since they end up\nreducing the charges to passengers who would have flown with them in any case. If winning customers from competitors by fare\nreductions becomes less attractive, the airlines as a group will be able to maintain higher prices that more than offset the cost of\ntheir frequent-flier programs.\n\nIn practice, the programs have not been effective in eliminating fare wars. Fliers built up large mile balances on several airlines,\nso they could be attracted by lower fares and still earn their frequent-flier miles; and the airlines hurt themselves by forming fre-\nquent-flier alliances that made travelers even more indifferent to the carrier they chose, since they might still be earning miles on\na carrier where they had a large, and therefore valuable, balance. Loyalty programs only work to reduce price competition where\nthe rewards to loyalty are substantial, and customers as a consequence concentrate their purchases. The airlines have attempted\nto rectify the situation by adding sunset provisions, so that unused miles expire after a set period of time, in an effort to reestablish\nthe principle of increasing benefits to loyalty.\n\nA third way of adjusting the structure is to limit output capacity in the market. If firms agree to restrict the amount of product\nthat can be offered for sale, and then abide by that agreement, the benefits of price cutting by any of them will be sharply reduced\nor eliminated entirely. The price-cutting firm gains nothing if it cannot supply the additional customers it tries to capture by low-\nering its prices. Indeed, in many industries, the major problem arising from the installation of more capacity than the market can\nsupport is not the direct costs of creating and servicing the capacity. Rather, it is that with additional capacity available, a firm is\ntempted to lower prices in the hope that by winning more customers, it can make use of the new factories, equipment, space, time,\nor other assets. The price war that is likely to result undermines profitability, not only on the new business attracted, but on the\npreexisting business as well.\n\nOne of the most successful examples of capacity limitation has been a self-imposed code of conduct that restricted the amount\nof airtime that television networks could sell for commercials. Zoning laws and environmental regulations have prevented the\n\nconstruction of new capacity for certain kinds of activity. Industry safety standards and procedures that restrict the hours of\n\f"}, "003093.png": {"text": "operation or delay new construction have the same effect, as do tacit industry agreements to go slow on expansion. For these\nadjustments to be successful, all the firms involved must agree to play by these rules. If some decide to deviate, they will benefit\ndisproportionately at the expense of those that behave and keep their capacity limited. The cooperative situation quickly unravels,\nand a price war soon follows. Also, capacity limitation only works when the firms in the business are protected by barriers to entry.\nIf newcomers can get in, no agreement by incumbents on limiting capacity can stand up. For example, restrictions on driving\nhours for truckers are unlikely to reduce capacity throughout the industry because any increase in shipping rates will attract new\nentrants like ants to a picnic.\n\nA fourth kind of structural adjustment that also requires universal compliance by incumbents is the adoption of pricing\npractices that raise the cost to any firm that lowers its price. One typical arrangement is a so-called most-favored-nation (MFN)\nprovision in industry pricing contracts. Under an MEN provision, if a firm offers a lower price or better terms to one customer, it\nmust offer the same price or terms to all its customers. This policy keeps a company from poaching selective customers by offering\nlower prices, because any price reduction applies automatically to all of its customers. The costs of acquiring the new business\nalmost invariably outweigh the gains. At the extreme, some MFN arrangements require rebates to customers who had previously\npaid more for an item than its current selling price. Though these arrangements appear to protect certain customers from paying\nmore than others do for the same items, in fact all customers end up paying more because no firm is going to cut prices to gain new\nbusiness. On occasion, antitrust authorities have actually enjoined the use of MFNs in an effort to maintain effective price compe-\ntition among firms.\n\nAnother structural adjustment that restricts price competition is an agreement to limit purchasing and pricing decisions to a\nspecific and narrow window in time. The television networks and other media have used preseason advertising purchase markets\nthat operate for two to three weeks before the beginning of the annual season. During this period, advertising is implicitly sold for\nless than it will cost later on the spot market. By keeping the buying period short, the suppliers make it difficult for customers to\nplay suppliers off against one another. The resulting \u201corderly\u201d markets are less vulnerable to the threat of successive price reduc-\n\ntions to which anxious media sellers might resort to fill slots if the purchasing period went on indefinitely.\n\f"}, "003094.png": {"text": "Social interactions within an industry may serve as an informal but still powerful restraint on competitive behavior that\nundermines collective price discipline. Where there are industry norms that involve \u201cfair\u201d pricing among the firms, they may be\nstrengthened by the added social stigma that attach to a deviating company. Thus, industries like ladies\u2019 undergarments, which\nhave been characterized by remarkable discipline over many decades, tend to be industries in which the owners and managers\ncome from similar backgrounds or geographic areas. The ability of these kinds of extra-economic connections to mitigate compe-\ntition is one of the reasons why globalization of markets is often a precursor to the complete breakdown of limits on price competi-\ntion, since the networks that bind owners and managers together seldom extend very far.\n\nA final structural adjustment that restrains the degree of price and feature competition within an industry is the basic reward\nsystem, both formal and informal, within the competing firms. If a firm\u2019s bonus, promotion, and recognition systems values sales\ngrowth over profitability, then controls on price cuts that boost volume at the expense of profits are likely to be weak. Price compe-\ntition within the industry is likely to be intense, and it will be impossible to maintain relatively high prices.\n\nIn an extreme version of this reward system, some firm cultures prize performance relative to competitors above other achieve-\nments. Gains in market share become more important than the growth that comes simply because the industry is expanding.\nSince relative performance is a zero-sum game, firms in such an industry will compete relentlessly. There is virtually no hope for a\ncooperative outcome to the prisoner\u2019s dilemma game of price and feature competition. Only when the culture of the firms within\n\nan industry concentrates on profits and on avoiding unnecessary risk does cooperation to the benefit of all become possible.\n\nTACTICAL RESPONSES\n\nStructural adjustments of the sort we have discussed are the most potent management tools for overcoming the natural tendency\nof prisoner\u2019s dilemma situations to leave everyone worse off than they would be if they could cooperate. They apply to direct price\n\ncompetition and to competition over product features, advertising, and service support, and even to competition over resources. If\n\f"}, "003095.png": {"text": "for some reason these structural adjustments cannot be implemented, tactical responses are a second means of escaping from the\nprisoner\u2019s dilemma. As complements or alternatives to structural adjustments, they can help inhibit direct competition.\n\nAny successful tactical response in a prisoner\u2019s dilemma/price-competitive situation requires two components: an immediate\n\u2014even automatic\u2014reaction to a competitor\u2019s price reduction, and a simultaneous signal of a willingness to return jointly to\nhigher prices. The first component makes certain that a firm that cuts prices never benefits from any reductions it has initiated.\n\nA firm under attack counters immediately and even automatically by matching the new, lower prices. This rapid response should\nhalt customer losses to the deviant firm, which ends up suffering from the adverse consequences of lower prices without the gains\nfrom increased sales. Management of the deviant firm should realize after a round or two that lowering prices to attract customers\nis not a winning strategy. If management is reasonable, it will abandon the approach and return to a pricing policy that maintains\nhigher prices for the industry. The second component, the signal of a willingness to raise prices jointly, is necessary to make sure\nthat the firms not remain mired in the low-price environment created by the initial price cuts and the immediate and often auto-\nmatic matching responses.\n\n\u201cBest industry price contracts\u201d are an example of an automatic price response strategy. Such contracts provide reimbursement\nto customers if the price the customers pay is higher than one verifiably offered by an industry competitor. These contracts an-\nnounce to customers and competitors that the firm will match any reductions a rival might make. \u201cMeet or release\u201d contracts are\nanother automatic response, with the added benefit of not requiring a firm to match a rival\u2019s price if it thinks it is too low for any-\none to make a profit. Advertised policies that guarantee to match or beat any price advertised by a competitor are acommon form\nof an automatic price response.\n\nWithout tactical responses that trigger automatically, it is important for firms to be vigilant regarding competitors\u2019 prices and\nto be organized to respond rapidly. High-minded indifference to rivals\u2019 price-cutting behavior, and an unwillingness to step on the\ntreadmill of lower prices, is an invitation to disaster in a prisoner\u2019s dilemma environment. The competitor benefits from its origi-\n\nnal move to lower price and the nonresponding firm suffers a loss of customers and a precipitous drop in profits. More important,\n\f"}, "003096.png": {"text": "if any competitor learns that aggressive price-cutting behavior works, it becomes more difficult to correct that behavior later on\u2014\nan invitation to extended, profit-destroying price wars.\n\nSelective responses are often preferable to blanket responses when a company is trying to deter noncooperative behavior.\nConsider the case of an established bank faced with a rival that has made an offer of below market loan rates in order to attract new\ncustomers. The target bank could respond by matching the lower rates for all its borrowers to keep them in the fold. But by being\nselective and matching the lower rates only for its borrowers with good credit, while letting the marginal borrowers be captured\nby the rival, the bank has improved the quality of its loan portfolio without antagonizing clients by having to call in loans or deny\nnew ones. At the same time, it has passively off-loaded its suspect borrowers to its aggressive competitor, whose own loan portfo-\nlio is now more likely to experience a higher level of defaults and a reduction in profitability. Though it may take some time, this\nlesson to the aggressive rival is likely to curb its tendency to offer discounts in the future.\n\nAny selective response designed to keep better customers while letting the marginal ones escape will have similar effects. An\nindustry whose firms are equipped to meet price cutting with selective responses should enjoy greater price stability than indus-\ntries where firms cannot be selective. The other side of the coin is that selectivity can be an offensive tool as well, and companies\nthat can poach their rivals\u2019 best customers are going to do so, and thus encourage price competition.\n\nSelectivity can take a second form. Companies responding to aggressive price behavior should pick their spots. The temptation\nin a price war is to attack a noncooperative rival where the rival is weakest, and weakest often means where the rival has a small\nmarket share and limited distribution. But economically, the opposite approach generally makes more sense. If a competitor cuts\nprices in a market where you have a dominant market share, you may be tempted to respond right there with further price cuts to\nteach the interloper a lesson. But this response has a \u201ccut off your nose\u201d quality about it. If the incumbent firm is selling 2 million\nunits per month in the market, and the interloper is selling only 400,000, then each one-dollar reduction in price costs the incum-\nbent $2 million per month, and the interloper $400,000. Who is being hurt more?\n\nA better response is to pick a market where the intruder is large and the incumbent small, and to cut prices in that market.\n\nIf the competitor responds, it, and not the incumbent, bears the disproportionate costs of the price war. Indeed, it may even be\n\f"}, "003097.png": {"text": "worthwhile to introduce\u2014or threaten to introduce\u2014a new product into a competitor's market solely for the purpose of letting the\ncompetitor know how painful price wars can be. What should be kept in mind is that attacking rivals is a tactic whose goal is to re-\nstore price stability and enhance industry cooperation, not an end in itself.\n\nLike many things of value, cooperative arrangements are easier to break than to mend. The second component of a tactical\nadjustment ina prisoner\u2019s dilemma situation, signaling for a joint return to higher prices, is difficult to accomplish. If all managers\nwere rational and focused on profitability, they would see the wisdom of rescinding a price decrease as soon as their competitors\nresponded with their own lower prices. But that doesn\u2019t always happen. The path back to higher prices is made more complicated\nbecause any actions taken by the competitors need to avoid violating antitrust laws. Face-to-face meetings to argue for or negotiate\nareturn to higher prices are clearly illegal. Using the telephone to accomplish the same ends is also unlawful, as the president of\nAmerican Airlines found out when he called his counterpart at Braniff, trying to arrange for a joint price increase.\n\nBut there are approaches that are both effective and lawful. A company\u2019s management that demonstrates a public attitude\nstressing the welfare of the industry as a whole on all matters, not just prices, signals a willingness to cooperate that can help\nreestablish industry cooperation in a prisoner\u2019s dilemma environment without triggering the wrath of antitrust enforcers. Work-\ning together in activities like lobbying the government, establishing industry-wide product standards, undertaking group charita-\nble endeavors\u2014none of which have anything to do with setting prices\u2014reinforces cooperative attitudes. More directly, firms can\nsignal a willingness to raise prices by announcing actual price increases. A rapid response from competitors to go along is critical\nto reestablishing price discipline, just as an immediate reaction to a price reduction is necessary to discipline the aggressive price\ncutter. Whenever a rival demonstrates a desire to moderate price competition, it needs to be encouraged.\n\nLike price reductions to punish aggressive behavior, price increases to promote cooperation are best carried out selectively. A\nprice increase in a conspicuous market\u2014Peoria, Illinois, used to be the standard\u2014is more likely to be noticed by rivals than price\nincreases spread randomly across the landscape. Price increases near the headquarters of a rival firm are also likely to get atten-\n\ntion, although there is the danger that a continual reliance on them will also get the attention of the antitrust enforcers.\n\f"}, "003098.png": {"text": "Ifa particular firm can establish a leadership position on industry matters, and if that firm has a culture that emphasizes profit\nover market share or sales volume, then that firm may be relied on by its competitors to resurrect industry cooperation on prices\nas well as the other joint concerns. Having a recognized leader with this attitude is helpful in escaping the prisoner\u2019s dilemma trap,\nespecially after a price war and the concomitant breakdown in cooperation. Cooperation can only be reestablished if individual\nfirms control reflexive, testosterone-induced competitive impulses. If firms have jumped into the fray without a plan for ending\nthe conflict, the chances for a return to harmony are slim. \u201cNever start a war you don\u2019t know how to end\u2019 is as useful a principle for\ncompanies as it is for countries.\n\nStructural and tactical adjustments to sustain cooperation in a prisoner\u2019s dilemma are mutually reinforcing, not mutually\nexclusive. Having structural policies in hand may facilitate tactical responses. For example, prices that are uniform, transparent,\nand public are easier for firms to match than prices that vary across customers and circumstances, prices that are complicated\nand obscure, and price levels that are negotiated privately. When industry practice embraces uniform and publicly announced\nprices, it is easy for companies quickly to match a reduction put in place by any deviator looking to gain customers. The prima facie\nvirtues of these pricing principles for both firms and customers are reinforced, for firms at least, by their effectiveness in helping\nto sustain industry cooperation.:\n\nAlthough the discussion of responses so far has been addressed to price competition, it applies equally to competition over\nfeatures, discounts, advertising, and resources. In all of these related areas, an aggressive firm decides that it can win customers\nby offering more, charging less, spending more to attract them, or paying more for scarce resources. In all of them, there are joint\ngains from cooperation but strong incentives for individual defection. Each of these initiatives is a blow to joint profitability, and\neach of them can be countered by the same kind of structural and tactical adjustments that work to make price competition less\ndesirable.\n\nAnd one final point to remember: understanding how the prisoner's dilemma works and the tools for coping with it can be\nof value to those market participants\u2014usually customers\u2014who actually benefit from competition and are harmed by industry\n\ncooperation. Prosecutors dealing with real prisoners know that they need to keep the prisoners isolated from one another and\n\f"}, "003099.png": {"text": "to bargain with them separately. Customers of companies in a cooperating industry should seek private, nontransparent price\narrangements; deal with suppliers individually, offering to concentrate their business with those who defect on price or features;\n\nand cooperate with other large customers in trying to undermine industry cooperation. A knowledge of the dynamics of the pris-\n\noner\u2019s dilemma can cut both ways.\n\f"}, "003100.png": {"text": "CHAPTER 9\n\nUncivil Cola Wars\n\nCoke and Pepsi Confront the Prisoner\u2019s Dilemma\n\nTHE PEPSI CHALLENGE\n\nIn 1974, Pepsi stood third, behind both Coca-Cola and Dr Pepper, for soda sales in Dallas, Texas. A Pepsi sales manager decided to\nconfront Coca-Cola directly. He began offering supermarket customers a taste test, to see whether they preferred Pepsi to Coke,\nprovided they did not know which they were drinking. (Dr Pepper was ignored.) Since Pepsi\u2019s research had previously discovered a\nwide preference for Pepsi\u201458 percent to 42 percent\u2014in blind taste tests, he was deservedly confident that his soda would prevail.\nIt did, and when he publicized the results, Pepsi\u2019s share of the local market increased. The gambit was so successful that the pres-\nident of Pepsi USA decided to broaden it. In 1975, the challenge moved from Dallas to all the markets served by company-owned\n\nbottlers, accounting for 20 percent of the company\u2019s soda sales. In two years the company went national with the campaign, pub-\n\f"}, "003101.png": {"text": "licizing the fact that customers liked the taste of Pepsi better than Coca-Cola. It helped Pepsi extend its lead over Coke in food store\nsales.\n\nThe campaign was brash, effective, and more than a little humiliating for Coca-Cola, but it was only the latest in a long series\nof competitive attacks that Pepsi had launched at its larger, more profitable, and better established rival. The challenge did catch\nCoca-Cola\u2019s attention, and the Cola Wars intensified as both sides joined in fierce fighting.\n\nThis chapter will concentrate on the competition between Coca-Cola and Pepsi in the domestic soft drink business. All the for-\nays the companies made into other industries\u2014motion pictures, wine and spirits, snack food, television programming, equipment\nleasing, and even closely related products like bottled water\u2014we are going to ignore, as the soda makers might have done as well.\nWeare also going to pay little attention to the international operations of the firms, even though they were a large (and for Coca-\nCola, the major) source of profits. The intense competition within the U.S. market\u2014the American version of the War of the Roses\u2014\nis interesting enough, especially since it took the companies, especially Coca-Cola, a long time to learn how to deal with their rivals\n\nwithout inflicting great damage upon themselves.\n\nCOLA DRINKS: A BRIEF HISTORY\n\nCoca-Cola and Pepsi-Cola had similar origins. Each was created by a pharmacist in a southern city toward the end of the nineteenth\ncentury, Coca-Cola in Atlanta in 1886, Pepsi-Cola in New Bern, North Carolina, in 1893. Each started as a single drugstore counter\ntreat, and each was good enough to expand, first to other drugstores, then through bottlers to a wider audience. Coca-Cola was\nimmensely more successful than Pepsi during the first five or six decades. Edward Woodruff bought the company in 1919 for $25\nmillion, a major investment for that period. Pepsi, by contrast, went into bankruptcy more than once, and often teetered on the\n\nbrink. As late as 1950, when Alfred Steele became CEO of Pepsi, some employees felt he had come to liquidate the company.\n\f"}, "003102.png": {"text": "But Steele did not put Pepsi out of its misery. Instead, he made it a respectable competitor of Coca-Cola, where he had been a\nmarketing executive. He introduced larger, \u201cfamily-sized\u201d bottles, which Pepsi and its distributors sold through the newly popular\nsupermarkets that expanded in the national suburbanization thrust following the end of World War II. In the first eight years of\nhis tenure, Pepsi\u2019s revenues more than tripled. Steele\u2019s successor, Donald Kendall, who became CEO in 1963, continued the cam-\npaign to take market share from Coke. The company began to focus on younger drinkers, people who had not yet developed the\nhabit of always ordering Coca-Cola. In 1975, Pepsi outsold Coke in food stores for the first time.\n\nFor many years, Coca-Cola\u2019s primary strategy toward Pepsi had been to deny its rival\u2019s existence. Executives were forbidden\nfrom mentioning Pepsi during staff meetings, nor did they discuss it with Coca-Cola bottlers. They belatedly increased the basic\nCoke bottle size to twelve ounces in 1955, a move Pepsi had made twenty years earlier. And they changed their advertising slogan\nin 1960 from \u201cBe Really Refreshed\u201d to \u201cNo Wonder Coke Refreshes Best.\u201d Coca-Cola\u2019s head-in-the-sand approach was intended as\nsome form of benign neglect\u2014if we do nothing, maybe the problem will disappear on its own. Unfortunately for Coca-Cola, it was\nbenign only for Pepsi, which continued to grow in the U.S. soft drink market, largely at Coca-Cola\u2019s expense. Coca-Cola needed a\nmore effective strategy to deal with its upstart rival. The requisite first step in developing that strategy, both for the company in\nits actual deliberations and for its critics in retrospect, is an analysis of the industry and the competitive regime in which the com-\n\npany operates.\n\nINDUSTRY ANALYSIS\n\nOn its path from flavorings and sweeteners to the thirsty consumer, a drink of soda passes through a number of corporate hands.\nThe soda companies themselves, who manufacturer syrup and concentrate, are clearly at the center of the soft drink industry (fig-\n\nure 9.1). Because they have owned and operated some of the other links in the product chain, it is important to delineate precisely\n\f"}, "003103.png": {"text": "those elements in that chain that are properly part of this industry and those that are genuinely outside it as suppliers and cus-\ntomers, even if under the same corporate umbrella.\n\nIt is clear that the suppliers of raw materials are various, numerous, and not integrally related to the soda companies. Both\nCoca-Cola and Pepsi made some of their own cans starting in the 1960s; they were out of the packing business by 1990. On the\nother end of the chain, there are even more companies that sell the drinks to the consumers, whether in supermarkets, restau-\nrants, gas stations, or baseball stadiums. They are not integrally related to the soda makers. This point might have been arguable\nduring the period when PepsiCo owned Pizza Hut, Taco Bell, and other mass food outlets that sold soda in large quantities, but the\nfact that the restaurants were later spun off supports the position taken here, that the \u201clast mile\u201d in soda distribution is a distinct\nindustry. Also, no beverage company ever acquired McDonald\u2019s, the dominant firm in the fast-food industry, which was successful\n\noperating as a customer of the soft drink companies, not an affiliate.\n\f"}, "003104.png": {"text": "Raw materials\n\nSugar and other\nsweeteners: IALY\n\nRoots, wigs and other\nflavoring agents: many\n\nPackaging: many\n\nSeda companies\n\nShrap/concenirate\n\nmakers\n\nPepsi-Cola\nCoca-Cola\nDr Pepper\nSeven-Up\n\nRoyal Crown\nOthers (much\nsmaller)\n\nBottlers/distributors\n\nPepsi-Cola\nCoca-Cola\nFranchisees\n\n \n\nRetail outlets\n\nSupermarkets\nand other stores\n\nRestaurants\n\nOn-site vending\nmachines\n\nMovie theaters,\nstadiums and\nother public\nvenues\n\n(Many at every\nlevel)\n\nFIGURE 9.1\nMap of the soft drink industry\n\nThe bottlers and distributors, by contrast, are joined to the soda companies at the hip. Many of them have been owned by the\ncompanies at various times, others are franchisees. The soda companies charge them for concentrate and syrup and have raised\nprices at times on the promise of providing additional advertising and promotional support. Advertising has generally been split\nbetween soda companies and bottlers on a 50/50 basis, whereas two-thirds of promotional costs are borne by bottlers. Whatever\n\nthe divisions, these are allied campaigns. The soda companies cannot operate successfully unless their bottlers and distributors\n\f"}, "003105.png": {"text": "are profitable and content. Whether company-owned or franchised, the bottlers and distributors are an integral part of the soft\ndrink industry.\n\nThe bottling function is the part of the industry that demands the most capital investment. The high-speed lines are expensive\nand highly specialized; cans don\u2019t work on lines designed for bottles, nor will a twelve-ounce bottle move down a line intended for\nquart containers. The demand for capital has been one of the reasons why the concentrate companies have moved in and out of\nthe bottler segment at various times, adding funds when necessary, then selling shares to the public when possible. Because Coca-\nCola and Pepsi have seldom synchronized their degree of ownership involvement in the bottler segment, their financial statements\nare often difficult to compare. The trimmed-down concentrate maker, selling flavor to the bottlers and fountains, will have a high\nreturn on sales and an extraordinarily high return on invested capital. But if we add in some company-owned bottlers, the margins\n\nshrink.\n\n\u2018WHICH COMPETITIVE REGIME?\n\nWe have divided markets into two competitive regimes: those with barriers to entry and those without. In which one do Coca-Cola\nand Pepsi operate?\n\nBoth key indicators of the presence of barriers to entry and competitive advantage\u2014stable market shares and a high return on\ncapital\u2014are present here. By the time of the Pepsi Challenge, in the late 1970s, the market shares of the major players within the\ndomestic soft drink industry had become quite stable. At the top were the two giants, Coke and Pepsi, sharing over 60 percent of\nthe market between them. The rest of the revenue went to three other popular drinks and a host of private label, local, or other de-\ncidedly third-tier players. See table 9.1.\n\nThe shares of both Coca-Cola the drink and Coca-Cola the company did slip slightly during this period, while those of PepsiCo\n\ninched up. Though these changes were large enough to finally put Coca-Cola on notice that it had to do something about Pepsi,\n\f"}, "003106.png": {"text": "they are not the kind we would find in industries operating on a more level playing field, without barriers to entry. The same sta-\nbility applies to the smaller brands. Seven-Up, Dr Pepper, and Royal Crown hung on to their shares of the market. They may have\nhad fewer loyal drinkers than the two giants, but they were loyal nonetheless.\n\nAsecond indicator confirms the existence of barriers. Returns to Coca-Cola and PepsiCo from their soft drink businesses were\nexceptionally high (table 9.2).: For businesses requiring little capital investment per dollar of sales, operating margins in the 16-\n17 percent range translate into after-tax returns on invested capital of at least 30 percent. As this figure is roughly three times the\nROIC for the average U.S. publicly traded corporation, it supports the claim that there are barriers to entry within the soft drink in-\n\ndustry, and that Coke and Pepsi operate inside them.\n\nTABLE 9.1\n\nMarket share in the soft drink business, 1977-82 (by case volume)\n\f"}, "003107.png": {"text": "1977 1978 1980 41982\n\nCoca-Cola 26.3% 25.8% 25.3% 24.6%\nDiet Coke 0.3%\nSprite 3.0% 3.0% 3.0% 2.9%\nTab 2.8% 2.9% 3.3% 4.0%\nOthers 4.2% 4.0% 4.3% 3.8%\nCoca-Cola Company total 36.3% 35.7% 35.9% 35.6%\nPepsi-Cola 20.09 20.4% 20.4% 20.3%\nDist Pepsi 2.4% 2.7% 3.0% 3.3%\nMountain Dew 2.2% 2.7% 3.2% 3.2%\nOthers 1.4% 1.2% 1.1% 1.3%\nPepsiCo total 26.0% 27.0% 27.7% 28.1%\nSeven-Up 73% 7.0% 6.3% 6.7%\nDr Pepper 5.6% 6.0% 6.0% 5.2%\nRoyal Grown Cola 48% 4.3% 4.7% 3.9%\nOther companies 20.2% 20.0% 19.4% 20.59\ntotal non-Coke, non-Pepei companise = =\u2014-37.796 37.3% 36.4% 36.3%\n\nBut table 9.2 also reveals another important piece of information. As the contest between the two companies began to intensify\n\nin the later 1970s, the profit margin of both firms started to shrink. When Coca-Cola finally picked up the gauntlet that Pepsi had\n\f"}, "003108.png": {"text": "been hurling for many years, it punished itself as much as its rival. We will return to this episode of corporate warfare and the play-\n\ners\u2019 strategies after we finish the discussion of competitive advantages in the soft drink business.\n\nTABLE 9.2\n\nU.S. soft drink sales and operating income ($ million)\n\n \n\n1977 1978 1980 1982\nCoca-Cola\nU.S. and Puerto Rico soft drinksales $1,178 $1,307 $1,928 $2,281\nU.S. and Pureto Rico operating income $201 $191 $204 $250\nOperating margins 17% 15% 11% 119%\nPepsiCo\nU.S. soft drink sales $876 $1,000 $1,403 $1,867\nU.S. operating income $136 $159 $177 $221\nOperating margins 16% 16% 13% 12%\n\nTHE SOURCE OF COMPETITIVE ADVANTAGES\n\nThe existence of barriers to entry indicates that the incumbents enjoy competitive advantages that potential entrants cannot\n\nmatch. In the soft drink world, the sources of these advantages are easy to identify. First, on the demand side, there is the kind of\n\f"}, "003109.png": {"text": "customer loyalty that network executives, beer brewers, and car manufacturers only dream about. People who drink sodas drink\nthem frequently, and they relish a consistency of experience that keeps them ordering the same brand, no matter the circum-\nstances. A beer drinker who normally orders Budweiser will try a Kirin in a Japanese restaurant, a Tsingtao in a Chinese restaurant,\nor a Dos Equis when eating Mexican food. Neither Pepsi nor Coke drinkers ask for Mexican cola. And there is no upscale version of\ncola for devotees who become more affluent, no BMW to lease once the Ford has lost its allure.\n\nSecond, there are large economies of scale in the soda business, both at the concentrate-maker and bottler levels. Developing\nnew products and advertising existing ones are fixed costs, unrelated to the number of cases sold. Equally important, the distribu-\ntion of soda to the consumer benefits from regional scale economies. Concentrate supplied by the soda company is sent to bottlers,\nwho add water, bubbles, and sweetener (always for Pepsi, and by the 1980s for Coke), close the containers, and send the drink on to\na variety of retail outlets. As with beer, the water is heavy and thus expensive to haul over long distances. The more customers ina\ngiven region, the more economical the distribution. A bottler of Coke, selling the product to 40-50 percent of the soda drinkers in\nthe market area, is going to have lower costs than someone peddling Dr Pepper to 5-6 percent of the drinkers.\n\nThe combination of captive customers and economies of scale creates a dominant competitive advantage, but it has not been\nso strong as to eliminate all the other soda firms. They can join together to use independent bottlers and distributors and make\ntheir sodas available. No one dies of thirst from not being able to find a Seven-Up. But the smaller firms do not threaten the two\nleviathans in the industry. They tend to get bought and sold each time an investor thinks he has discovered a way to squeeze more\nprofit out of this variety of sugar water than the previous owner did. And these investors have a point. The second-tier brands are\nalso protected by barriers to entry. They have loyal customers, and Dr Pepper, for one, because of its regional concentration, gains\n\nsome benefits from economies of scale. The steady cash flow has made them ideal candidates for leveraged buyouts.\n\nGUNFIGHT AT THE KO CORRAL: THE SODA MAKERS PLAY THE PRISONER'S DILEMMA,\n\f"}, "003110.png": {"text": "The prisoner\u2019s dilemma is like a marriage in Gomorrah. Though there are rewards for the parties to remain faithful, these are often\noverwhelmed by the incentive to cheat. Cheating by one member often leads to cheating by both, and the marriage dissolves under\nthe weight of mutual distrust. In an environment like this, keeping a marriage intact demands work, attention, and the desire on\nboth sides to cooperate in the interests of the whole.\n\nFrom its inception, the Coke (ticker symbol=KO) and Pepsi marriage was a nightmare. Coke, the dominant partner, simply ig-\nnored Pepsi longer than it should have. Not until the 1970s would Coke executives even mention Pepsi in internal meetings. Pepsi,\nthe neglected spouse, misbehaved repeatedly. In 1933, at the depth of the Depression, it effectively cut its price in half, doubling\nthe size of the bottle to twelve ounces while keeping the price at five cents. In the 1950s, it resumed its attack. As we mentioned,\nPepsi moved earlier into supplying supermarkets and it targeted those drinkers who were up for grabs: young, unattached to either\nbrand, and with money to spend. It seduced them with pop music stars and made them into a youth phenomenon\u2014the Pepsi\nGeneration. It sponsored concerts and other promotions geared to this market. To drive home the point, it ridiculed Coke as the old\nfolks\u2019 drink, something served in retirement communities and nursing homes.\n\nFor its part, Coca-Cola paid no attention to many of these moves by Pepsi, a strategy that did nothing to discourage its rival\nfrom continuing its aggressive stance. In terms of the prisoner\u2019s dilemma, Pepsi generally chose the noncooperative option, and\nCoca-Cola did nothing to punish it for its behavior. Table 9.3 is a chronology of initiatives and responses through 1982.\n\nFor almost all of this period, the initiative rested with Pepsi. Coca-Cola's responses were delayed, timid, and ineffective. It took\ntwenty years for it to offer Coke in a twelve-ounce bottle; it was reluctant to compete with its own six-and-a-half-ounce skirt-\nshaped container, which had attained iconic status. It trailed Pepsi into the supermarkets, and it followed Pepsi\u2019s direct-store-\ndoor (DSD) delivery service. Aside from being the first to introduce a lemon-lime drink (ahead of Pepsi, that is, but certainly not\nSeven-Up) and a diet version of its cola (again, in front of Pepsi but not Royal Crown), Coke was playing follow the leader. As a\nconsequence, Pepsi was able to triple its revenues in the 1950s and reduce Coca-Cola\u2019s lead in the domestic soft drink business. At\nthe end of World War II, Coca-Cola commanded 70 percent of the market; by 1966, that had fallen to 30 percent, with Pepsi second\n\nwith 20 percent.\n\f"}, "003111.png": {"text": "By the late 1970s, Pepsi still trailed Coke, but it was making inroads, especially with younger drinkers and in the supermarket/\nfood store channel. Though this success may have been cause for celebration at Pepsi headquarters, the history of conflict between\nthe companies did not bode well for the future of this relationship. Each side seemed more interested in inflicting pain than in\nfinding some way to achieve harmony and mutual gain. Executives in both companies were rewarded for sales growth and market\nshare gains, even if they had to sacrifice profit to get there. A warrior culture permeated the two firms, setting the standards for\nattitude and behavior. These qualities are not conducive to a successful marriage. This was the environment in which Coca-Cola\n\nembarked on its long-belated response to the Pepsi Challenge.\n\nTABLE 9.3\nCoke\u2019s and Pepsi\u2019s Competitive Steps, 1933-1982\n\f"}, "003112.png": {"text": "YEAR\n1909\n\nPeps! initiates:\nLowers prise of 12-02. bottle\n125 cent; 1939: \"twice 40\n\u2018Much fer a Niokal Too\"\n\nradia jrale\n\nAllred Steele beccmes CEO;\nate\u00bb \"Boat Coke\" pelioy\nIntroduces 24 oz bottle;\nfocuses cn sala through\neupermerhate\n\n1960-58 Increases revenue 300%\n1981\n\n1960.\n\n \n\n19608\n\n1983\n\n1983 Donal Kendal\n\nbecomes CEO\nLaunches \"Pepsi Genaratice\u201d\ncampaign\n\nlnprowe service\n\n{e eupetmarhots through\nditeot etore doce (03D)\ndelivery cparatices,\n\nbetter deplaye\n\nRaizes price for concentrate\nbby 20%, on par with Coke.\n\u2018Spendsnewmaegnncn\nbunting and promotizes,\nBegins Pepai Challenge\n\nwith blind tacte teots in Daas\nHao largeot share of food\nateee voles\n\nExtend Chalenge to markets\nscccunting for 20% of eales\n\n1984\n\n1980\n\n1970.\n\nccorly\n1970.\n\n1978\n1978\n1978\n1976\nPepsi Challenge\npow nationwide\n\n1980 John Soully, presidentot\nPepsi USA, wants bottlers\nto attack Coke's etrongheld\n\nin vending machines\n\nCoca-Cola responds\n\n\u2018and initiates: Pepsi responds\n\u2018Coe increases vise\n\n1 12cz.in 1955\n\n1985, Changes advertizing\n\nlogan to*Be Rely Refreshed\u201d\n\nIntrockuoee Meuntain\nDewin 1964\nIntrodnes\n\nDiet Popa in 1964\n\nIntroduces Sprite\n\nIntroduces Tab\n\nFellows ouit\n\nAlso\n\ninoregoes apending,\n\u2018on ado and premetions\n\n(CEO Avetin enncunces\nthat Urited States ie not a\ngrowth area for Coca-Cola\n\u2018State price decounts\n\nin reas whore Coke ia\nstrong, Pepsi weak\nGetting \u20ac2% of\n\ncoda eales from\ninternaticns! market\nPepai get 20% of\n\nite 2aleoin theoe markets]\n\f"}, "003113.png": {"text": "TABLE 9.3 (continued)\nCoke\u2019s and Pepsi\u2019s Competitive Steps, 1933-1982\n\nYEAR Pepsi initiates\n1981\n\n1982\n\n1982\n\n1982\n\nCOCA-COLA'S FIRST MOVE: A SHOT IN THE FOOT\n\nCoca-Cola responds\nand initiates\n\nRobert Goitusta\nbecomes CEO;\nannounces aim to grow\nin U.S. market\n\nBagins more aggressive\nadvertising with new\n\u201cCoke Is It\u201d slogan\nBagins price discounts:\nsells 50% of food store\nvolume at discount\n\nIntroduces Diet Coke,\nfirst use of Coke name\non second brand; it\nbecomes the largest\ndiat drink in 1983\n\nPepsi responds\nResponds to\nprice discounts\n\nFollows suit;\nmatches discounts\n\f"}, "003114.png": {"text": "Coca-Cola, watching its market share erode slowly and its operating margins shrink, decided to make a frontal assault on Pepsi. In\n1977, it initiated a price war to gain market share. Price wars between two elephants in an industry with barriers to entry tend to\nflatten a lot of grass and make customers happy. They hardly ever result in a dead elephant. Still, there are better and worse ways of\ninitiating a price contest. Coca-Cola chose the worst. Instead of lowering concentrate prices across the country, it focused on those\nregions where its share of the cola market was high (80 percent) and Pepsi\u2019s low (20 percent). This tactic ensured that for every dol-\nlar of revenue Pepsi gave up, Coke would surrender four dollars. In these markets, the Coke bottler was company-owned, the Pepsi\nbottler an independent franchisee.\n\nIn the face of this assault, Pepsi had no choice but to support the bottler with its own price cuts in concentrate or see all of its\nother franchisees question the company\u2019s commitment to its indispensable partners. So Pepsi rose to the Coke challenge, as Coke\nmight have predicted had it considered carefully its own tactics. Pepsi cut prices for its concentrate and increased spending on\nadvertising. Both companies ended up slicing into their margins. And Coca-Cola's initiative did not stop the gradual loss of market\nshare to Pepsi.\n\nIn the normal form of the noncooperative game, the worst box for the players to find themselves in is the one in which neither\ncooperates (figure 9.2). Unfortunately for their joint benefit, it is also the one in which they are most likely to end up\u2014the equilib-\n\nrium\u2014since it is the best choice each can make if it assumes that the other will also make that choice.\n\f"}, "003115.png": {"text": "PEPSI\n\nCooperate Don\u2019t Cooperate\n\nCooperate\n\nCOCA-COLA\n\nDon't Cooperate\n\n \n\nFIGURE 9.2\n\f"}, "003116.png": {"text": "Coca-Cola\u2019s price-cutting strategy, targeted at itself more than its rival, was expensive for both firms, but more damaging to\n\nCoke.\n\nCOCA-COLA'S SECOND MOVE: BACKING INTO SUCCESS\n\nBoth companies continued to introduce new drinks during this period: diet, decaffeinated, and decaffeinated diet versions of the\ncolas, as well as sodas with other flavorings. They were aggressive in managing and extending their shares of supermarket shelf\nspace, capitalizing on their direct-store-door (DSD) delivery capacity. In contrast to price wars and expensive advertising, the\nbattle for shelf space, which they fought to a draw, hurt the smaller soda brands rather than each other. Both the introduction\n\nof new beverages (development costs and advertising campaigns) and the servicing of markets with direct delivery (local scale\neconomies) were activities that benefited from economies of scale. The proliferation of varieties and superior service allowed the\ntwo majors to shift some sales to themselves, at the expense of the smaller players.\n\nBut despite this success relative to Seven-Up, Dr Pepper, and the like, Coke was still coming out on the short end of the Pepsi\nChallenge. Younger consumers especially preferred the sweeter taste of Pepsi.: And sales in food stores, where customers had a\nchoice between the two, had already tilted in Pepsi\u2019s direction. Coca-Cola was concerned that in a short time, Pepsi might legiti-\nmately claim that more people actually drank its cola, not simply that they preferred it.\n\nBy 1985, Coca-Cola had decided to confront this problem head-on. Using its Diet Coke formulation as a base, which to many\nconsumers tasted more like Pepsi than it did Mother Coke, Coke took out the artificial sweetener and rebuilt the drink with high-\nfructose corn syrup. After tens of thousands of taste tests, the company introduced this sweeter formulation of its traditional\ndrink and made the new product its flagship brand, going so far as to remove old Coke from the market. New Coke had a new can,\nanew slogan, and a new advertising campaign. Together with the sweeter taste, all these changes were aimed at the younger\nmarket that Pepsi had so far managed to dominate. At first the whole strategy was a disaster. New Coke may have scored higher in\n\nthe Pepsi Challenge, but sales were embarrassingly low. Fortunately for Coca-Cola, an outpouring of protest from those customers\n\f"}, "003117.png": {"text": "committed to the original drink forced the company to reconsider its plans. Within four months, old Coca-Cola was back, first as\nCoca-Cola Classic, then simply as Coca-Cola, with the sweeter version now labeled New Coke.\n\nAfter the fact, some analysts tried to argue that the New Coke strategy was a brilliant gambit to win more shelf space for the\ncompany, now that it had two distinct brands of the calorie- and caffeine-laden version of the drink, rather than one. This inter-\npretation conveniently ignored the original intent, which was to abandon old Coke entirely. The company did not want to split its\nsales between the two and allow Pepsi to claim the top spot. But in fact the turmoil did benefit Coca-Cola. The media attention was\nintense, and the company realized what it had ignored when it ran the taste test\u2014that many loyal customers had a visceral attach-\nment to the original, a drink they identified with their youth, their country, their very identity. Pepsi did surpass the market shares\nof both old and new Coke, but only for a short while. By 1986, Classic Coke was back in the lead, and the combined shares of Classic,\nCoca-Cola (new), and Diet Coke surpassed Pepsi and its diet version, 29 percent to 23 percent (table 9.4).\n\nThe New Coke fiasco ended up providing Coca-Cola with a potential new weapon for competing in the sweeter/younger seg-\nment of the market. Now, if Coke wanted to go to war against Pepsi, it could do it on Pepsi\u2019s home turf. Sweet Coke could be used as\nan \u201cattack\u201d brand, introduced into markets where Pepsi was dominant. If New Coke were really successful, it might capture one-\nsixth of this market. Should Coke decide to use New Coke as a \u201clow-priced\u201d\u2014warrior\u2014brand, then Pepsi would be made to suffer.\nMatching the lower price, a decision Pepsi virtually had to make, would cost it six dollars in sales for every dollar it cost Coke.\nMeanwhile, traditional Coca-Cola could have stood aside from this fray, maintaining its status as the drink for mature cola lovers,\nand its higher profit margins. However inadvertently, Coca-Cola had at last learned whom to punish in a price war. Now that it had\n\nthis weapon, peace between the two might be possible.\n\nTABLE 9.4\nMarket share, 1982-86 (by case volume)\n\f"}, "003118.png": {"text": "Chassic\n\nCoca-Cola\n\nDist Coke\n\nSprite and Diet Sprite\n\nTab\n\nCherry Coke\nCaffeine-free, all\n\nOthers\n\nCoca-Cola Company total\n\nPepsi-Cola\n\nDist Pepsi\nMountain Dew\nCaffeine-free, all\nOthers\n\nPepsiCo total\n\nSeven-Up\n\nDr Pepper\n\nRoyal Crown Cola\n\nOther companies\n\nTotal non-Coks, non-Pspsi companies\n\n24.6%\n0.3%\n3.5%\n4.0%\n\n3.49\n35.6%\n\n20.3%\n3.3%\n3.2%\n0.4%\n0.99\n\n28.190\n\n6.7%\n5.2%\n3.99\n20,59\n36.3%\n\n1984\n\n22.5%\n5.2%\n3.8%\n1.6%\n\n1.8%\n2.6%\n37.5%\n\n19.1%\n3.2%\n3.0%\n2.7%\n0.7%\n\n28.7%\n\n6.8%\n5.0%\n3.1%\n18.9%\n33.8%\n\n6.19\n15.0%\n6.7%\n4.3%\n1.1%\n1.7%\n1.7%\n2.0%\n38.6%\n\n18.9%\n3.9%\n3.0%\n2.4%\n1.6%\n\n29.8%\n\n6.0%\n4.9%\n3.0%\n17.7%\n31.6%.\n\n19.196\n2.49,\n7\n43%\n0.6%\n1.99%\n1.79\n2.59%\n39.9%\n\n18.6%\n4.4%\n3.0%\n2.0%\n2.7%\n\n30.796\n\n5.2%\n45%\n2.9%\n16.6%\n29.596\n\f"}, "003119.png": {"text": "WISING UP: FROM PRICE WARS TO COOPERATION\n\nAfter a decade of beating each other up, and with the New Coke weapon now pointed at Pepsi, Coca-Cola and PepsiCo had fought\neach other to a standstill. Like our prisoners who learn to cooperate after playing the game enough times, the soda companies\nfinally changed strategies (table 9.5). They made visible moves to signal the other side that they intended to cooperate. Coca-Cola\ninitiated the new era with a major corporate reorganization. After buying up many of the bottlers and reorganizing the bottler net-\nwork, it spun off 51 percent of the company-owned bottlers to shareholders in a new entity, Coca-Cola Enterprises, and it loaded up\non debt for this corporation. With so much debt to service, Coca-Cola Enterprises had to concentrate on the tangible requirement\nof cash flow rather than the chimera of gaining great hunks of market share from Pepsi. In the world of the soda giants, with only a\nfew players, Coca-Cola\u2019s initiative was impossible to miss and difficult not to understand. PepsiCo responded by dropping the Pepsi\nChallenge, toning down its aggressive advertising, and thus signaling that it accepted the truce. The new cooperative relationship\nhad the desired effect where it counted most: profit margins. Operating profit margins went up from below 10 percent for Coca-\n\nCola to more than 20 percent. Pepsi\u2019s gain was less dramatic but also substantial (figure 9.3).:\n\nTABLE 9.5\nCoke\u2019s and Pepsi\u2019s competitive steps, 1984-92\n\f"}, "003120.png": {"text": "Pepsi Coca-Cola responds Pepsi\n\nYEAR initiates and initiates responds\n1984 \u2014 Begins touse 100% Follows suit in some\nsspartame in dist beverages areas (cannot gst enough\naspartame for alll\nApril Introduces \u201cNew\u201d Declares holiday\n1985 Coke, eliminates old for its employees;\nCoke; enormous press new ad campaign:\ncoverage \u201cthey blinked?\nJuly 1985 Brings back the original\nas Cocs-Cala Classic:\nby September, itis outselling\n\nnew Coke 3 to 1 in food stores:\n\n1986 \u2014 Wayne Calloway becomes\nCEO; former promises to\n\nfocus on profitability\n\u2018and return on equity.\n\n1986 Buys two of its largeet Buys two large\nfranchise bottlers; now independent\nowns 38% of total franchisees;\nvolume keeps on buying\n\nuntil, by 1990, it\nowns 51% of\nbottler volume\n\n1986 Sells 5196 of bottler Takes Pepsi\noperations to public Bottling Group\n9s Coca-Cola public, selling\nEnterprises, Inc. 6590 stake, in\n\n1999\n\n1989 Both companize raise soft\n\ndrink prices 8.3%\n(largest increase since 1981)\n\n1992 Reintroduces New Coke Increases\n\u201888 Coke Il, available only in television\nselect markets advertising in\n\n\u2018one Coke Il\n\nmarket\n\f"}, "003121.png": {"text": "This harmonious and profitable state of affairs continued into the 1990s.\n\n25%\n\n \n\n \n\n15%\n\n10%\n\n \n\n \n\n0%\n1977 1982 1987 1992 1997\n\nsams Coke \u2014\u2014 Pepsi\n\nFIGURE 9.3\nOperating profit margins, domestic soft drink business, 1977-98\n\f"}, "003122.png": {"text": "IS CULTURE DESTINY?\n\nUnfortunately, like bad marriages, companies have an internal dynamic that is not easily overcome, even by peace and high\nreturns on invested capital. Wayne Calloway at PepsiCo and Robert Goizueta at Coca-Cola, aided by the statesmanlike support of\nboard member Warren Buffett, did bring some measure of peace to the cola world. Goizueta judged his performance by two mea-\nsures: return on equity and the share price. He regarded the revenue line as \u201cthe curse of all curses.\u201d During his sixteen-year lead-\nership, the price of the company\u2019s shares appreciated by almost 30 percent per year. Calloway, who had been the president of Frito-\nLay before he became the chief executive at PepsiCo, also preferred return on equity to bragging rights about market share. During\nhis decade as CEO, the share price of Pepsi also grew dramatically, by 24 percent annually. Sadly, cancer killed both these executives\nwhile they were still young.\n\nTheir successors, Douglas Ivester at Coca-Cola and Roger Enrico at PepsiCo, were Cola Warriors, enthusiastic participants in the\ncentury-old conflict that dominated the culture of both companies. In an article in Fortune magazine that received much media\nattention, CEO-in-waiting Ivester, described as Goizueta\u2019s \u201cpit bull,\u201d declared that Coca-Cola\u2019s policy would be to stick a hose in the\nmouth of its competitor, whom he saw as struggling in the pool. Enrico, a Vietnam veteran, had already published The Other Guy\nBlinked: How Pepsi Won the Cola War, a book that gloated over the New Coke episode in the ongoing struggle. The people at Coca-\nCola never forgave him. Under his leadership, PepsiCo announced ambitious goals for effectively stealing share from Coke in inter-\nnational markets, where Coke was dominant.\n\nBoth strategies failed. Ivester did not drown Pepsi\u2014Pepsi\u2019s market share actually increased\u2014as he and his board of directors\nshould have known. But he did manage to put a dent in Coca-Cola\u2019s earnings. For its part, Pepsi lost out in Venezuela, the only inter-\nnational market where it had a substantial share. Coca-Cola made an offer to the Pepsi bottler who had a monopoly for the country.\nIt must have been an offer he couldn\u2019t refuse, because he switched allegiance and started to bottle and distribute Coke. One might\nask what the Coca-Cola and PepsiCo boards of directors were doing while the CEOs decided to resort to the warfare strategies that\n\nhad served the two companies so poorly before the truce of the late 1980s.\n\f"}, "003123.png": {"text": "Ivester\u2019s tenure at Coca-Cola hardly lasted two years. He was undone by a series of problems, including several health scares in\nEurope and a racial discrimination lawsuit in Atlanta. His response, the board felt, was too aggressive, and he managed to damage\nthe company\u2019s image, which was one of its most important assets. The man who wanted to drown his competitor was undone by\nthe same uncompromising temperament. It was during his watch that Pepsi belatedly emulated Coca-Cola by spinning off its bot-\ntling business in 1999, creating what an industry journal called a \u201crational player.\u201d With that move, both companies raised their\nprices to supermarkets, which had fallen by more than 10 percent over the prior four years. Unhappily for Ivester, it was too late\nfor him; he was gone by the end of the year.\n\nThe urge to grow, to hammer competitors and drive them out of business, or at least reduce their market share by a meaningful\namount, has been a continual source of poor performance for companies that do have competitive advantages and a franchise,\nbut are not content with it. It may be that the same aggressive personality traits that push people forward until they reach the top\nof the corporate ladder also move them to take on the competition, whatever the cost. It would be foolish to expect a sudden shift\nfrom warrior to corporate statesman for most of these people. Still, incentive systems that reward based on some aspect of profit,\nrather than for revenue or another measure of size, may focus attention on what is good for the shareholders and, by extension,\n\nother stakeholders in the company.\n\f"}, "003124.png": {"text": "CHAPTER 10\n\nInto the Henhouse\n\nFox Becomes a Network\n\nFOX BROADCASTING COMPANY\n\nIn 1985, Rupert Murdoch announced that he was going to form a fourth television network in the United States. Murdoch\u2019s net-\nwork would join the three incumbents that had come to dominate the industry within a decade of its inception after World War II.\nAs part of his overall strategy, he bought six independent stations in large American cities and the Twentieth Century Fox movie\nstudio. The News Corporation, the global media conglomerate he had built starting with one newspaper in western Australia,\nalready owned more than one hundred newspapers and magazines in Europe, Australia, and North America, as well as television\nbroadcasters in Europe and Australia. He saw Twentieth Century Fox as the entertainment asset at the heart of his empire, produc-\n\ning material he could distribute throughout all his channels.\n\f"}, "003125.png": {"text": "No one ever accused Murdoch of thinking small. His plans for the News Corporation involved a major challenge. He would have\nto launch and keep afloat the fourth television network, something that no one had accomplished since the 1950s, until it became\nprofitable. In reaching both that goal and his larger global vision, he expected to realize some of the supposed synergies that came\nfrom combining a production studio with a distribution system that extended far beyond the broadcast network in the United\n\nStates.\n\nTHE BROADCASTING INDUSTRY\n\nThe club that Murdoch so much wanted to join had only three members: ABC, CBS, and NBC. Each of them had been successful\nradio networks in the 1930s, an experience that served them well as they moved into the new medium. They knew how to deal\nwith advertisers, with local station affiliates and independents, with running news organizations, and with the entertainment\ncomponent that made up a large part of the product they delivered to consumers. A fourth network, started by the engineer Allen\nDuMont, whose background was in the set manufacturing part of the business, lasted into the 1950s but then disappeared. Other\nefforts by entertainment companies like Paramount Pictures to establish themselves in the network broadcast game did not last\nvery long.\n\nAs it evolved in the three decades after the end of WWII, the network broadcasting business was only one segment of the\ncomplete industry that brought news, sports, entertainment, and advertising\u2014which paid for the rest\u2014into the American home\n(figure 10.1).\n\nIn the development of first radio and then television, the United States differed from virtually all other countries in that the\ngovernment licensed, but did not own or directly control, the airways. The ultimate revenue stream of the entire industry came\nfrom advertisers, who bought time in which to air commercials. During the golden years of radio and the early days of television,\n\nlarge sponsors actually produced some of the programs that advertised their wares, but by the early 1960s, they had ceded control\n\f"}, "003126.png": {"text": "to the networks. Production costs had risen, and the advertisers liked the flexibility of buying limited commercial segments ona\nrange of shows and networks. They also bought time directly from the local stations, both independents and those connected to\nthe networks.\n\nThe production of \u201ccontent\u201d was split among the networks, production companies, and local stations. The networks and the\nlocal stations produced national and local news, sporting events, and a range of other shows. The major entertainment pieces that\nfilled the evening (prime time) hours\u2014the comedies, dramas, and made-for-television movies\u2014they bought from the studios. The\nmovie studios already had the experience and the infrastructure to produce this fare, and they leapt at the opportunity to grow a\nnew revenue stream after the government ended their direct ownership of movie theaters on antitrust grounds. The glamour of\nthe movie business, even with the \u201cmovie\u201d confined to the small-screen world of television, attracted a number of smaller players\ninto the production business, to compete with the established studios. There was no shortage of creative talent pitching show con-\n\ncepts to the networks.\n\f"}, "003127.png": {"text": "Production Local stations\n(Companies Ovned and operated\nMovie stadios WNBC-TV\nWamer Bros. WCBS-TV\nColumbia KABC-TV\nParamount And others\nUniversal Affliates\n\u2014 Westinghouse\nIndependents Metromedia\nMIM KRON\nLorimar WFAA\nAnd others\nIndependents\nWON\nWOR\nAnd others\n\n \n\nFIGURE 10.1\nMap of the television industry, around 1985\n\f"}, "003128.png": {"text": "The networks bought the shows they approved from the production companies, or rather, they bought enough episodes to\nsee if the program would find an audience. If it did, they contracted for another round. The networks paid the producers between\n80 and 90 percent of the producers\u2019 costs, leaving the producers to look elsewhere for full cost recovery and a profit. They found\nit in the syndication market. Regulations severely limited the number of prime-time shows a network might own for itself. The\nrest belonged to the producers, who were able to sell the rerun rights to syndicators. Syndicators put packages of shows together\nand resold them to local stations and even networks to run after the popularity of the shows had been established. To qualify for\nsyndication, a show needed to last for sixty episodes, and most did not qualify. Those that did, however, provided revenue for the\nproducers. By the 1970s, more than half the total revenue of the film studios came from its television productions: shows sold di-\nrectly to the networks; syndication sales; made-for-television movies; reruns of old films.\n\nGovernment regulation limited the number of local stations a network could own. Recognizing that economies of scale might\nmake television distribution a natural monopoly, and fearful that control of major sources of news might ultimately rest in very\nfew hands, successive administrations had allowed the companies in the business to expand but retained some upper limit. Even\nafter the absolute number of VHF stations was raised from five to twelve, the networks were still prevented from reaching more\nthan 25 percent of the population through their own outlets\u2014the \u201cowned and operated\u201d stations. But they struck \u201caffiliated\u201d\ndeals with many local stations, each of whom was committed to a single network carrying many, but not all, programs from that\nnetwork. It was cheaper for the local stations to accept these popular programs than to find alternatives with the same appeal. In-\ndependent companies in the business of owning affiliates faced the same limitations on ownership as did the broadcast networks.\nThe owned and operated and the affiliated stations were more profitable than the independents. They spent more on local pro-\ngramming, like news and features, and had larger audiences. The independents had to rely on reruns, old movies, local sports, and\nother shows with narrowly focused audiences.\n\nThe affiliated stations did not buy shows from the networks. Revenue flowed in the other direction: the networks paid the\naffiliates to carry their programs. For that, the networks received the fees that came from their six minutes per hour of prime-time\n\nadvertisements. The affiliates had three minutes of advertising time for themselves, which they could sell to local sponsors or\n\f"}, "003129.png": {"text": "national advertisers or use for public service announcements. Local broadcasting, especially for the owned-and-operated and the\naffiliates, was the most lucrative part of the entire business. Adding the two years 1984 and 1985 together, the combined operat-\ning income of all three networks was 9 percent of their revenues. Their owned and operated stations had operating margins of 32\npercent. It has been suggested that they were actually subsidizing the networks.\n\nThis vitally important connection suggests that when we look at the networks, we need to treat their owned and operated local\nstations, and probably even their affiliates, as part of the same segment (broadcasting per se) of the industry. But the rest\u2014the\nproduction firms, the syndicators, and the advertisers\u2014were clearly in separate portions of the overall industry, no more tied than\n\na publisher is to a book merchant or a fructose grower to a beverage manufacturer.\n\nBARRIERS TO ENTRY?\n\nAs always, we look at two features of an industry to determine whether it is protected by barriers to entry. The first is the history\nof market share stability. If newcomers have not been successful in establishing themselves within the industry, and if there has\nbeen little movement in the market shares of the incumbent firms, then the chances are good that barriers to entry exist. The sec-\nond feature is return on capital. If the incumbent firms in the business have been earning a higher than normal return on capital,\nthat fact supports the claim that barriers do exist. We know that prior to Fox, all those who tried to get into the broadcasting net-\nwork business failed, including the DuMont Network that entered the television network business at its inception, but without the\nbackground in radio broadcasting.\n\nThe record on market share is one of exceptional stability. In the ten years between 1976 and 1986, the three networks com-\nbined had an average absolute change of 9 percentage points, which works out to 3 percentage points per network for a whole\ndecade (table 10.1).\n\nCalculating market share stability by treating the sum of the three networks\u2019 individual shares as if they represented 100\n\npercent of the total audience allows us to measure movement among the three, but in this case it ignores an equally significant\n\f"}, "003130.png": {"text": "bit of information. As a group, the networks were losing market share at the rate of around 1 rating point per year. Some of it was\ngoing to the independent stations, some of it to the cable stations that reached 40 million homes by 1986. Even if we confirm the\nexistence of barriers to entry protecting the incumbent networks from strong competition by start-ups, that does not mean that\nthe networks were immune from an erosion in their audience, who found alternatives to traditional network offerings among a\n\nlarge number of small players.\n\nTABLE 10.1\nMarket share changes for the three networks, 1976-86\n\nRating Points Normalized\n1976 1986 1976 1986 Change Absolute\nABC 18.7 12.8 36% 32% -4.2% 4.2%\nNBC 16.4 14.6 31% 36% 4.6% 4.6%\nCBS 171 13.1 33% 32% -0.4% 0.4%\nTotal 52.2 40.5 100% 100% 9.2%\nAverage over 10 years 3.1%\n\nOur other key test for the existence of barriers to entry is high return on capital. In the two years 1984 and 1985, the three\nnetworks combined had operating income of $2 billion on revenues of $15.8 billion, or 12.6 percent. These figures include both\nthe network business and the owned and operated stations, which, as we have seen, had much higher margins. The 12-13 percent\noperating margins have to be seen in the context of the capital requirements for these firms. These requirements were minimal.\n\nMost ads were sold before the start of the season, limiting investments in accounts receivable. There was no inventory. During\n\f"}, "003131.png": {"text": "these years, distribution of the shows to the local stations was handled by AT&T, leaving only studios and broadcasting equipment\nas fixed assets (property, plant, and equipment). The owned and operated stations also had few capital requirements other than\ntheir own studios, broadcast antennas, and equipment. We estimate that the assets looked something like the figure in table 10.2.\nWe put all the assets required at about 15 percent of sales. Spontaneous liabilities (meaning accounts payable, accrued wages\nand taxes, and other non-interest-bearing obligations) finance a third of the assets.: That leaves capital requirements at around 10\npercent of sales. With operating margins at 12-13 percent, the pretax return on capital amounts to 120-130 percent. Even if the\ninvestments requirements were twice our estimate, the pretax return on capital would be 60 percent or more. Given the steadiness\nof the revenues, the networks could easily finance their operations with half debt, half equity. The debt would provide a tax shield\n\nto keep the after-tax return on equity capital in the stratosphere.\n\nTABLE 10.2\n\nEstimated balance sheet of networks and owned stations, 1984-85 (assets as a percentage of sales)\n\nCash 1%\nAccounts receivable 4%\nInventory 0%\nProperty, plant, and equipment 10%\nTotal assets 15%\nSpontaneous liabilities 5%\n\nTotal capital required 10%\n\f"}, "003132.png": {"text": "All the signs of an industry protected by high barriers to entry are present here, in spades. Thanks to the barriers, the firms\ninside earned exceptional returns on capital. This is what made the industry attractive to Murdoch, as it had been to Paramount\nand other aspiring entrants. But it also served as a warning of how challenging it would be for a newcomer to climb the walls, get\n\ninside, and survive.\n\n\u2018WHICH COMPETITIVE ADVANTAGES?\n\nThe only source of competitive advantages not involved in creating barriers to entry around the network business was technology.\nThe incumbent networks had no proprietary hold on the equipment necessary to capture and send broadcast signals to the tele-\nvision sets that had become ubiquitous in American homes. RCA, the parent of NBC, was a manufacturer of sets, as DuMont had\nbeen, but so were a host of other companies unrelated to the broadcasters. Technology was an open field, and anyone could play.\n\nCustomer attachment was a different matter. Successful shows developed a loyal following, and they frequently lasted for\nyears. The other networks took care not to schedule their own most popular programs at the same time. In the days before the\nremote channel changer (according to some historians of technology, the only rival to the ATM machine for the most humane\ninvention in the last half of the twentieth century) a substantial portion of the viewership of one show stayed put when the hour\nended and the next program began. Network executives crafted their schedules to give new programs a boost by launching them\nin the wake of established and popular programs. Television viewers were not completely captive customers; they could and did\nchange channels and opt for a new program in place of an established one. Still, incumbents held an advantage over entrants, who\nwould need to accumulate an audience over time in the face of network programming competition.\n\nThe government imposed restrictions on the broadcast industry. It rationed the scarce radio spectrum to prevent signal inter-\nference, and it used regulation to preserve the public interest in competition and free access. It limited the networks, and other\nnonnetwork broadcasting companies, to ownership of local stations reaching no more than 25 percent of the population. This\n\nrestriction created the system of affiliated stations, associated with the networks but less tightly tied than the owned and operated\n\f"}, "003133.png": {"text": "ones. But most of the other government policies buttressed the barriers to entry. The Federal Communications Commission li-\ncensed local stations and assigned them the frequencies over which to broadcast. In each of the largest metropolitan areas, the FCC\nissued no more than seven VHF licenses. In smaller locales, even fewer VHF licenses were available. These had gone, in the 1940s,\nto the existing radio networks, giving them a permanent leg up in their ability to reach audiences. When cable technology emerged\nin the 1960s, the FCC initially constrained its geographic spread and restricted subscription services, in an effort to keep access\nfree to viewers. Gradually, however, television audiences could tune in to more channels both through cable systems and improved\nUHF technology.\n\nThe government also regulated the costs that the networks paid to AT&T to transmit their programs to the stations. Originally,\nthese charges were structured so that it cost only slightly more to send a full day\u2019s programming than it did a single hour\u2019s. This\nwas not a pricing scheme that encouraged small broadcasters with only a few hours of programs to distribute. Things changed in\nthe early 1980s. Competitors, including satellite operators, were allowed into the transmissions business, and the pricing struc-\nture at AT&T better reflected the number of hours carried. By 1986, government barriers to entry, once formidable, had decreased\nsubstantially.\n\nHowever, economies of scale were the most powerful competitive advantage that kept the networks protected from eager new\n\nentrants, and these were not changing. Network broadcasting is largely a fixed-cost business:\n\n+ Programming costs are fixed. Networks contract for new shows before they or the producers know the size of the\naudience they will reach. It is true that some crucially popular shows, and especially their star performers, can\ndemand more money for renewals. Sometimes the networks pay, sometimes they pass. In the main, however, pro-\n\ngramming costs do not rise proportionately with the size of the audience.\n\f"}, "003134.png": {"text": "+ Network distributions costs are fixed. AT&T did not charge more to transmit popular shows from the networks to\nthe local stations. A new network trying to establish itself would initially be at a severe cost-per-viewer disadvan-\ntage in paying this bill.\n\n+ Local distribution costs are fixed. For broadcast signals of equivalent range, it costs no more to reach 50 percent\nof the potential viewers than to reach 5 percent. Even newspapers do not have an economy of scale advantage as\nclear-cut as broadcasters do.\n\n+ Local production costs, like news programs, are somewhat fixed. Popular newscasters get paid more than less\npopular ones, it seems clear, but not in proportion to the size of their audience. Studio fixtures don\u2019t vary with the\nsize of the audience, nor do the cameras and other equipment that send out the signals.\n\n- Advertising costs are fixed. The ads the networks or stations run on themselves and for themselves, and the ads\nthey place in newspapers, magazines, or even on competing stations, do not vary with the size of their own audi-\n\nence. And advertising sales costs are essentially the same for all national networks regardless of viewership.\n\nA prudent executive at that time, deciding whether to invest millions of dollars to break into the network business, must have\nrealized how formidable was this array of competitive advantages protecting the incumbents and their profit margins. He or she\nwould also have seen that as a group, the networks were losing market share and that some of their advantages were eroding due\nto changes in technology (like the remote control, the VCR, and satellite transmission) and government regulations (like easing\nthe limitations on the reach of cable services). Even an audacious, deep-pocketed, politically savvy Australian media mogul would\nhave been operating at a significant competitive disadvantage\u2014never a happy strategic position. On the other hand, he may have\nnoticed that the networks, operating behind their barriers, had worked out some rules of the game that mitigated competition\ndespite an overall market share that was in decline. If our mogul played his cards right, he might get to take a seat at the table and\n\nprosper along with his established competitors.\n\f"}, "003135.png": {"text": "COMPETITION AMONG FRIENDS\n\nIf the Coca-Cola vs. Pepsi battle was a replay of the Civil War, pitting the sons of Atlanta against aggressive Northerners in White\nPlains, New York, the competition between the networks was more like country club golf. All were headquartered in New York\nCity. All had backgrounds in radio broadcasting; ABC came into existence with the forced divestiture of a portion of NBC\u2019s network\nin the 1940s. All moved into television at the start of the video era. Over the years, they worked out a set of tacit rules that kept\ncompetition in check and profits high. They did not undercut one another on price, either on what they would charge or what they\n\nwould pay. Unlike the soda makers, they learned how to play the prisoner\u2019s dilemma for the benefit of all.\n\nADVERTISING ARRANGEMENTS\n\nThe networks\u2019 revenues came from selling time to sponsors. They took care never to offer this time at discount prices. First, most\nadvertising time was prebought by the sponsors under long-term contracts. Time was available closer to the actual broadcast date\nin a spot market; the spot rates were higher than the contract rates. Contracting was done by all three networks during a limited\ntime period, which restricted bargaining by ad buyers. The networks did not undercut one another on price.\n\nSecond, they restricted the supply by limiting the number of advertising minutes in prime time under the mantle of a public\ninterest code of conduct. When the ads were sold, they came with an estimate of the size of the audience that would be reached. If\nactual viewers fell short of the estimate, the networks made good on the advertising contract by offering the sponsor more ad slots\nat no charge. This \u201cmake good\u201d practice used up more of the precious minutes, tightening supply just at those times when, due to\nfailure to deliver, demand might have fallen. If there were not enough buyers at an acceptable price, the networks either ran ads\nfor their own shows or they broadcast public service announcements. They did nothing to encourage sponsors to wait until the\nFor Sale signs were posted. The net result was that network advertising prices continued to rise steadily even as their joint market\n\nshare of viewers eroded.\n\f"}, "003136.png": {"text": "PURCHASING PROGRAMS\n\nThe networks approached the purchasing of programs with the same gentlemanly attitude they employed in the selling of adver-\ntising time. They did not vigorously compete with one another for new shows. Program ideas were shopped during a two-week pe-\nriod, so if one network expressed an interest, there was not enough time for a program\u2019s producers to see if another would outbid\nit. When a pilot episode had been filmed, the network retained the right to turn it down, and the studios were left to shoulder the\nexpense. These decisions also took place within two weeks, when the networks were putting their schedules together. This time-\nlimited competition kept the networks from bidding against one another for programs that looked like winners.\n\nNor did the networks try to woo established programs from one another. When a series did shift networks, like Taxi, which\nmoved from ABC to NBC in 1982, it was because it had been canceled by its original network, not enticed by its new one. The coop-\nerative stance of the networks toward programming also worked in their handling of sporting events. CBS had a long-established\nrelationship with the National Football League. Rather than challenge it, NBC helped to start the American Football League. When\nthe NFL and the AFL merged in the late 1960s, each network kept its relationship. Not wanting to be left out of a sport growing in\npopularity, but understanding how the networks played the game, ABC created Monday Night Football to get its share of the pie.\n\nThis arrangement lasted for more than two decades.\n\nAFFILIATING WITH THE LOCAL STATIONS\n\nThe networks did not steal one another's affiliated stations. Government regulations permitted only one affiliate per network ina\ngiven market, so there was room for all. Also, regulations made it difficult to shift a license from one local station to another, an-\nother constraint on network poaching. Still, the genteel attitude of the networks toward one another did as much as the regulatory\n\nenvironment to temper their competitive zeal.\n\f"}, "003137.png": {"text": "ROOM FOR ONE MORE?\n\nRupert Murdoch had not become one of the largest global media barons by playing nice. He had gone head-to-head with competi-\ntors, unions, and governments. His announcement that he intended to challenge the existing networks had to get their attention.\nHe already owned both the Fox studio and local stations in the large markets. He had a newspaper presence on three continents. If\nhe decided to invade the network industry with guns blazing, he had more firepower than the networks had seen from other po-\ntential interlopers.\n\nStill, a handicapper giving odds on a brawl] between Fox and the existing networks would have had to favor the networks. They\nhad the audiences, and they were not going to lose them quickly. Therefore, they could pay more for programs than could Fox, and\nthey could charge more for their ads. They already had strong local affiliates in addition to their owned and operated stations. NBC,\nnow owned by General Electric, and ABC, a division of Capital Cities Communications, had the resources to withstand a protracted\nconflict. CBS, in an effort to stay independent, had loaded its balance sheet with debt and was more vulnerable. Still, it had valuable\nassets it could sell, like the local stations it owned, and it could cut costs by consolidating operations. The lavish management style\nby which the networks had operated for years left them with plenty of fat to trim before they started to hit muscle or bone.\n\nThere is no doubt that a frontal assault by Murdoch, even one that ended in defeat for Fox, would have been costly for the\nnetworks. Had he competed on the price of ads, they could have matched him. But since his revenue stream was much smaller, the\ndollar damage to them would have been far greater. Had he bid for their programs, they could afford to pay more, but again, they\nhad a whole schedule to defend and he was just starting out. For Fox and for the networks, abandoning the old game of carefully\nmoderated competition for a bruising, no-holds-barred battle would have been painful.\n\nMurdoch needed a way gain admission to the club without having to batter down the gates and undermine the value of a\nmembership for himself and for the others. He had to let them know that his intensions were more or less harmonious with their\ninterests. He had to make them realize that letting him enter peacefully would serve them better than a scorched-earth defense. He\n\nneeded to send them signals that he knew how to play their game.\n\f"}, "003138.png": {"text": "LOCAL STATIONS\n\nMurdoch\u2019s first move was to buy six independent stations from Metromedia. He did not go after affiliates of the networks, which\nwould have been a shot across the bow. The $1.65 billion he spent on them was considerably more than their current cash flow\nwould justify, and he financed his purchase with debt. His plan to make them the heart of his new network would, he felt, justify\nthe premium he had paid. To the networks, the fact that he had not tried to steal their affiliates was reassuring, as was the debt he\nhad taken on to get into the business. His plans called for Fox Broadcasting to lose money in its early years, but with all that debt\nhanging over him, he was less likely to begin price wars on advertising or programming with his profitable competitors.\n\nWith the six Metromedia stations as a base, Fox went out to sign affiliates in the rest of the country. Though it did manage to\ncontract with local stations covering more than 80 percent of the country, they were not a strong group. Most of them operated in\nthe lower-powered UHF part of the spectrum, and they had a paltry share of the prime-time viewing audience. Fox would be start-\n\ning with a small base of viewers.\n\nADVERTISING\n\nMurdoch followed the lead of the established networks in subscribing to the code of conduct that put a limit on the number of\nadvertising minutes for each half hour of prime-time broadcasting. He established his price at 20 percent below what the net-\nworks were charging per rating point. This discount was only marginally aggressive. If he were to attract advertisers to his new,\nunproven, and much smaller network, he had to offer them something. By pegging his prices to those of the networks, although\nat a discount, he signaled that he intended to cooperate, but he also let them know that they could not match him on price. If they\nlowered their rates, he would maintain the 20 percent discount and lower his. Since their advertising revenue would dwarf his for\nthe foreseeable future, the pain to them would be much greater. On the other hand, if they raised rates, he would go along, albeit at\n\nhis 20 percent discount. He would not be an impediment to their continued exercise of pricing power.\n\f"}, "003139.png": {"text": "PROGRAMMING\n\nHere again, Fox did not confront the networks head-on. It started with a limited schedule of original programs. The first estab-\nlished star Fox hired was Joan Rivers, to host a late-night talk show. Rivers had already been passed over by NBC in favor of Jay Leno\nto follow Johnny Carson on The Tonight Show. The other programs in its first years were also ones that the established networks\nhad either rejected outright or were not likely to run. Studs, Married with Children, and The Simpsons were either too vulgar (though\nthis may be hard to believe from the vantage point of the twenty-first century) for the other networks, or in a cartoon format,\nwhich they reserved for Saturday-morning children\u2019s shows or Disney specials.\n\nMurdoch had made his fortune in print journalism by following the path of sensationalism in his papers. Even his broadsides\nwere tabloids. Fox Broadcasting adopted the same approach. By going down-market, it reduced direct competition with the other\nnetworks. If this kind of programming was going to win Fox an audience, it was more likely to come from independent stations,\neither broadcast or cable, that were already carrying similar fare. It also targeted a teenage and youth audience that had no estab-\n\nlished viewing habits and was more easily attracted.\n\nROOM FOR ONLY ONE MORE\n\nThe manner in which Fox secured local stations, priced its advertising, and filled its time slots with entertainment sent strong\nsignals to the networks that it was not going to make trouble. It did not appear checkbook in hand to steal any of their established\nprograms or stars or woo their local affiliates. Its advertising, though offered at a discount, was still pegged to the network rates,\n\nand it did not intend to expand supply by reserving more time for ads. The message to the networks was this:\n\n+ We intend to abide by the rules of your game.\n\f"}, "003140.png": {"text": "+ Though you can probably crush us if you choose, it will cost you much more to fight us than to let us in. And since\nwe have made the Fox Broadcasting System a part of our global media strategy, we are not going to go easily or\nquietly.\n\n+ The smart move is to let us join the club.\n\nConsidered as a prisoner\u2019s dilemma game, Fox signaled that it wanted to join the networks in the most profitable box on the\nboard.\n\nIt was the smart move for the networks, provided they did not see Fox as the first of a number of new entrants who as a group\nwould clearly spoil the party. Had they been faced with that challenge, they would have had no choice but to nail its hide to the\nbarn door as a warning of what other entrants might expect. But Fox could demonstrate that it was, if not unique, at least ex-\nceptional in the field of potential networks. It had bought the six Metromedia stations, added a few others, and signed up local\naffiliates, which gave it national distribution. Anyone else would have to get in via cable, which would be expensive for viewers.\nFox\u2019s network also was also part of a media empire that included a film studio and many newspapers and magazines. Those re-\nlationships may have looked formidable to the networks, even if they turned out to be less important than Murdoch anticipated.\nPutting all these features together, Fox could make the case that no one else was likely to try to enter the network business with the\n\nsame prospects.\n\nTHE BUSINESS TRANSFORMED\n\nThe networks did not try to kill Fox Broadcasting when it was still in its infancy. They read Fox\u2019s signals correctly, that it would be-\nhave itself if allowed to survive. And so it did, at least for a while. But over time, the environment changed and became more com-\n\npetitive. Regulation was loosened to allow more cable stations to enter and expand their offerings. Subscription cable channels\n\f"}, "003141.png": {"text": "grew in number and appeal. Broadcast technology via satellite continued to lower the cost of distribution to local stations. The\ndistinctions between a network and a large syndicator were breaking down, as syndicators bought first-run programming from\nstudios and delivered it directly to independent stations on shared advertising terms. Home electronic devices like the remote\ncontrol and the VCR became virtually ubiquitous, further shrinking the hold that stations had on viewers and, more important, al-\nlowing viewers to avoid watching the advertising that was footing the bill for the whole enterprise.\n\nThese developments lessened the potency of the competitive advantages that had made the network industry so profitable.\nThe new owners of ABC, CBS, and NBC moved to cut costs by reducing staffing at the news bureaus and elsewhere, and lowering\nthe amount they spent on programming. All of these changes had been in the works when Murdoch and Fox were moving into the\nbusiness. They continued during the period while Fox was establishing itself.\n\nThe presence of Fox, combined with the decline in profitability and the change in ownership of the other networks, ultimately\nundermined the culture of cooperation that had held the competitive juices in check. The networks were no longer the comfort-\nable and clubby collection of longtime associates. By 1993, Fox outbid CBS for the rights to broadcast National Football Confer-\nence games, ending a relationship of many decades\u2019 duration and sparking an extended bidding war that finally undermined the\nprofitability of football contracts. A few years later, ABC was angling to steal David Letterman from CBS, not a trick that Leonard\n\nGoldenson would ever have tried on William Paley. It was the sort of thing in which Coke and Pepsi were expert.\n\nWHAT ABOUT SYNERGIES?\n\nThe intended lynchpin of Murdoch\u2019s strategy had been integration, the idea that Fox Broadcasting, including the Twentieth\nCentury Fox studio, the network, and the owned and operated stations, would have opportunities for additional profits because\nof their tight relationships with one another and with the other parts of the News Corporation\u2019s media holdings. As well as using\n\nTwentieth Century Fox to feed the Fox network, he planned to syndicate shows overseas. But synergies, while often invoked to\n\f"}, "003142.png": {"text": "justify overpaying for an asset, are difficult to realize in practice. What added benefits were to be realized by putting companies in\nthe supply chain under the same ownership? If the industry is protected by barriers to entry, the firm is already earning superior\nreturns on capital. If the industry is competitive, then contracting with a sister company adds nothing to either firm\u2019s earnings. In\neither case, it is hard to identify any gains from putting the two firms under the same ownership.\n\nClearly there were no barriers to entry in the production segment of the business. New players emerged all the time, thanks to\nthe allure of the entertainment world. Companies in this business, as we should expect, had historically earned very low returns\non investment. The other networks did not own any studios, in part because of regulation but more importantly because they\nhad always found it less costly to let the studios do the creative work. In the case of Twentieth Century Fox and Fox Broadcasting,\nif the studio had a program that gave every indication of drawing a large audience, what would be gained from offering it to Fox\nBroadcasting at anything less than the going market rate? And if it had some shows that were not as promising, why should Fox\npay more for them than NBC or ABC? Money might be moved from one corporate pocket to another, but the net gain to the corpora-\ntion would be zero. So long as there was no shortage of supply, Fox Broadcasting gained nothing from its connection to the studio.\nSo long as it could produce shows that other networks wanted, Twentieth Century Fox gained nothing from its connection to the\nbroadcaster.\n\nWhat about advertising time? Suppose Fox Broadcasting was unable to sell out its advertising slots. Might it not use that spare\ntime to promote movies from Twentieth Century Fox, and do it at no cost to the studio? Perhaps, but if the time were available\nfor nothing, the audience could not have been attractive to paying advertisers. Maybe the studio would be getting something for\nnothing, but it could not be very much. Free advertising on a poorly watched network could not have been the source of Murdoch\u2019s\nsynergy strategy.\n\nFox\u2019s other supposed source of synergy was the ability to syndicate the studio's programs to international outlets. Here again,\nthe issue was whether anything was to be gained by doing the syndication in a sister company of the same corporation, or going to\noutsiders. If international syndication was a competitive industry, there was no joint benefit in keeping syndication in-house. The\n\nsyndicating arm could charge no more than could the competition, nor could it charge less and still make a profit. If international\n\f"}, "003143.png": {"text": "syndication was not competitive, if, that is, in certain markets, established firms were protected by barriers to entry, then the syn-\ndicating arm of Fox would be operating at a disadvantage. In this case, the studio would be better off contracting with a powerful\ncompany already in the business. Again, nothing in the corporate relationship between the studio and the syndicating arm would\n\nproduce any benefit.\n\nLEARNING FROM FOX\n\nThe history of Fox\u2019s entry into the network industry stands at the crossroads of many of the ideas in this book. The three networks\nenjoyed competitive advantages and barriers to entry, thanks to captive customers, government regulation, and significant\neconomies of scale. They made a lot of their money from their ownership of local stations, which were like tollgates on the road\nadvertisers needed to travel. The three networks had learned to play the prisoner\u2019s dilemma game and not engage in price wars, ei-\nther in the amount they would pay for program content or in the rates they would charge advertisers.\n\nThese high returns, and the barriers to entry on which they depended, were one of the reasons Murdoch decided to start a\ncompeting network. He played the entry/preemption game, which we discuss at length in the next chapter, like a master. He made\nit clear to the incumbent networks that it would be cheaper for them to let him into the club than to try to strangle his network in\nthe cradle. Fox succeeded in establishing itself as a fourth network where previous entrants had failed.\n\nDespite Murdoch\u2019s brilliance and the skills of the established networks in avoiding costly price wars, the idyllic situation did\nnot last for network television. Changes in government regulations and in technology both undermined most of the competitive\nadvantages that had made the networks so profitable. Cable stations, VCRs, even the remote channel changer diminished customer\ncaptivity and made the networks less attractive to advertisers, which were the primary source of revenue. The networks are still\n\nwith us, Fox included, but they are not the cash-generating machines they used to be.\n\f"}, "003144.png": {"text": "Finally, the Fox strategy was aimed at deriving benefits from owning businesses that boosted one another\u2019s profits. The studio\nwould supply programming content to the network and its affiliated stations, unsold advertising time could be used to promote\nfilms from Twentieth Century Fox Studios, and the company would own a syndication operation to sell the programs overseas.\nMurdoch was a media baron, and if he could integrate all the components in his holdings, surely some synergies would result. But\nin practice, synergies also depend on barriers to entry. If the various links on the supply chain are in markets where there are no\n\nbarriers, there is simply no extra profit to be extracted from a common ownership structure.\n\f"}, "003145.png": {"text": "CHAPTER 11\n\nGames Companies Play\n\nA Structured Approach to Competitive Strategy\n\nPART II: ENTRY/PREEMPTION GAMES\n\nCOMPETING OVER QUANTITY\n\nAfter price competition, the other commonly occurring competitive situation involves the decision to enter a market or to expand\nin an existing market. The essential competitive actions here concern output levels and production capacities rather than prices.\nCompetition along these dimensions is a natural complement to price competition, since prices and quantities are the two funda-\nmental variables in market competition.\n\nFox\u2019s decision to enter the network arena has elements of both situations. However, the nature of quantity competition differs\n\nin several major ways from that of price competition, and the strategic imperatives involved are not identical. Understanding the\n\f"}, "003146.png": {"text": "dynamics of quantity competition, involving both output and capacity, therefore, is a second essential element of competitive\nanalysis. The formal structure that captures the features of this kind of competition is known as the entry/ preemption game.\n\nThe first important difference between price and capacity competition is the issue of timing. Expanding capacity requires\na significant lead time and is long-lasting, in contrast to price changes, which can be quickly introduced and just as quickly re-\nscinded. For this reason, there is often an important distinction between the players in the entry/ preemption game. In the pris-\noner\u2019s dilemma game, all competitors have more or less equal status; anyone can be a leader or follower in changing prices. There\nis essentially no difference between offense and defense. In the entry/preemption game, the distinction between aggressor and\ndefender is generally clear. In most instances, there is an established company that plays defense against entrants who are trying\nto get into the market and are on the attack.: Therefore, in this game, the sides have to develop distinctly different strategies if they\nare to succeed.\n\nThe second important difference is that in the entry/preemption game, decisions, especially mistakes, have enduring conse-\nquences. In the prisoner\u2019s dilemma game, if there are long-lived unfavorable outcomes, they are the result of persistent foolish-\nness. At any moment, the competitors can take corrective action and make more profitable choices. But if Lowe\u2019s decides to build\na store on what has been Home Depot\u2019s turf, or Monsanto adds plant capacity to increase its production of nitrate fertilizer, these\nfacilities are in place for an extended period. When they play an entry/preemption game, competitors have to take into account\nthese long-run consequences.\n\nFinally, aggression plays a different role in entry/preemption games than it does in prisoner\u2019s dilemma games. In pricing\ncompetition, some firms justify extended, costly price wars with the hope that they may eventually drive their competitors out of\nbusiness entirely. Historically, however, there are few instances in which well-run, long-established companies have been elimi-\nnated by a price war. Except as a reaction to the behavior of others, aggression in price competition is almost always dysfunctional.\nThe saving grace is that the potential damage of aggressive price cutting is limited by the fact that it is readily reversible, at least in\n\ntheory.\n\f"}, "003147.png": {"text": "Aggression works differently in an entry/preemption game. First, given the costs of reversing direction when capacity de-\ncisions are involved, the incentives for an aggressive reaction to an entrant\u2019s initiative are reduced. Unlike for the price-cutting\ncompetitor, who can easily change course, the commitment to invest in additional capacity is not easily undone. Therefore, the\njustification for an aggressive response\u2014that it will bring the initiator to its senses\u2014is less robust, and the argument for ac-\ncommodation becomes more compelling. The corollary is that an aggressive decision to expand capacity or output may be more\neffective than a tentative one, since the respondent realizes that the aggressor is not going to back off. On the other hand, the risks\nof aggressive behavior are heightened in the entry/preemption game. If one firm takes steps to expand output and its competitors\nrespond in kind, the extended consequences of these capacity decisions make them hard to undo, and the mutual pain inflicted\nwill last a long time. Because aggression is a two-edged sword in capacity decisions, a more delicate approach is required to navi-\n\ngate the strategic imperatives of the entry/ preemption game than to manage pricing competition.\n\nSTRATEGIC APPROACHES FOR THE ENTRANT\n\nIna typical entry/preemption situation, an established firm in a local or product market enjoys material competitive advantages\nover most but not all other companies. One company, also a strong player with similar advantages relative to the majority of firms\nwith which it directly competes, considers entering the specific market in question. An example, which we discuss in detail in\nchapter 13, is Kodak\u2019s entry into the instant photography market, which was dominated by Polaroid. The ball is in the entrant\u2019s\ncourt; all the incumbent firm can do is prepare in a general way to resist the incursion. The outsider must decide between entering\nthe market and staying out. Though there are a range of possible entry moves, from tentative and measured to a full-frontal as-\nsault, to keep things simple we will treat the decision as binary, a choice between either enter or don\u2019t enter. If entry occurs, the in-\ncumbent now has to decide how to respond. It may have previously adopted a fierce attitude trying to forestall any entry, but once\n\nentry has taken place\u2014and deterrence, by definition, has failed\u2014the world looks quite different. If it reacts aggressively to repel\n\f"}, "003148.png": {"text": "the entrant, the incumbent is likely to face an expensive, drawn-out conflict involving price cuts, higher advertising expenses, and\nextensive and costly consumer promotions. It needs to consider the two basic alternatives; either accepting the entrant, however\n\ngrudgingly, or attacking it. Both alternatives have costs, and a rational decision compares them carefully.\n\nTHE TREE (OR EXTENSIVE) FORM AND ENTRY/PREEMPTION GAMES\n\nJust as there is a natural but not obligatory fit between prisoner\u2019s dilemma (pricing) games and the matrix form of representation,\nso the extensive or tree form of formal presentation works well with entry/ preemption (quantity) games. Consider a potential\ninteraction between Home Depot and Lowe\u2019s. In our example, Lowe\u2019s is well established in a particular geographic market and\nHome Depot is considering whether to open stores in that territory. In this case, the competitive interaction starts with Home\nDepot\u2019s initial decision. Conforming to our simplification decision, it can choose either to enter the market or to stay out. This\noption is represented in the first branches of the tree structure in figure 11.1. If Home Depot decides not to enter the market, then\nLowe\u2019s has nothing to react to and the game is effectively over, at least for the moment. This event is represented by the Don\u2019t Enter\nbranch and position D in figure 11.1.\n\nIf Home Depot decides to go ahead and open a store in this market, then Lowe\u2019s is compelled to respond. Its basic choices are\nto accept Home Depot's presence and not change anything about its operations, or to resist this incursion and make a competitive\nresponse. These choices are found on the upper half (Enter) of the tree, the branches Accept and Resist stemming from Lowe\u2019s\ndecision box. If Lowe's does nothing to contest Home Depot\u2019s entrance\u2014if it maintains its current prices, levels of advertising, and\npromotion; offers no special incentives to shoppers; and does not retaliate by threatening to open a store on Home Depot's turf\u2014\nthat may be the end of the story. We will be at position A in the figure, with the game over, or at least this inning ended.\n\nHome Depot might take Lowe\u2019s passivity as an invitation to be more aggressive\u2014to open stores in other Lowe\u2019s markets or try\n\nto capture much of its business in this area by aggressive pricing and promotion\u2014so it is impossible to write a definitive finis in\n\f"}, "003149.png": {"text": "any situation that involves two powerful competitors. To represent these later actions we would need to extend the Accept branch\n\nof the tree beyond our current terminus.\n\nChange in Profit ($ million)\n\nLowe's HomeDepot\n\n \n\n \n\n-$2m +$1m\nHome Depot | B lm +30.2m\nc -33m -$2m\nDon't Enter\n| D 0 0\n\nFIGURE 11.1\n\nThe tree (or extensive) form for an entry/preemption game\n\nLowe\u2019s, perhaps anticipating that if it rolls over and plays dead here it will only encourage Home Depot to make additional\n\ninvasions, may decide to resist. It can lower its prices, up its advertising, announce future store openings in Home Depot territory,\n\f"}, "003150.png": {"text": "and otherwise make life uncomfortable for its rival. Now Home Depot has to decide how it wants to respond. It can persist in its\naggressive strategy\u2014lower its own prices, step up its advertising, prepare to resist any Lowe\u2019s openings in its territory\u2014or it can\ndecide to scale back its original ambitions and be satisfied with a lesser share of the contested market than it had intended. In\neither case\u2014Home Depot persists (position C) or Home Depot draws back (position B)\u2014a stable outcome has been reached which\nis likely to last for some time. The Persist choice will lead to extended economic combat between the two firms, both in this initial\ncontested market and perhaps nationally. The Draw Back choice may produce a less aggressive outcome from both parties, each ac-\ncepting the other\u2019s dominance in certain markets.\n\nComparing the outcomes is easier if we establish one as a base case and evaluate the others relative to that base. In this\ninstance, the natural choice for the base case is the Don\u2019t Enter choice, to which we can assign a value of zero to each competitor,\nsince nothing has changed. We then calculate the incremental profits or losses for Home Depot and Lowe's for each of the other\nthree outcomes. If Home Depot enters and Lowe's accepts (position A), then Lowe\u2019s will have lower profits and Home Depot higher\nones than in the Don\u2019t Enter situation. Given what we know about other markets in which the two compete directly, we estimate\nthat Lowe\u2019s profits drop by $2 million and Home Depot's rise by $1 million.\n\nIf Lowe's decides to fight it out, then the ultimate outcome depends on how Home Depot reacts. One outcome follows the\npath Enter\u2014Resist\u2014Draw Back (position B). In this case, Lowe\u2019s losses are reduced to $1 million, and Home Depot gains only $0.2\nmillion. Finally, if Home Depot persists by responding aggressively to Lowe\u2019s resistance (position C), the outcome is probably the\nworst for both. Lower prices and higher advertising and promotional expenses will cut into profitability, only partially offset by\nthe increase in total sales in this market. That increase will also require more spending on overhead. The beneficiaries are the con-\nsumers, who get more choices and lower prices. Our assumption here is that the additional expenses will lower Lowe's profits by\n$3 million, Home Depot\u2019s by $2 million. As in the matrix presentation of the pricing decisions, the economic outcomes need to be\nadjusted to account for other motives, like concerns about sales level, relative performance, or the possible desire by Home Depot\n\nto leave no market served solely by Lowe's.\n\f"}, "003151.png": {"text": "Clearly this tree structure is a better tool than the matrix for representing competitive interactions in those cases where the\nsequence of actions is significant and where the available choices evolve over time as the game develops. The simplicity of the\nmatrix recommends it for situations in which timing is not important and the decisions can be repeated. One useful distinction is\nthat the extensive form works better in situations that involve capital investment decisions, where a major commitment has to be\nmade and the sequence of decisions does matter. The matrix form is suitable for pricing, marketing, and product feature decisions,\n\nwhich are more easily revocable and can be adjusted many times, depending on how the competition responds.\n\nASSESSING LIKELY OUTCOMES\n\nThe advantage of the extensive form (tree structure) for analysis is that it is dynamic. Steps proceed in sequence, and it is possible\nto think through the likely consequences of a series of actions and reactions as they progress. The process involves identifying at\neach future stage\u2014each decision box\u2014both one\u2019s own best choices and the likely responses of competitors. Putting these decisions\ntogether creates alternative paths through the tree, each ending in a particular outcome. Each outcome has a payoff, and by com-\nparing the payoffs, it is possible to rank the various courses of action. Some can be rejected outright if the payoff is awful, like the\npath Enter-Resist-Persist (outcome C) in figure11.1. Another may be provisionally embraced, like path Enter-Resist-Draw Back\n(outcome B), where the outcome is potentially beneficial, at least to Home Depot. Once the tree has been laid out, the analysis actu-\nally moves backward, from outcomes to prior choices.\n\nIn this case, Home Depot's final decision is whether to draw back after Lowe\u2019s has resisted, or to be aggressive and go head-to-\nhead with all the price cuts and additional advertising costs involved. If Home Depot's executives are rational, the choice is simple\n\u2014earning $0.2 million is better than losing $2 million. In the prior move, Lowe's is faced with the choice of acquiescing, which will\ncost it $2 million, and resisting, which will cost it either $1 million if Home Depot draws back or $3 million if Home Depot persists.\nLowe\u2019s, knowing the alternatives for Home Depot, assumes it will draw back. Thus Lowe's effective choice is between resisting,\n\nleading to an ultimate loss of $1 million, or accepting, leading to a loss of $2 million. If these are the alternatives, resisting is the\n\f"}, "003152.png": {"text": "better decision. Home Depot\u2019s original decision on whether to enter should be made fully cognizant of how Lowe's is likely to re-\nspond at that point. In this example, discretion is clearly the appropriate course.\n\nIn areal situation, the detailed development of the tree, with its branches, to all the potential outcomes, and then the analysis\nof alternatives by moving backward through the tree, will be much more complicated than in this straightforward example.\nRather than trying to anticipate all the possibilities from scratch, a more practical approach is to simulate the game.\n\nThe first step in a simulation is to identify the actors, their motivations, and the initial choice that sets the game in motion.\nDifferent people are assigned to the roles, and the game is played out step by step, choice by choice, until the likely paths have been\ndeveloped and the outcomes evaluated. Successive trials of this sort should identify which strategies lead to better outcomes and\nwhich lead to worse. This investigation by simulation will usually be more effective in identifying the superior paths through a\nrealistically complicated tree than an analysis that tries to anticipate all the choices through a purely mental exercise. Simulations\nare also the best means to incorporate historical information on real competitors, both the choices they have made in similar situ-\nations in the past, and their motivations as revealed by those choices.\n\nOnce the incumbent has made its choice, the entrant has limited flexibility. It can either retreat or advance from its initial\nposition. In the extreme, it may decide to back out altogether. But the fixed nature of the decisions within the entry/preemption\ngame\u2014the fact that substantial commitments have been made and retreat is difficult\u2014means that the outcome will be deter-\nmined largely by the incumbent\u2019s reaction to entry. With so much riding on this reaction, the entrant should do whatever it can to\navoid provoking an aggressive response by the incumbent. If it sees that an aggressive response is inevitable, it should stay out of\nthe market, because a protracted struggle will almost certainly ruin any chance that its foray will be profitable. To avoid an attack\nby the incumbent, the newcomer wants a strategy that will make it much less costly for the incumbent to accommodate than to\nresist.\n\nThere are a number of ways to minimize the costs of accommodation. The first is avoiding head-to-head competition, just as\nin the prisoner\u2019s dilemma. If the incumbent firm focuses on upscale, sophisticated customers, then the entrant can be less threat-\n\nening by targeting downscale, unsophisticated ones. It can choose a niche strategy if the incumbent has adopted a high-volume,\n\f"}, "003153.png": {"text": "mass-market one. It can concentrate on geographic or demographic sections within the market that have not been important to\nthe incumbent. For example, Fox Broadcasting entered the network television market with programs the established networks\nwould not touch, like The Late Show Starring Joan Rivers, The Simpsons, and Married with Children.\n\nSecond, the entrant should proceed quietly, taking one small step at a time. A brash public announcement that it plans to\ncapture a major portion of the incumbent's business, with openly proclaimed goals for market share, is almost certainly going to\ntrigger an aggressive reaction. The lobster dropped suddenly into a pot of boiling water struggles and tries to jump out. Lobsters\neased into a pot of cold water, which is then heated gradually, remain passive, even as they become dinner.\n\nA general nonconfrontational attitude can be reinforced with specific signals. Limitations on the entrant\u2019s capacity senda\nreassuring message. A single store is less threatening than five, and a new plant able to supply just 10 percent of the market is less\nof a concern than one able to satisfy the entire market. Idiosyncratic, restricted, and onetime sources of financing are another\nstrong signal of limited intentions. A large and visible war chest is more likely to lead to war than to the incumbent quitting the\nfield. Limitations in advertising reach and product lines also reduce the likelihood of a nasty reaction by the incumbent, since it\ncan weigh the small losses it will incur by accommodation against the costliness of an aggressive response. Fox\u2019s entry strategy\nstarted with a restricted programming schedule, both a recognition of economic reality and a signal of nonaggression to the in-\ncumbent networks.\n\nThird, to the extent that it can, the entrant should let the incumbents know that it is moving into only one market, not all the\nones the incumbents dominate, and that it is unique among other potential entrants. If the existing companies see the newcomer\nas only the first of many, they have no choice but to resist and make an example of it, to discourage the others. Again, Fox was\nclever. It made sure that its challenge to the existing networks was oblique. The target audience for its programs was distinctively\ndown-market when compared to that of its established colleagues. Fox\u2019s style would make a transition to the mainstream difficult,\nlimiting its threat to the established firms. Also, before it entered the network business, it had put together a string of local stations\n\nthat it owned or with which it had an affiliated relationship. Anyone trying to copy Fox\u2019s strategy would have difficulty replicating\n\f"}, "003154.png": {"text": "this move. The incumbent networks could believe that even if Fox did succeed, other newcomers were not likely to follow it into\nthe business.\n\nFourth, in situations where there are a number of incumbents, as in television networks, the newcomer wants to spread the\nimpact of its entry as widely among them as it can. Doing a little damage to a number of incumbents is less likely to provoke an\naggressive response than if the entrant wounds only one of them, but that one severely. In that case, the injured incumbent would\nhave to respond aggressively. Again, Fox\u2019s strategy was well formulated. Its first programs, late-night talk shows, put it into com-\npetition with NBC and Johnny Carson. But it followed with comedy and youth-oriented shows that competed more directly with\nABC. It did not try to challenge NBC\u2019s powerful Thursday night lineup, then (1986) anchored by The Cosby Show.\n\nThere are a number of things an entrant can do to make it expensive for incumbents to mount an aggressive response. If the\nentrant makes moves that are difficult for it to reverse, it sends the signal that an incumbent is in for a long and costly fight if it\ntries to crush the newcomer. A venture with a large upfront investment and hefty fixed costs, especially when the firm has some\nflexibility as to the split between fixed and variable costs, indicates a powerful commitment by the entrant to stay in this market.\nBy contrast, subcontracting production, sales, or some other important functions, especially when the contracts are short and\ncarry no significant cancellation penalties, sends the opposite signal: that the entrant is cautious and has an exit strategy in hand.\n\nWhen there are several incumbents, a strategy of making small inroads against each spreads the pain and makes the newcomer\nharder to kill, since none of the incumbents alone can deliver a mortal blow. Moreover, any incumbent firm that decides to attack\nthe entrant runs the risk, through collateral damage, of starting a war with its existing rivals, which can be costly and protracted.\nFor example, if either NBC, CBS, or ABC had felt the need to resist Fox\u2019s entry into the network business, and had attacked Fox by\nlowering its own advertising rates, that move would have shattered the cordial pricing discipline within the industry and hada\ndestructive effect on network profitability. It is hard for an incumbent firm in these situations not to shoot itself and its estab-\nlished competitors in the feet, once it decides to shoot. And, if its established competitors respond in kind, the situation will be-\n\ncome quite ugly. In Fox\u2019s case, the networks held their fire and there was no serious price competition for advertising.\n\f"}, "003155.png": {"text": "Finally, an entrant may make a strong public commitment to succeeding, or at least persisting, even if its actual activity is small\nand focused. The purpose is to deter retaliation by established firms, but the strategy can be dangerous. The worst outcome in an\nentry/preemption situation is a long and protracted competitive struggle. A strong public commitment by the entrant to succeed\nmay leave it no room for retreating, even if that becomes the rational choice. So commitments, if they do not dissuade the incum-\n\nbent from resisting, may lead to competitive wars, as in the contest between Kodak and Polaroid in the instant film business.\n\nTHE INCUMBENT\u2019S BALANCING ACT\n\nIncumbents in an entry/preemption game have to be more careful than the entrants, since they have more to lose. Even before\nany specific entrant appears on the horizon, an established firm can attempt to deter entry by its general attitude and competitive\nposture. If it could make an irrevocable commitment to respond aggressively to all challenges, then any potential entrant with an\nounce of rationality should steer clear and find some other market in which to work. In theory, this deterrent strategy, if success-\nful, would be very inexpensive, because the incumbent would never need to make good on its threats\u2014an assured-destruction\npolicy without the need for destruction. In practice, however, these commitments are difficult to make and expensive to keep, even\nif there is only small potential for irrational entry.\n\nAn established company can assume a confrontational posture by maintaining large excess capacity to meet any additional\ndemand created by an entrant offering lower prices. Its credibility is enhanced if its cost structure has high fixed and low vari-\nable costs, so that any additional product can be churned out at little extra expense. An advertising department and a sales\norganization ready to meet any competitive incursion, and a product line and geographical coverage that leaves few uncovered\nniches to tempt a potential entrant are all potent warnings to newcomers. Ample financial resources\u2014the proverbial war chest\u2014\nserve a similar purpose. Corporate culture and positioning can reinforce these economic measures. A company that concentrates\n\nnarrowly on one particular product, that lives or dies by its success or failure in that market, is going to be ferocious in defending\n\f"}, "003156.png": {"text": "itself against potential competitors. Polaroid, for example, did nothing but instant photography. At the other extreme, a diversified\ncompany with many eggs in many baskets, all of which need to be watched simultaneously by management, is less likely to go to\nwar over any single challenge. A company with a messianic devotion to its product line, which its sees not simply as a source of\nprofits but as a gift to humankind, is likely to be a more frightening competitor than a coolly rational economic actor for whom\nreturns on investment are the only touchstone. The company that can convey the depth of its commitment to its business has a\ndecent chance to keep most potential competitors at bay.\n\nThere are downsides to this strategy of preemptive ferocity. First, it is expensive to maintain excess capacity with high fixed\n\n \n\ncosts, to have marketing firms on retainer to meet challenges only on the distant horizon, and to have products in many niches so\nas not to leave any room for an entrant. These costs have to be measured against the benefits of deterring entry, and the measure-\nment is not simple, since no one can count all the entrants that have been successfully deterred. Second, if some entrant decides\nto proceed anyway and gets into a market, it may be more profitable for the incumbent firm to accommodate that entry than to\nrespond aggressively. Protracted price and feature wars do nobody any good. Thus, an adversarial, messianic culture is a double-\nedged sword that at times should best be left in its sheath. An established firm should always preserve an element of rationality\nand avoid the extremes of a potential competitive response to entry. Once the entrant has moved in, the established firm's strategy\nshould be to punish the newcomer as severely as possible at the lowest possible cost to itself. Just as in the prisoner's dilemma, this\npunishment is best delivered in the entrant\u2019s home markets. A price war hurts the leader in that market, and striking the entrant\nwhere it is strong and the incumbent only a minor factor is cheaper for the incumbent and much more costly for the entrant. This\nkind of reciprocity of home market invasion is an important weapon in any established firm\u2019s arsenal, and the earlier it is used, the\nmore effective it is. If Lowe\u2019s discovers Home Depot scouting real estate locations in Lowe\u2019s core territories, it should immediately\nand visibly respond in kind, sending its real estate staff onto Home Depot turf, contacting realestate brokers to make sure the story\n\ngets out. The implied threat has the additional advantage of being cheap to deliver.\n\f"}, "003157.png": {"text": "STRATEGIES REGARDING UNOCCUPIED TERRITORY\n\nA particular variant of the entry/preemption game needs to be approached with special care. There are territories in either\ngeographic or product space that are unoccupied. They are potential sites for an entry/ preemption game, but without the roles\nassigned to incumbent or entrant. Several equally powerful competitors may seek to claim that territory. The traditional wisdom\nsays that the first competitor to get its stake in the ground, making an irrevocable commitment to occupying that market in force,\nshould effectively preempt and deter its rational, but slower-moving, competitors. But in practice, the other firms considering\nentry are not usually put off by the early action of someone else whom they see as having only the insignificant advantage of a\nsmall lead in time.\n\nFor example, if Home Depot announces that it is going to build a store in territory previously unoccupied by it or Lowe's, Lowe\u2019s\nis as likely to infer that Home Depot has private information about the desirability of this market as that Home Depot is merely\ntrying to preempt any move Lowe\u2019s may make there. If Lowe\u2019s decides not to enter, and Home Depot does, and its store becomes\nnotably successful, the Lowe\u2019s managers are going to face sterner questioning than they would if they had followed Home Depot\ninto the market and both stores were marginally profitable. Indeed, the history of attempts to enter virgin territory preemptively\nhas not been a happy one for either the first mover or its slightly later competitors. In general, the watchword in the entry/ pre-\nemption situation is discretion over valor, and that advice is especially true in the case of unoccupied territories, which often turn\n\nout to be lawless frontiers.\n\nGENERAL PRINCIPLES FOR ANALYZING COMPETITIVE INTERACTIONS\n\nIn our analysis of direct competitive interactions, we have focused on just two forms of competition: prisoner's dilemma games,\n\nwhich are contests over pricing, and entry/preemption games, which are contests over capacity. This restricted approach is jus-\n\f"}, "003158.png": {"text": "tified primarily because these two basic games encompass the overwhelming majority of strategic situations that companies\nconfront when interacting with a small number of equally powerful competitors. So in cases of mutual competitive interactions,\nan efficient first step in formulating strategy is to look for features of these two games in the situation at hand. If either is present,\nthen it pays to exploit the wealth of existing wisdom about how these games are best played.\n\nMost realistic competitive interactions cannot be \u201csolved,\u201d in any formal sense, to yield an explicit best strategy. The use of just\ntwo specific games to organize information and anticipate actions is an acknowledgment of how imprecise the discipline is. Where\nthese two models fail to capture the essence of a competitive situation, thinking in these terms alone will have limited value. For-\ntunately, there are other ways to handle strategic analysis. One important alternative is the adoption of a cooperative perspective,\nwhich we will discuss in chapter 14. But before addressing cooperation, there are some general principles to keep in mind no mat-\nter what kind of game is being played.\n\nThe first is to organize the relevant information systematically: who are the competitors, what ranges of actions are available\nto them, what are their motivations, and what are the likely sequence in which decisions will be made. It is essential to identify\nspecifically those agents whose actions can affect a company\u2019s own profitability, whether they are current competitors, as in the\nprisoner's dilemma game, or potential competitors, as in entry/preemption, or some other more complex relationship. Companies\nthat ignore this imperative often find themselves confronting an unpleasant strategic surprise.\n\nFor each agent, the analysis should reveal:\n\n+ The range of actions that the agent has available. If a competitor does something completely unanticipated, there\nhas obviously been a failure of analysis.\n\n+ The consequences for the company of the possible combinations of actions by all the relevant competitive actors. What\ndo the outcomes and payoffs look like for all the parties?\n\n- How the various agents value these consequences, or, in other words, what motivates each agent?\n\f"}, "003159.png": {"text": "It also helps to identify any constraints on the sequence of actions that agents are likely to take and the information firms have\nwhen they make their choices among actions. Enough information must be collected and assimilated so that scenarios can be laid\nout and considered, as illustrated in bare-bones form by the Lowe\u2019s-Home Depot example.\n\nThere are two possible ways to employ this information. One is to lay it out systematically in either a tree form (figure 11.1) or\na matrix form (figure 11.2) and to try to reason through to a \u201csolution\u201d to the game. For simple situations, this approach may be\nfruitful. With situations of realistic complexity, reason alone will seldom unambiguously identify a precise best course of action.\nStill, general directions for how to proceed may emerge. For example, let us revisit the prisoner's dilemma example of Lowe's and\nHome Depot competing over prices and calculate the sum of the payoffs to all the players for each outcome. That is, how much did\nLowe\u2019s and Home Depot profit together\u2014including nonmonetary values\u2014in each of the four outcome boxes? If the sums, which\nare the joint outcomes, vary across the boxes, as they do here, then there is some scope for the firms to cooperate in order to reach\nthe highest joint outcome (table 11.1). In this case, the biggest joint payoff comes when each firm charges $115 and they divide the\nmarket equally; the smallest comes when each charges $105. All firms benefit if they restrict the competition to choices among the\nhigh-payoff outcomes. In this case and many like it, it may make sense for competitors to cooperate at some level.\n\nSimilar calculations are possible for the entry/preemption game (table 11.2). In this instance, the best joint result is that Home\nDepot not get involved in the first place. Should it decide to enter, then the best joint solution, although not the best for Home\nDepot, is with an entry that does not lead to full-throttle competition and a price war. Again, because of the variation in the total\n\nindustry (joint) payoff, there is room for cooperation.\n\f"}, "003160.png": {"text": "LOWE\u2019S\n\nSHS $105\n\nSLS\n\nHOME DEPOT\n\n$105\n\n \n\nFIGURE 11.2\n\nThe matrix (or normal) form of the prisoner\u2019s dilemma\n\f"}, "003161.png": {"text": "In contrast, if the joint payoffs are the same for all the outcomes, then there is no space for cooperation because the competitors\nhave nothing to gain from it. In these cases, competition should and will be unrelenting. These competitive situations are\nconventionally described as \u201czero-sum\u201d games (although \u201cconstant-sum\u201d is more accurate). Any gain that one competitor makes\ncan only be at the expense of its rivals. These games tend to arise when the people making the decisions care primarily about rel-\native performance\u2014about market share rather than revenues, profits compared to the competition rather than absolute profits,\nwinning rather than doing well. In the extreme, where winning or losing vis-a-vis the other firm is the only thing that matters, the\nexistence of only one winner for each outcome produces a constant-sum payoff structure and remorseless competition. When the\ncorporate culture stresses relative performance, that bodes ill for profits, returns to shareholders, and employee well-being. Unfor-\n\ntunately, this generalization is one of the few that can be made with any confidence on the basis of \u201creasoning\u201d alone.\n\nTABLE 11.1\n\nIndividual and joint payoffs in the prisoner\u2019s dilemma game\n\nChange in Profit ($ million)\n\nLowe's Home Depot Joint\nHD Enters\u2014Lowe's Accepts $ (2 \u00a2 1 $ 1)\n\u2014Lowe's Resists\u2014HD Draws Back $ 4) $ 0.2 $ (0.8)\nHD Persists $ (3) $ (2) $ (5)\nHD Does Not Enter $0 $ 9 $ o $ 0\n\f"}, "003162.png": {"text": "TABLE 11.2\n\nIndividual and joint payoffs in the entry/preemption game\n\nChange in Profit ($ million)\n\nLowe's Home Depot Joint\nHD Enters\u2014Lowe's Accepts $ (2 \u00a2 1 $ 1)\n\u2014Lowe's Resists\u2014HD Draws Back $ 4) $ 0.2 $ (0.8)\nHD Persists $ (3) $ (2) $ (5)\nHD Does Not Enter $0 $ 9 $ o $ 0\n\nAsecond approach that often works well in practice is to simulate\u2014to \u201cwar game\u201d\u2014the competitive interactions between the\ncontending parties. For simulation, the information should include a detailed description of all competitive agents, their potential\nactions, the returns they would realize under various industry outcomes, and their motives. These competitor profiles form the\nbasis for the people playing the assigned roles and making the decisions within the simulation. Simulations are more effective\nwhen they are played repeatedly to produce alternative outcomes, which can then be compared against historical experience. If a\ncompany in several lines of business, for example, always drops its prices as soon as any competitor enters one of its markets, that\nis a good indication of how it will act in the future.\n\nAnother benefit of simulation is that, while it can handle more complexity than rational analysis, there does come a point\nwhen the number of competitor profiles becomes unmanageably large. And at that point (more than a half dozen competitors is\n\na good rule of thumb) the simulation process also tends to be become diffuse and unwieldy. This is a fairly certain sign that there\n\f"}, "003163.png": {"text": "are no effective competitive advantages in the market in question, in which case analysis of direct competitive interactions is\nsuperfluous.\n\nFor most direct competitive interactions, it is best to bring multiple approaches to bear. Use the prisoner\u2019s dilemma and entry/\npreemption analysis when they are appropriate. Do well-planned simulations, and do them repeatedly. Consider relevant histor-\nical examples. Try to adopt a cooperative or bargaining perspective (chapter 14) and see where that leads. Competitive strategic\n\nanalysis is as much an art as a science, and the artist who can see the subject from multiple perspectives will do a superior job.\n\f"}, "003164.png": {"text": "CHAPTER 12\n\nFear of Not Flying\n\nKiwi Enters the Airline Industry\n\nBLACK HOLE: THE AIRLINE INDUSTRY AND RETURNS TO INVESTORS\n\nFor investors, the airline industry has been a vale of tears. In the first edition of The Intelligent Investor, Benjamin Graham wrote\n\nthat his book might be of use as a warning to those who bought shares in the expectation that the industry would grow.\n\nSuch an investor may for example be a buyer of air-transport stocks because he believes their future is even more\nbrilliant than the trend the market already reflects. For this class of investor the value of our book will lie more in its\nwarnings against the pitfalls lurking in this favorite investment approach than in any positive technique that will\n\nhelp him along his path.\n\f"}, "003165.png": {"text": "The history of the industry in the years between 1949 and 1970 bore out Graham\u2019s predictions. Revenues grew even faster than\nanticipated, yet \u201ca combination of technological problems and overexpansion of capacity made for fluctuations and even disas-\ntrous profit figures.\u201d\n\nBut the allure of the industry remained powerful. Warren Buffett, Graham's preeminent student and an investor renowned\nfor his business acumen and disarming candor, acknowledged that he, too, had been bitten by the airline bug, ignoring all that he\nhad learned from Graham. Temporary insanity was the only explanation he could offer for why he took a large position in USAir\npreferred shares in 1989. He should have known better. As he said, since the Wright brothers, \u201c...despite putting in billions and\nbillions and billions of dollars, the net return to owners from being in the entire airline industry, if you owned it all, and if you put\nup all this money, is less than zero.\u201d\n\nInvestors have repeatedly accommodated airlines by providing capital. Airlines have accommodated investors by providing\nthem with a stream of new companies and established ones emerging from bankruptcy. If insanity is indeed the explanation both\nfor entrepreneurs creating new airlines and for investors repeatedly throwing money at them, then the madness has been more\nthan temporary. But we may not need to resort to the insanity defense. Looking at the aggregate returns of an industry since its\ninception can mask periods of strength and niches of profitability. Even in the dark times of 2003, confronting a recession, fears of\nterrorism and war, and industry overcapacity, a few airlines managed to earn money even while others were declaring bankruptcy.\n\nSo the decision by the founders of Kiwi International Airlines to start a new carrier was risky but not necessarily suicidal. If\nthey picked their spot with care, managed not to antagonize the big, established carriers, and did all the other things essential to\nnurture a small business when surrounded by larger ones, they had a chance. Though there was a long list of prior entrants who\nultimately crashed and burned, a few had succeeded, most notably Southwest. But the Kiwi founders had to be aware that the air-\n\nline industry did not forgive mistakes in strategy or execution.\n\nNO GOLDEN AGE: THE INDUSTRY UNDER GOVERNMENT REGULATION\n\f"}, "003166.png": {"text": "Almost from the beginning, the airline industry seemed to require some assistance from the government. In the 1920s, the Kelly\nAirmail Act opened mail delivery contracts up to private airline companies. The steady revenue was important for them as they\nstarted to develop commercial passenger service. But since virtually anybody could get into the game, competition was fierce and\nthe route pattern chaotic. In 1930, the postmaster general tried to rationalize the system by awarding mail contracts at his discre-\ntion. Though Congress directed that competitive bidding remain in place, the postmaster guided the process to favor three major\nairlines, United, TWA, and American, each of which came to dominate one region in the cross-country market. These companies\ngrew by buying smaller competitors. In 1934, President Roosevelt learned that the airmail contracts contained rich subsidies for\nthe favored companies and tried to put an end to the practice. After a brief and disastrous effort to have army planes and pilots\ncarry the mail, the system reverted to competitive bidding. This time the competition was legitimate, and the three airlines had\nto bid against Delta, Continental, and other new carriers. All tried to grow market share by aggressive bidding; all lost money for\nsome years.\n\nTo address this problem, Congress passed the Civil Aeronautics Act in 1938, at the tail end of the New Deal regulatory phase. It\nestablished the Civil Aeronautics Board (CAB), with authority over route entry and exit, fares, mergers and acquisitions, interfirm\nagreements, and airmail rates. This regulatory regime established order in the industry, so much so that from 1938 through 1978,\nno new trunk line was created. The routes were distributed to provide cross-subsidies between dense, profitable long-haul flights\nand shorter, more lightly traveled and money-losing routes. The carriers could not compete on price, and they were allowed to\nraise fares when their own costs increased. For a while, the trunk carriers flourished. Even though the CAB encouraged local carri-\ners to enter the market, the four largest trunk carriers retained 70 percent of the market into the 1960s.\n\nDespite all the protection afforded by the regulators, the industry did not continue to prosper. The adoption of jet aircraft,\nbegun in the later 1950s and in full throttle over the next ten years, added enormous capacity to the trunk carriers. The planes\nheld more passengers and traveled much faster. All the airlines were left with seats to spare, just as they had more debt to service\nto finance their new planes. The first oil shock of 1973-74 raised their operating expenses, as did inflation in the labor market. A\n\nweak economy dampened demands for seats. The situation was so dreary that the CAB sanctioned cooperation among the carriers\n\f"}, "003167.png": {"text": "to reduce capacity in major markets. Nothing helped. There were too many seats and not enough customers. Regulation may have\nbeen part of the problem. Intrastate carriers, not subject to CAB fare requirements, charged less per mile, sold more of their avail-\n\nable seats, and earned more money than did the interstate airlines.\n\nEVERYONE INTO THE POOL: THE END OF REGULATION\n\nBy 1978, liberals and conservatives had joined forces to push for deregulation. There was some apprehension that travelers might\nbe gouged if they had only one airline to choose from for a specific destination, but economists argued that since barriers to entry\nwere so low, a competitor would quickly enter any market supporting excessive fares. President Carter had appointed economist\nAlfred Kahn as chairman of the CAB, and Kahn was thoroughly committed to ending the regulatory regime. Congress passed and\nCarter signed the Airline Deregulation Act in October 1978. Under its provisions, the CAB would no longer regulate fares or routes;\nairlines would be free to fly where they wanted and charge what they liked. Regulation was supposed to phase out over a several-\nyear period, but it unraveled almost immediately. Price controls were gone by 1980, as were restrictions that determined which\ncarriers could fly what routes.\n\nWith the end of regulation, the industry became intensely competitive. The large, established trunk carriers were challenged\nalmost immediately by regionals looking to expand outside their areas of strength and by new entrants trying to profit by offering\nlower fares on a few profitable routes. The newcomers were not burdened by the expensive and restrictive labor contracts that had\nbeen the norm during the regulated period, when airlines were able to raise fares to cover expenses. Their challenge left the incum-\nbents with no choice but to compete on price, no matter the impact on their profitability. Some of the weaker airlines attempted to\nsolve their high labor cost problems through Chapter 11 bankruptcy proceedings. When they emerged, they were not bound by ex-\nisting union contracts and could rehire workers at substantially lower wages. Wages in the industry declined through the 1980s,\n\nbut these savings did not help the airlines\u2019 bottom lines. Only the customers benefited.\n\f"}, "003168.png": {"text": "Of the many unanticipated changes induced by deregulation, the most far-reaching was the emergence of a hub-and-spoke\nroute system. Under the pressure of competition, the trunk carriers realized that they could lower costs and fill more seats by fun-\nneling traffic through hub cities, where long-distance and short-haul flights converged. A single hub connected directly to 40 cities\nat the ends of its spokes would link 440 city pairs with no more than one stop or change of planes. The airline could concentrate its\nmaintenance and passenger service facilities in the hub airports. It could focus its local advertising where its route structure was\nmost dense. There were substantial regional economies of scale for the airline that dominated a hub airport, as well as the benefits\nof needing to fly fewer planes to service its routes.\n\nBut all the cost and revenue advantages of a hub-and-spoke system were vulnerable to intense competition from weaker car-\nriers who, in order to fill their seats, dropped prices below what it cost to fly the passengers. When one airline dominated a hub, it\nmade money. When two well-established airlines served a single hub city, they often managed to keep prices stable and profitable.\nBut a third carrier, especially one trying to break into a new market, with low labor and other fixed costs, and with an aggressive\nmanagement out to earn their wings, could wreak havoc on the incumbents\u2019 income statements. One economist calculated that\nthe arrival of a low-priced entrant in a market would do as much damage to the value of an incumbent's equity as if it had to fly its\nplanes empty for about four months.\n\nThe incumbents found themselves in a quandary. They could match the prices and lose money on every ticket sold. They could\ndecline to match, and lose passengers. Customer captivity, even with frequent-flier programs, was low to nonexistent. Sometimes\nthe challenger was simply too egregious, and incumbents retaliated not simply to keep their passengers but to drive the upstart\nout of business.\n\nThe more strategic response, developed over some years after 1978, involved the use of a complex and opportunistic fare\nsystem to manage \u201cyield\u201d and \u201cload.\u201d The airlines defined \u201cyield\u201d as revenue divided by revenue passenger miles (the number of\npassenger seat miles actually sold), \u201cload\u201d (or \u201cload factor\u201d) as revenue passenger miles divided by available seat miles. Using their\ncomputerized reservations systems, the airlines could offer identical seats at wildly different prices, depending on travel restric-\n\ntions, time of purchase, and the remaining availability of seats. With experience and good programming, the major airlines could\n\f"}, "003169.png": {"text": "continuously adjust the price structure to milk as much revenue as possible from the ticket sales. Smaller and newer competitors\nhad neither the history, the volume, nor the sophisticated information technology to compete on this front. Their business strat-\negy encouraged a \u201ckeep it simple\u201d approach, for example by offering all tickets on a route with no restrictions, and at the same\nprice.\n\nThe efficiencies of the hub-and-spoke system, fortified by yield enhancement through a complex fare structure, provided some\nrelief to the established and well-run carriers. They had at least a temporary respite from the aggressive competitors, both new and\nseasoned, who were willing to lower prices to fill one more seat. But neither hub-and-spoke nor the sophisticated fare structure\nwas sufficient to transform an industry that was marginally profitable in its good years into a reliable money maker. By 1990, the\nthree most successful large carriers were United, American, and Delta, all with strong hub systems. Some old names like Eastern\nand Pan American had virtually disappeared, while others like TWA held on, but barely. Yet even the leaders had just scraped by.\nOver the twenty-six years from 1975 through 2000, the combined returns for the three averaged slightly less than 4 percent in\npretax operating income, around 7 percent in pretax return on invested capital (figure 12.1). With returns like this, the wonder is\n\nwhy so many people, both operators and investors, continued to be attracted to the industry.\n\nTHE INDUSTRY IN 1990\n\nThe structure of the airline industry is straightforward (figure 12.2). At the core are the carriers, both the large trunk firms and the\nsmaller, more regional and local ones. They fly aircraft manufactured by a few airframe companies. In 1990, only three companies\nwere producing large aircraft: Boeing, McDonnell Douglas, and Airbus. Another group, including Embraer, Bombardier, Fokker,\nand a few others, made smaller planes for shorter routes. Though the airlines sometimes received financing from the manufactur-\ners, relations between airlines and manufacturers were essentially arm\u2019s length. The arrival of Airbus as a genuine competitor in\n\nthe 1980s gave the airlines some leverage in dealing with Boeing, the dominant supplier. Other essential elements for the flight,\n\f"}, "003170.png": {"text": "including catering, deicing, and fueling, were provided by specialized service companies. Most of the other important functions,\nlike aircraft maintenance, baggage handling, and ticketing, the major airlines did for themselves, with the smaller carriers con-\ntracting out for some of them. Financing was provided either internally by the larger carriers, when their balance sheets were\n\nstrong enough, or by third parties, either as lenders or leasers of the planes. Even start-ups like Kiwi were able to find someone who\n\nwould lease them an aircraft.\n\n14%\n12%\n\n10%\n\n \n\n1975 1980 1985 1990 1995 2000\n\neee United \u2014\u2014American ewes Delta\n\f"}, "003171.png": {"text": "FIGURE 12.1\nOperating income margins of United, American, and Delta Airlines, 1975-2000\n\nWithin the carrier portion of the industry, the airline companies fell into several overlapping categories. There were the large,\nseasoned companies like United, American, and Delta, whose routes went back far into the regulated era. These three had been the\nmost successful of the bigger airlines, even though, as we saw above, they were not consistently profitable. But within their home\nterritories\u2014their most significant hubs\u2014they did earn money and maintain their market share. Other established carriers had\nstumbled after the end of regulation. Some, like Pan American, disappeared entirely; others, like Continental and TWA, went into\nbankruptcy, merged, or were bought out and reorganized. One newcomer, Southwest, had established itself as a profitable niche\nplayer, flying selected routes in Texas and the Southwest, mostly out of a hub at Love Field in Dallas. Southwest was extremely\nefficient. Other upstarts, like Midway, People Express, and New York Air, had had a moment or two of glory as small, focused com-\n\npanies, but then grew themselves into bankruptcy.\n\f"}, "003172.png": {"text": "FIGURE 12.2\n\n   \n   \n\nAirplane Manufacturers Airlines (Carriers) Ticket Agents\nBoeing Trunk Mumeroves\nMcDonnell Douglas i Corporate Travel\nAirbus\n\nDepartments\nEmbracer a\nBombardier\nFokker\nAnd others\n\nCustomers\n(iliers)\n\nLocal Airport Authorities\nMaintenance and Catering\nServices\n\nFinancing Sources\n\nMap of the airline industry\n\f"}, "003173.png": {"text": "The airline companies distributed tickets through travel agents, of which there were many, through corporate travel depart-\nments who set themselves up to capture the agency discount for themselves, and directly to passengers. Some of the airlines, no-\ntably United, American, and TWA, were able to harvest some advantages through their computerized reservations systems, which\nthey provided to ticket agents, and that were programmed to display their own flights at the top of the page. They also profited by\ncharging other airlines a fee per ticket to qualify as \u201ccohosts\u201d and receive favorable placement on the screens. The systems supplied\ntheir airline owners with information on competitors\u2019 pricing and scheduling. Clearly it was better to be the owner of a popular\ncomputer reservations system than an airline needing to rent space on someone else\u2019s system.\n\nThe last player in the industry, broadly considered, was the local authorities who controlled the airports and, more impor-\ntantly, the allocation of gates. In the entire production chain, gates in heavily trafficked airports were the only truly scarce re-\nsource. The local authorities, had they so chosen, could have collected for themselves whatever economic rent the competition for\na limited supply would generate. But the authorities had as their main mission the economic development of the region. Their pri-\nmary interest was to promote air traffic at the airport, to have strong carriers connecting their city to many others with frequent\nand convenient flights. So in most cases they did not try to milk the last dollar from the carriers, at the risk of reducing service.\n\nWe know that there were no substantial barriers to entry protecting the airline industry as a whole. Existing firms disappeared\nand new ones entered, with a pace of turnover that we do not expect to see in an industry with incumbent competitive advantages.\nThe operating margins and returns on investment for the three leading carriers reflect intense competition among incumbents\nand newcomers alike. In the main, deregulation had been a bonanza for passengers, at least for those whose primary concern was\nprice. But it had been hard on carrier profitability.\n\nStill, within the competitive turmoil, some pockets of strength and stability persisted. As we would expect, local dominance\nplayed the critical role. United, American, Delta, Continental, and TWA all had hubs in which they were the leading carriers.\nWithin these hubs, they maintained share stability and even profitability, as the combination of some consumer preference and\nlocal economies of scale created a competitive advantage. Travelers were more likely to make their first call to the carrier with the\n\nmost flights to the most destinations and the most convenient gates; size begat traffic. And the economies of scale available to large\n\f"}, "003174.png": {"text": "carriers within the hubs were considerable: centralized maintenance; better deployment of crew, ground staff, and even airplanes;\ntargeted advertising and promotion. Once a carrier dominated a hub, it could spread these essentially fixed costs over a larger\npassenger base. Even its frequent-flier program, designed to reward loyalty and thus keep passengers committed to one carrier,\n\nworked more effectively when that carrier was the logical choice because of its hub dominance.\n\nKIWI TAKES OFF\n\nThe founders of Kiwi International Airlines, a grand name for a company that would initiate service with a fleet comprising two\nused Boeing 727s, were mostly pilots who had been laid off in the turbulent years of the late 1980s. Their motivation was to put\nthemselves and people like them back into the cockpits and cabins, working at jobs they loved. They figured that with their experi-\nence and passion, they could run their airline more intelligently and efficiently than the mismanaged carriers whose problems had\nled to their unemployment. They had something to prove. This kind of motivation, including a dose of revenge, does not generally\nmake for the most realistic business plan or management strategy. But whatever its source, the approach Kiwi took to entering the\nairline business was brilliant.\n\nIn 1990, the core of the future Kiwi team, led by former Eastern Airlines pilot Robert Iverson, started to put together a plan to\nbuy the New York\u2014Boston-Washington shuttle from troubled Pan American. Within a year they had secured enough backing to\nmake a fully funded $100 million bid. They lost out to Delta, which bought the shuttle, Pan Am\u2019s additional routes, and its other\nassets for $1.7 billion. Another abortive bid, this one for Midway, with different financial backing, was trumped by Northwest. But\nthe team stayed together. Ten pilots kicked in $5,000 apiece, enough money to allow the group to continue planning. They looked\ninto buying the Federal Aeronautics Administration certificates from ailing carriers in California and Florida, but that came to\nnaught. Then officials in the FAA and the Department of Transportation, impressed with the team\u2019s professionalism and determi-\n\nnation, suggested that they start an airline from scratch and apply on their own for a certificate.\n\f"}, "003175.png": {"text": "Financing came from forty-six pilots who each invested $50,000, from flight attendants who put in $5,000 apiece, and from\nsome former airline executives who contributed various amounts. The company managed to raise around $7 million, hardly a\nfortune but enough to get off the ground. They chose Newark as their center of operations because competition there was less in-\ntense, and they became the first scheduled airline based in New Jersey. When they began flying in September 1992, they had leased\ntwo used planes to operate on three routes, Newark to Chicago, Newark to Atlanta, and Newark to Orlando. How could such a tiny,\nunderfinanced, new enterprise hope to survive, much less flourish, in a contest with United, American, and Delta, the three most\npowerful airlines in the industry?\n\nIn some ways, Kiwi\u2019s position was similar to Rupert Murdoch\u2019s when he decided to challenge the network incumbents with\nFox Television. The networks were already big, and they benefited from economies of scale and some customer captivity. Mur-\ndoch would clearly be operating at a disadvantage. On the other hand, the network industry was highly profitable because there\nwere strong barriers to entry and the incumbents knew how to play the prisoner\u2019s dilemma game, to live harmoniously with one\nanother. The airline industry had much lower barriers, confined to those carriers with strong hub dominance. In the main, the\nairlines did not know how to get along with one another. The history of the industry in both its regulated and deregulated phases\nshowed how difficult it was to restrain overcapacity, and how overcapacity led, almost inevitably, to brutal price wars. With such\nlow barriers, Kiwi did not have a problem getting into the industry. Perhaps the question was, why did it want to?\n\nThe Kiwis understood that they should not frontally antagonize the established carriers. As Iverson told Forbes magazine, \u201cOur\ntask is to stay away from their bottom lines.\u201d That meant staying small and unthreatening enough so that it would cost the airlines\nmore to eliminate them\u2014\u201cto swat a fly off their backs,\u201d in Iverson\u2019s terms\u2014than to let them live. The choice of routes was part\nof this strategy. The Newark-to-Chicago route would cut only minimally into United\u2019s and American\u2019s business. The Newark-to-\nAtlanta route would nick Delta; the flight to Orlando would take some business from Delta and Continental. By spreading the pain\naround, Kiwi minimized the loss to any single competitor. It also reduced its business risk by flying three routes; if any of the major\n\ncarriers started a fare war to eliminate Kiwi, it would still have two routes unaffected by the competition.\n\f"}, "003176.png": {"text": "Kiwi also avoided challenging the carriers directly on price. Kiwi pegged its ticket charge to the lowest restricted fare the com-\npetition was offering. It did enhance the service. Its tickets were unrestricted and required no advanced purchase. It reconfigured\nits planes to reduce the number of seats from 170 to 150, putting all passengers in the equivalent of business class. It served hot\nmeals rather than snacks.\n\nIt had no substantial budget to promote itself in the public media, so it avoided another direct challenge to the incumbents.\nInstead, Kiwi executives went directly to its target market, the managers of smaller businesses for whom low prices and superior\nservice made a difference. Iverson and his colleagues made the rounds of Rotary and Kiwanis Club lunches, telling the Kiwi story.\nOther Kiwis visited travel agents and companies, leaving literature and a good impression. This story of \u201cthe little airline that\nmight\u201d caught on, so that even before its first flight, it garnered more than enough press coverage to compensate for its lack of an\nad budget.\n\nKiwi did not poach pilots, flight attendants, or other personnel from the existing airlines. A large part of its reason for being\nwas to put these people back to work in an industry they loved and in a company they thought they could run more intelligently\nand profitably than the ones that had laid them off. Kiwi believed that it could earn money by having a cost structure much lower\nthan that of the traditional carriers. It leased its planes at a bargain rate because, with so much turmoil in the industry, used planes\nwere a glut on the market. It saved by substituting skillful public relations for expensive advertising. Its real key was supposed\nto be its lower labor costs. The pilots and attendants were going to earn much less than their peers at the established carriers, yet\nsmile about it. The \u201ccan-do\u201d attitude of its employee-owners, who would dispense with the restrictive work rules that burdened\nthe traditional carriers, also helped. No job was beneath a pilot, attendant, or other employee. Pilots as managers could fly planes, if\nthe need arose and a scheduled pilot called in sick. Before it began flying, the company calculated that it could break even if it filled\naround 50 percent of its seats. Its cost structure was planned to come in at 20 percent lower than United\u2019s per revenue passenger\nmile. Though this savings was substantial, South-west\u2019s cost were some 18 percent lower still. But lower costs did not present the\nsame kind of frontal challenge to the established airlines that well-advertised lower fares might. Kiwi did not want to arouse the\n\nslumbering giants.\n\f"}, "003177.png": {"text": "\u2018WHAT THE INCUMBENTS SAW\n\nAt first, Kiwi made it easy for United, American, Delta, and Continental to ignore it. It could carry so few passengers on each of\n\nits routes that even if it filled every seat, the loss to the big carriers would be miniscule. It aimed at a segment of the market\u2014the\nsmall business traveler\u2014that was not a high priority with the established carriers. It did not begin a price war, even though it\noffered more service and convenience for the same fare. It did not steal pilots. It did not look like it had grand plans for growth; it\nhad not raised public capital, and its employee-contribution approach to raising equity involved clear limitations on the amounts\nthat could be accumulated. For Kiwi to become a threat rather than a pest, some of these parts of its business plan would have to\nchange. Also, Kiwi was distinctive enough, with all those airline veterans pitching in, to make its approach difficult to replicate.\nOnly pilots aching to get back into the cockpit would kick in their savings and pitch in to load baggage. It was unlikely that one suc-\ncessful Kiwi would engender a dozen more.\n\nThe Kiwi business strategy had always been aware of what the airline would look like to the established carriers. \u201cWe designed\nour system,\u201d Iverson told a trade journal, \u201cto stay out of the way of the large carriers and make sure they understand we pose no\nthreat. The seats we take away will be insignificant, so our presence in the market will have no measurable impact on their yields.\u201d\n\nOn the other hand, Kiwi did look like it might be difficult to eliminate. The pilots, flight attendants, and other airline veterans\nformed a committed community. If they had not exactly pledged their lives, their fortunes, and their sacred honor, they had come\nclose. The $50,000 each pilot had invested was for most a substantial sum; undoubtedly, some of them took out second mortgages.\nThe pilots wanted to remain pilots, and for many of them the next best alternative was a distant second. Should any of the estab-\nlished airlines decide that Kiwi had to be confronted, Kiwi had given notice that it was not going to go quickly.\n\nAny price war with Kiwi would be protracted and costly, with most of the cost borne by the established carriers. If United\ndecided to confront Kiwi on the Newark-to-Chicago route, it would also challenge American, which would have to respond. Each of\nthem, carrying many more passengers than Kiwi, would suffer disproportionately compared to the small upstart. Having pegged\n\nits fares to those of the established carriers, Kiwi had announced that it was going to meet any reduction in price. Meanwhile, Kiwi\n\f"}, "003178.png": {"text": "would still be making a profit, presumably, on its Atlanta and Orlando runs. So the fare war would not end quickly, and the longer\nit lasted, the more bleeding the large airlines would do. The real economic pain of a price war seemed more trouble than the minor\ninconvenience of losing a few passengers to Kiwi.\n\nKiwi\u2019s entry strategy was uniformly well conceived. It made Kiwi hard to kill without threatening the established carriers.\nInitially this strategy seems to have worked well. The major airlines did not respond aggressively during Kiwi's first three months\nof operations. But in early 1993, as Kiwi\u2019s success began to draw attention, Continental, which also had a hub at Newark and thus\nwas directly threatened, undercut Kiwi\u2019s fares. Kiwi employees responded by accepting pay cuts to keep the airline viable. Conti-\n\nnental retreated and for the next year it left Kiwi alone. Kiwi appeared to be on track for a profitable, though small-scale, future.\n\nKIWI GROUNDED\n\nUnfortunately, Kiwi could not sustain its disciplined approach. In September 1992, the airline had two hundred employees, two\nleased planes, and six scheduled flights per day. By September 1994, it had grown to one thousand employees, twelve planes, and\nforty-seven flights. Kiwi had added Tampa and West Palm Beach as destinations to its earlier roster of Newark, Chicago, Atlanta,\nand Orlando. It had complicated the route structure by more than doubling the direct routes connecting these cities. Nor was it\nthrough expanding. By March 1995, it had fifteen planes, operated sixty-two flights per day, and was about to add Bermuda, Myrtle\nBeach, Raleigh-Durham, Richmond, and Charlotte to its route structure. Kiwi\u2019s original strategy\u2014to not get so big as to challenge\nthe existing carriers, and to focus the business on a single hub, simple route structures, and an identifiable target market\u2014was\nnow history.\n\n\u201cFish gotta swim,\u201d wrote Oscar Hammerstein, \u201cand pilots gotta fly,\u201d he might have added. There were at least forty-six pilots\nwho bought into the Kiwi mission. They were not going to be satisfied sharing six flights per day, even if each were a round-trip.\n\nThey also wanted to prove that they knew better than the companies that had fired them how to operate an airline at a profit.\n\f"}, "003179.png": {"text": "Also, Kiwi did not succeed in escaping the curse of other entrants. A spate of fledgling airlines\u2014Western Pacific, ValuJet, Reno\nAir, Midway, Air Tran, Frontier, Vanguard, Air South, and Spirit\u2014entered the industry at essentially the same time. The combina-\ntion of cheap aircraft available for lease, a supply of laid-off former airline pilots, and the continuing labor-related problems of the\nmajor airlines proved fatally attractive to others beyond Kiwi. The influx of so many new carriers forced the existing airlines to\nrespond. By the spring of 1994, price competition by the majors was back in force. Continental and United even started low-priced\nversions of themselves, Continental Lite and Shuttle by United. Kiwi found itself with too much company for a stealth strategy to\nsucceed, even as it abandoned that strategy.\n\nIncreased size and a wider route structure could not, of course, provide Kiwi with economies of scale comparable to those\nenjoyed by the major airlines. Nor could they compete with the established carriers on customer preference. More frequent flights,\nmore useful frequent-flier programs, and a perceived higher level of safety\u2014an advantage abetted by the ValuJet crash in the\nspring of 1996\u2014all favored the big carriers. Meanwhile, Kiwi\u2019s larger and more complex route structure led to higher costs without\nsubstantially enhancing its appeal to customers.\n\nGrowth also undermined Kiwi\u2019s anticipated operating efficiency. In 1994, CEO Robert Iverson looked back on Kiwi\u2019s promising\nstart and rhetorically asked, \u201cHow did this miracle happen?\u201d His answer was that Kiwi employees \u201cwith a selfless sense of mis-\nsion see solutions not visible through the traditional clouds of adversarial corporate storminess.\u201d With something at stake, the\nemployees were \u201calways thinking about how to make this company better.\u201d But this spirit seems not to have survived the influx of\nadditional employees necessary for rapid expansion. The new employees did not have the same high level of commitment as the\nfirst generation. The Kiwi originals found themselves in a larger, more impersonal organization that could not be run only on en-\nthusiasm and a willingness to pitch in.\n\nAfter his tenure ended in February 1995, Iverson took a very different view of the company and its ethos. It had become\ndifficult to get workers to do as they were told. Pilots refused to fly charter trips because they thought of Kiwi solely as a scheduled\nairline. Some flight attendants refused to make promotional announcements because they considered them undignified. Some\n\nemployees gave free tickets to charities without management approval. Meetings lasted forever because everyone had to havea\n\f"}, "003180.png": {"text": "say. Behavior looked so churlish that one executive likened it to grade school. A structure of operations that had been well adapted\nto Kiwi\u2019s original strategy proved unsuitable in its new growth mode.\n\nBy the end of 1995, Kiwi had accumulated losses of more than $35 million. The company ran through three more chief ex-\necutives in a few months after Iverson\u2019s removal. Finally Russell Thayer became CEO. He had experience in the industry. He had\nbeen president of Braniff when it filed for bankruptcy in 1982, and he had tried to fix Pan American before its demise in 1992. He\nwas no more successful as a savior for Kiwi. The airline filed for Chapter 11 bankruptcy in October 1996 and ceased operations a\nshort time later. Kiwi had a lot of company in its failure. Of the many new airlines that jumped into the deregulated industry, only\nSouthwest, with a well-developed hub in Dallas and a famous operating efficiency, survived and flourished. (The jury is still out on\nJet Blue and some other newcomers.) It is possible that Kiwi never had a realistic chance for success, given its initial competitive\ndisadvantages and the toxic state of competition in the airline industry. Still, it did not help itself with its rapid abandonment of a\nstrategy that was well designed and appeared to be working. Strategy ought to be a guide for action, not a rationalization for other-\n\nwise unrealistic business goals.\n\f"}, "003181.png": {"text": "CHAPTER 13\n\nNo Instant Gratification\n\nKodak Takes On Polaroid\n\nELEPHANT AT THE GATES\n\nGeorge Eastman is one of the giants in the history of American industry. For most of its long life, Eastman Kodak, the company he\nfounded, was an unblemished success story. From its inception in the 1880s as a supplier of dry photographic plates and then roll\nfilm, it came to dominate the amateur photography business both in the United States and around the world. For almost a century,\nKodak had the wind at its back. Demand for home photography grew rapidly and steadily, and for much of this period, Kodak was\nalmost unchallenged as a supplier of \u201cthe Kodak moment.\u201d From 1958 to 1967, demand in Kodak's core market grew at 13 percent\nafter adjusting for inflation.\n\nBy the 1970s, however, the company faced an increasingly saturated market. Even its long tradition of innovation was no help\n\nin spurring increasing sales. Between 1967 and 1972, inflation-adjusted growth in its core U.S. market fell to 5.6 percent a year;\n\f"}, "003182.png": {"text": "between 1972 and 1977, it declined again to 3.5 percent annually. Kodak\u2019s management responded by considering expansion\nopportunities in what it considered adjacent markets. It settled on two: photocopiers and instant photography. Each of these mar-\nkets was dominated by a well-entrenched incumbent\u2014xXerox in copiers and Polaroid in instant photography. In neither case did\nKodak develop a coherent strategy for dealing with the competitive advantages enjoyed by these firms. Both investments turned\nout badly, especially the decision to challenge Polaroid. The Kodak versus Polaroid contest is a cautionary \u201chow-not-to\u201d story about\n\nmarket entry.\n\nLAND\u2019S END: THE POLAROID MISSION\n\nMany firms have mission statements; Polaroid had a mission. Edwin Land founded the company in the 1930s to produce polar-\nizing filters, but he seemed to have found his calling and the company\u2019s quasi-religious purpose with the development of instant\nphotography. In a 1981 interview, Land said: \u201cour essential concept is that the role of industry is to sense a deep human need, then\nbring science and technology to bear filling the need.\u201d Land wanted to satisfy the need for \u201cconnection.\u201d He proposed to help fill it\nwith effortless and immediate photography. The level of Land\u2019s commitment was clear and total from the beginning. After intro-\nducing instant photography in 1947, Polaroid concentrated almost exclusively on this business. All of its eggs were in the instant\nphotography basket.\n\nPolaroid\u2019s first model, the Polaroid Land Camera, weighed five pounds, cost ninety dollars, and produced a sepia print of modest\nresolution in sixty seconds. The camera gave Polaroid a toehold in the amateur photography business and a monopoly on instant\ncameras and film. The original product sold largely because of its novelty. For the company to grow, it needed to offer more than\ngrainy sepia prints. It spent heavily on research and development and produced a steady stream of innovations. In the years after\n1947, Polaroid improved both cameras and film. It made the film speed faster, replaced sepia with black-and-white and then\n\ncolor prints, improved picture resolution, and changed the packaging and handling to enhance ease of use. The film development\n\f"}, "003183.png": {"text": "process that originally took one minute was reduced to ten seconds for black-and-white. Polaroid eliminated the waste negative\nmaterial, which was messy to dispose of, and also the necessity of coating each print by hand to stabilize the image. Its cameras\nalso improved, becoming more automatic and easier to use. A sonar device even focused the lens. By 1975, Polaroid instant pho-\ntography systems were technological marvels.\n\nLand\u2019s single-minded devotion to instant photography paid off handsomely (figure 13.1) Polaroid\u2019s sales grew from $6 million\nin 1950 to $98 million in 1960 and $420 million a decade later. By 1975, sales exceeded $800 million. Operating profits through\nthe late 1960s grew even more rapidly. Subsequently, a steep run-up in research and development expenses through 1974 led toa\n\nreduced operating profit, but there was a sharp recovery in 1975.\n\n \n\n \n\n5900 siao\n$800\n$120\n$700\n$100\n$600\n8\n$500 sso \u00a7\ni :\nF ss00 3\naa soo\n\u00e9\n$300\nsao\n$200\n$20\n$100\n$0 $0\n1980 19ss 1960 1965 1970 1975\nSales Operating Income\n\f"}, "003184.png": {"text": "FIGURE 13.1\n\nPolaroid\u2019s sales and operating income, 1950-75 ($ million)\n\nThe rapid, steady growth rate, combined with consistent profits, made Polaroid a Wall Street favorite. Throughout the period,\nthe shares traded at hefty multiples of book value and earnings. Polaroid was a charter member of the \u201cNifty Fifty,\u201d an elite group\nof firms in the late 1960s that had become the darlings of professional money managers. These companies were considered im-\nmune to the vicissitudes of a dynamic and competitive economy. Unfortunately, Polaroid\u2019s stock price, like those of the other Nifty\nFifty, declined sharply in the bear market of 1973-74. However, well-timed sales of equity, including an issue of $100 million in\n1969, had solidified Polaroid\u2019s financial position. At the end of 1975, Polaroid had $180 million in cash on hand, and only $12 mil-\nlion in debt.\n\nThe key to Polaroid\u2019s economic position was the technology produced by the combination of Land\u2019s genius, substantial spend-\ning on research and development, and its position as the only supplier of instant photography. R&D expenses averaged more than\n7 percent of sales from 1962 to 1971 and then increased sharply. Between 1962 and 1975, Polaroid spent over $600 million on\nR&D. This investment and the successive generation of products that Polaroid had produced were heavily protected by patents\non both cameras and film. As Land later said, \u201cThe only thing that keeps us alive is our brilliance. The only thing protecting our\nbrilliance is our patents.\u201d The patents helped the company retain its unique status in instant photography, as did the unpatented\nprocess and manufacturing know-how that Polaroid had developed over the years.\n\nIn its early days, Polaroid contracted out camera manufacturing and purchased the negative material for its films from Kodak.\nHowever, as it improved the features of its products, the technology became more complex. By 1969, Polaroid had decided largely\nto end the contracting out of even the nonsensitive parts of its production processes. It wanted to maintain almost complete con-\n\ntrol for reasons of quality and secrecy.\n\f"}, "003185.png": {"text": "Polaroid\u2019s marketing prowess was more questionable. New product introductions tended to follow a pattern established with\nthe first Polaroid Land Camera. The original system was expensive and relatively inconvenient. It sold slowly until the company\nimproved product quality, lowered prices for the cameras, and gained market acceptance, first in a steady stream, later in a rush.\nBut just at that point, Polaroid introduced a revolutionary new system whose film format was incompatible with existing cameras,\nand the process began all over again. The idea of blowing out camera sales by aggressive pricing and then making money on film\npurchased by the new captive customers never became part of Polaroid\u2019s strategy.\n\nBy the late 1960s, when Polaroid had finally achieved widespread acceptance of its first-generation cameras, the company\nbegan work on an entirely new film and camera system. In 1963, it had introduced color film as the final refinement of its original\nsystem, thereby reversing a decline in sales. But six months later it came out with an entirely new film and camera format for both\ncolor and black-and-white. The new system used film packs, more convenient than the existing rolls but requiring a new camera.\nThis camera, the Colorpack, was priced at $100. True to the Polaroid tradition, sales initially fell short of the company\u2019s expecta-\ntions. Within the year it introduced a less expensive version. By 1969, when the new system had been widely accepted, a Colorpack\ncamera was selling at retail for $29.95.\n\nBy then, Polaroid was already contemplating its next-generation system, the SX-70, which Land considered a major step\ntoward his goal of the ultimate in one-step photography. The SX-70 worked off a film pack that included a battery. The camera fo-\ncused automatically, had a built-in flash, and offered much-improved resolution and better color. With the press of a single button,\nthe photographer took the picture and began the film processing, which ended when a motor driven by the battery in the film pack\ndelivered the developed photograph.\n\nLike most Polaroid innovations, the SX-70 got off to a shaky start when it was introduced in 1972. The first camera model\nretailed for $180, six times the price of Polaroid\u2019s existing Colorpack camera. There were quality problems with the cameras and\nwith the film packs, especially with the batteries. Sales trailed projections badly. It took three or four years, and the introduction of\nnew and much less expensive SX-70 cameras, before the volume started to build. By 1976, there were only an estimated 2 million\n\nSX-70 cameras in use around the world, compared with 25 million of the simpler Colorpacks.\n\f"}, "003186.png": {"text": "Polaroid\u2019s treatment of the firms that sold its cameras did little to endear it to its immediate customers. The company did not\ngenerally concern itself with the welfare of the wholesale and retail intermediaries who moved its products to the consumer. From\nthe start it distributed the cameras and film as widely as it could, through camera shops, department and discount stores, mass\nmerchants, drugstores, and whatever other outlets were available. It did not try to control the price of its cameras at the retail\nlevel, nor did it protect the distributors when it introduced a new model, leaving them to dispose of the old inventory. As a result,\nPolaroid\u2019s channel relationships were weak and often contentious. In Edwin Land\u2019s view, it was the consumer that mattered, and\nhere Polaroid\u2019s efforts were more successful. The company advertised heavily and its name had become synonymous with instant\n\nphotography.\n\nPOLAROID\u2019S ADVANTAGES\n\nIn 1975, a conventional assessment of Polaroid\u2019s competitive advantages in the instant photography market would have had to\nconclude that they were substantial. Polaroid monopolized the instant photography business until 1976; it sold all the cameras\nand all the film. Consumers wanting film developed on the spot had no choice but Polaroid products. In terms of market domi-\nnance and share stability, it owned the entire market and there was perfect share stability from 1947 to 1975. Polaroid also earned\nextraordinary returns on investment (figure 13.2). Between 1960 and 1975, its pretax return on invested capital averaged around\n42 percent, unambiguously above Polaroid\u2019s cost of capital. But after peaking at 75 percent in 1966, the return began to fall. The\naverage for 1970 through 1975 was only 20 percent.\n\nThis decline was not attributable to competition, since there was none. Rather it stemmed from Edwin Land\u2019s particular\npriorities and the introduction of the SX-70 generation of products. The increased research and development expense and the\ninvestment in plant and equipment associated with the development of SX-70 pushed down current returns, and as of 1975, the\nexpected financial benefits had not yet materialized. The fact that Polaroid\u2019s returns in the 1970s were not as high as in the past re-\n\nflected Land\u2019s relative lack of interest in financial performance, not any current weakness in Polaroid\u2019s competitive advantages.\n\f"}, "003187.png": {"text": "These advantages had several sources. Polaroid benefited from customer captivity, proprietary technology, and economies of\nscale, but not in equal measure. The company did have captive customers, in the sense that once consumers owned Polaroid cam-\neras, they had to buy Polaroid film if they wanted to take pictures. But this captivity was not especially powerful or enduring. The\ncost of a new camera was not an insurmountable barrier to an existing Polaroid user, provided the new model, including the film,\nwas demonstrably better. Polaroid itself expected its existing users to upgrade when it introduced the Colorpack in 1963 and the\nSX-70 in 1972. The cameras were simple to operate. That was a key to their appeal, so experienced users would not have to aban-\n\ndon some hard-to-acquire mastery by switching.\n3%\n70%\naR\n\n50%\n\n \n\n40%\n\n30%\n\n20%\n\n10%\n\n \n\n \n\n1960 1965 1970 1975\n\n\u2014\u2014 ROIC Pretax\n\f"}, "003188.png": {"text": "FIGURE 13.2\n\nPolaroid\u2019s pretax return on invested capital, 1960-75\n\nPolaroid was better protected by the second competitive advantage, propriety technology for both its products and its pro-\ncesses. When the original patent for its camera design expired in 1966, it applied for additional ones to protect its advances. Also,\nit had accumulated a world of experience in engineering and manufacturing both cameras and instant film. Each time it came\nout with a new system, Polaroid itself had to spend several years fine-tuning production and eliminating problems. The SX-70\nsystem was even more challenging than its predecessors. Given the complexity of both camera and film, it would take a great deal\nof money, talent, and patience for a new entrant to begin to match Polaroid\u2019s production technology, all the while being careful not\nto infringe on Polaroid\u2019s patents.\n\nThe third advantage, economies of scale, also protected Polaroid. Making instant cameras and instant film requires major\nspending for plant and equipment. The R&D investment is considerable. Polaroid laid out more than $600 million in the fourteen\nyears between 1962 and 1975, including over $200 million in just two years to get the SX-70 system ready. Additionally, it\nsupported a substantial advertising program. In 1975, it spent $52 million on advertising, more than 6 percent of its net sales. A\nnew entrant, especially one with the aggressive goal of reaching half of Polaroid\u2019s sales in a year or two, would be spending more\nthan 12 percent of its sales to match Polaroid dollar for dollar. This is hardly a formula for profitability. So economies of scale, com-\nbined with Polaroid\u2019s modest level of customer loyalty, were another substantial barrier for any new entrant to overcome. Taken\ntogether, all three competitive advantages, reinforced by fanatical dedication to instant photography, presented a daunting chal-\n\nlenge to any potential entrant. A potential competitor might have been well advised to stay way.\n\nOVER THE TOP: KODAK DECIDES TO HURDLE THE BARRIERS\n\f"}, "003189.png": {"text": "Though Polaroid owned the instant photography market, it did face competition within the broader reaches of amateur photog-\nraphy. A customer could always opt for traditional film photography, where choices were abundant. Kodak was far and away the\nleading film producer and, at the lower end of the market, the leading camera manufacturer as well. Since George Eastman first\nproduced his roll film and Kodak cameras in the 1880s, the company had been synonymous with ease-of-use photography for\neveryone. Its yellow box was among the most readily identified brand symbols anywhere photographs were taken. It dominated\nthe photography business, not only for personal use, but also for professionals and the scientific/medical community. Until 1954,\nwhen the Justice Department forced it to separate the sale of film from the processing of that film, the company had controlled\nvirtually the entire photographic value chain. Even when independent film processors did emerge, they bought much of the paper,\nchemicals, and equipment from Kodak. In 1976, twenty years after the consent decree, it still owned half the processing market\nwhen the value of the supplies is included.\n\nKodak was a formidable competitor, and like Polaroid, it thrived on innovation. With the largest share of the film market, it\ncould outspend its rivals on the research and development necessary to upgrade the quality of its films, which it did relentlessly.\nLike Polaroid, the company had made its fortune by making picture taking simple. Its first Instamatic camera was brought to mar-\nket in 1963. Within a little more than two years, Kodak had sold 10 million of them. It repeated the success ten years later when\nit came out with a smaller version, the Pocket Instamatic. Both cameras used film packed in cartridges designed to slip easily into\nplace in the cameras. For the Pocket Instamatic, Kodak shrank the size of the film and its magazine so that everything could actu-\nally fit into a pocket. The company made exposure setting automatic, and it improved the flash mechanism, first into bulb cubes\nthat could fire four times, then into permanent flash mechanisms within the camera. George Eastman would have been proud.\nEverything was simple, and the cameras were big sellers. The smaller film brought Kodak an even larger share of the market, and\ncompetitive processors had to buy new equipment just to keep up.\n\nLike Polaroid, Kodak was hugely profitable. From 1950 to 1975, its pretax operating margins of 25 percent were greater than\nPolaroid\u2019s at 19 percent. In 1975, it had a pretax return on invested capital of 33 percent, well above both Polaroid\u2019s 20 percent\n\nand also above any reasonable estimate of its cost of capital. Sales and profits were both growing rapidly (figure 13.3). From 1950\n\f"}, "003190.png": {"text": "through 1975, sales had increased from about $500 million to nearly $5 billion, or about 10 percent growth per year.: Its operating\nincome in 1975 was nearly $1.1 billion, ten times larger than Polaroid\u2019s. Like Polaroid, Kodak was a charter member of the Nifty\nFifty and was extremely well financed. At the end of 1975, it had $747 million in cash and cash equivalents, versus $126 million in\ndebt.\n\nNevertheless, by the mid 1970s, there were unaccustomed pressures on Kodak\u2019s management. Annual sales growth of 10\npercent was good when inflation was at 1 to 2 percent. It was less satisfactory when inflation ran to 6 percent or more. Kodak was\nalso losing market share in some of the segments, like color print paper, that it had always dominated. As a result, the instant pho-\n\ntography market, which was growing at least as fast as Kodak\u2019s core business, seemed an attractive target.\n\n \n\n \n\n$6,000 $1,400\n$5,000 $1,200\n$1,000\nsso \u00a7\n& 33,000 =\nsoo 2\n&\ns4co\nnam $200\nso 0\n\n \n\n \n\n19ss 1960 1965 1970 1975\n\nee Sales \u2014\u2014 Operating Income\n\f"}, "003191.png": {"text": "FIGURE 13.3\n\nKodak's sales and operating income, 1950-75 ($ million)\n\nIt was well known in the industry that Kodak was interested in moving onto Polaroid\u2019s turf. There was speculation in 1969 that\nPolaroid would allow Kodak to sell a compatible color film of Kodak\u2019s manufacture, but nothing came of that supposed agreement.\nSo Kodak went its own way, developing a system to compete directly with Polaroid. It made no secret of the project, describing its\nplans in its 1973 and 1974 annual reports. The film would be litter-free, and Kodak would offer a range of cameras at widely vary-\n\ning prices. Since the term instant was already taken by the Instamatic, Kodak referred to this project as \u201crapid-access photography.\u201d\n\nELEPHANT AND TIGER\n\nHow did Kodak expect its entry strategy into the instant photography market to play out? When Walter Fallon, the Kodak execu-\ntive responsible for this decision and later Kodak\u2019s CEO, looked at Polaroid, he could not have been oblivious to Polaroid\u2019s competi-\ntive advantages. Its name was synonymous with instant photography. It had decades of experience with instant cameras and film.\nIt had economies of scale and a large base of customers already owning Polaroid cameras. And last although hardly least, it had an\narray of patents covering the new SX-70 technology. Admittedly, Polaroid also had weaknesses. It had poor relationships with the\ncustomers in its distribution channel, and by the end of 1975, it had not worked all the kinks out of the SX-70 system. However, on\nbalance Fallon had to anticipate an uphill struggle.\n\nIf Polaroid were to respond aggressively to Kodal\u2019s entry, then it could be expected to match or exceed any Kodak initiative.\nShould Kodak try to lure customers with lower prices, Polaroid was likely to counter with even lower prices. Given its economies\nof scale advantage and its greater experience with technology, Polaroid\u2019s costs were likely to be significantly lower than Kodak's. If\n\nKodak tried to offer a superior product than Polaroid, it would have to circumvent Polaroid\u2019s patents on its new features. If Kodak\n\f"}, "003192.png": {"text": "attempted high product quality, it would somehow have to develop an edge despite Polaroid\u2019s greater experience with the tech-\nnology and the processes. If Kodak tried to beat Polaroid by spending more on advertising, Polaroid would undoubtedly respond\nby upping its own spending. With a greater customer base, the resulting increase in cost per customer would be greater for Kodak\nthan for Polaroid.\n\nIt was possible, at least in theory, that Edwin Land would recognize the potential damage that aggressive competition would\ninflict on Polaroid. Because Polaroid would sell more cameras and much more film, given its large installed base, price cuts of any\nduration would hurt it more than Kodak. On the other hand, competition involving advertising or product development that\nincurred additional fixed costs would be more expensive for Kodak, relative to its output, than for Polaroid. Neither competitor\nwas likely to exhaust its financial resources any time soon. The argument for restraint by Polaroid did not come down to relative\nstrength. Given its competitive advantages, Polaroid was in the more powerful position. Rather it depended on Land embracing a\ncooperative posture in light of the joint financial damage that aggressive competition would impose on both firms.\n\nNothing in the history of Polaroid or Edwin Land suggested that he might pursue this course. Given his psychological and eco-\nnomic commitment to the instant photography market, he was not likely to let anyone, even an elephant of the stature of Eastman\nKodak, deflect him and his company from their sacred mission. As much to the point, Polaroid had no place else to go. Kodak was\ninvolved in a number of businesses beyond photography, notably chemicals. Polaroid was a pure instant photography company.\nWith all his eggs in this basket, Land was not going to surrender even a part of that domain without a struggle. Finally, Land had\nnever been dedicated to bottom-line financials. The size and persistence of his investment in the SX-70 system, even before Kodak\nhad definitively entered the instant photography market, indicated how far he was prepared to go to meet his goals of satisfying\n\u201cthe need for connection.\u201d Anyone looking at Polaroid should have realized that it was going to treat any new entrant as a hostile\nforce to be contested at every turn.\n\nKodak, it appears, never seems to have considered a strategy of restrained entry along the lines of Fox and Kiwi. Instead of a\nmuted approach that had at least the possibility of not provoking Polaroid, it came in with trumpets blaring. It started to hint at\n\nits entrance in its 1973 annual report. It devoted more space in 1974 and 1975. The close involvement of a senior corporate officer\n\f"}, "003193.png": {"text": "like Fallon reinforced the message that Kodak was not planning to settle for some minor niches within the instant photography\nmarket. From Land\u2019s perspective, Kodak \u201cjust walked deliberately into our field with a callous pretension that we didn\u2019t exist.\u201d For\n\nan entrant like Kodak challenging an incumbent who had a decidedly strong hand, this was not a constructive approach.\n\nNO INSTANT SUCCESS\n\nThese considerations notwithstanding, Kodak told the world in February 1976 that its instant cameras and film would go on sale\non May 1 in Canada and two months later in the United States. Kodak met these deadlines. It accompanied the rollout of cameras\nand film with a large consumer advertising campaign and a program to educate an army of retail sales personnel with the infor-\nmation they needed to help customers. It offered two models of cameras, the EK 4 and EK 6, to compete at different price points,\nand a color film that rivaled Polaroid\u2019s in quality and stability. Kodak's prices were in line with Polaroid\u2019s.\n\nIf Fallon had thought that Polaroid would surrender a significant part of its business without a fight, he was mistaken. If he\nthought that Kodak would be able to offer a product superior to Polaroid\u2019s, he was mistaken in that as well. When Edwin Land first\ngot his hands on the Kodak cameras, he claimed to be \u201ceuphoric.\u201d Unlike Polaroid\u2019s SX-70 model, which folded up for convenient\ncarrying, the EK 4 and EK 6 were bulky rigid boxes. Admittedly, Polaroid\u2019s lower-priced models were also nonfolding. But Kodak\nhad to win over Polaroid customers, a goal requiring product superiority. Polaroid had only to hold its own, which it could achieve\nwith product parity. Independent observers confirmed Land\u2019s initial reaction, that Kodak\u2019s cameras and film were no better than\nPolaroid\u2019s.\n\nKodak also experienced production difficulties that it should have anticipated, but did not. It could not produce film as fast as\nit had planned. Unable to provide the film, the company had to halt camera shipments until it could catch up. Separate difficulties\nin camera production delayed the introduction of some planned models. The lack of product coupled with Kodak's heavy advertis-\n\ning and promotion campaign worked to Polaroid\u2019s advantage. Retailers reported that customers, drawn into the stores by Kodak\u2019s\n\f"}, "003194.png": {"text": "efforts but frustrated by empty shelves, turned to Polaroid. People interested in instant photography were not inclined to wait to\nbuy these cameras.\n\nNor was Polaroid standing still in the face of Kodak's long-awaited entry. In August 1975, the company had introduced two new\nSX-70 camera models, one at the high end of the line, one in the middle. In part to support these introductions, it boosted an al-\nready substantial advertising budget by $16 million for the Christmas 1975 season. Polaroid had also moved decisively to improve\nrelationships with its distributors. Prior to Kodak\u2019s entry, its salespeople were seen by retailers as mere order takers, waiting pas-\nsively for calls from customers who had no alternative choices. After Kodak arrived, the salespeople changed their approach. They\nbegan calling on stores more frequently, providing faster delivery, improved service, and higher levels of cooperative advertising.\n\nAt the same time, Polaroid tried to quash the Kodak threat in the courts. It brought suit in the United States, Canada, and the\nUnited Kingdom, claiming that Kodak had violated a number of its patents on cameras. It asked for injunctive relief to take Kodak\nout of the instant business in a hurry. An early ruling in its favor in the UK was overturned at the appeals level. The cases contin-\nued on. Though Polaroid no longer had the prospect of a quick victory that would eliminate Kodak from the field, Kodak was forced\nto defend itself on another front, and it labored with the possibility that Polaroid might ultimately win a large monetary judgment\nand an order forcing Kodak to abandon instant photography.\n\nKodak's initial sales results appear to have been disappointing, despite management\u2019s claim that the dealer orders exceeded\nprojections. By the end of 1976, Kodak announced shipments of 1.1 million instant cameras. Unfortunately, many of these cam-\neras remained on dealer shelves. In its 1976 annual report, Kodak could only state that \u201cthe majority were in the hands of picture-\ntakers at year end.\u201d As a result, Kodak was forced to continue its aggressive holiday season advertising campaign into January and\nFebruary, normally a quiet period for sales. By the end of its first year in the instant photography business, Kodak appears to have\nsold between 600,000 and 700,000 cameras to consumers. During the same period, Polaroid had camera sales of 4 million. Never-\ntheless, Fallon seemed to believe that he could iron out the production problems and step up to meet what its market research indi-\n\ncated was a powerful demand.\n\f"}, "003195.png": {"text": "In the next few years, Kodak did gain on Polaroid. In 1978 it sold 5.5 million cameras, up from the 1.1 million in 1976. By\nthen it had around 35 percent of the market, up from 15 percent. But the venture had not been profitable for Kodak. Each time it\nintroduced a new camera model, Polaroid followed suit, especially at the low end. When Kodak offered rebates or reduced prices,\nPolaroid matched them, after overcoming an initial reluctance. Kodak did succeed in turning the cameras, both its own and Po-\nlaroid\u2019s, into an equivalent of Gillette's razor, sold at or below cost to spur the sale of blades, or in this case film. The price cutting,\nimproved quality, and the attention brought to instant photography by both companies\u2019 stepped-up advertising campaigns ex-\npanded the overall market for instants. In 1975, they represented 25 percent of all still cameras sold to amateurs; in 1978, the\nshare had increased to 45 percent. For Kodak, however, that growth was a mixed blessing. It was, after all, the dominant seller of\nregular cameras and film.\n\nUnfortunately, 1978 proved to be a high-water mark both for instant cameras and for Kodak. A wave of high-quality, relatively\ninexpensive, and easy-to-use cameras based on the 35mm film format began to arrive from Japan. Even with processing costs in-\ncluded, 35mm film was cheaper than instant. When stores and kiosks offering one-hour processing began to open, the advantage\nof instant film was further eroded. By 1980, it seemed clear that the great growth spurt in instant photography was over. After\nselling more than 5 million instant cameras in 1978 and capturing close to 40 percent of the market, Kodak's fortunes declined.\nBy 1981, its market share was down to around a third, and that translated into 3 million cameras. Things never got any better.\nAlthough Kodak's financial statements never broke out the figures for instant photography, industry analysts believed that in the\ncompany\u2019s best years in the business, it may have broken even. Between 1976 and 1983, estimates put its operating losses at more\nthan $300 million after taxes, and this figure did not include all the money it had invested in development.\n\nThe final blows were struck in the courts. After some years of wrangling, Polaroid\u2019s patent infringement suit reached the\nfederal bench in October 1981. It took four more years for a decision. In September 1985, Judge Rya Zobel found that Kodak had\nindeed infringed on seven Polaroid patents, most related to the SX-70 camera. In October, she gave Kodak until January 9, 1986,\nto stop making and selling both instant cameras and film. Though Kodak appealed all the way to the Supreme Court, it had no\n\nsuccess in getting the ruling overturned. In January 1986, it announced that it was leaving the business and would lay off eight\n\f"}, "003196.png": {"text": "hundred full-time and many more part-time workers. Though Kodak had claimed in court that it would be seriously damaged if\nforced out of the instant business, it is hard to see how, since that project had never earned any money for Kodak, and had been a\nmajor sinkhole of management attention.\n\nWhen the wheels of justice ground to a final decision, in 1990, Kodak had to pay Polaroid almost $900 million in damages. The\naward was the largest in the history of patent infringement suits, although it was much less than the $5.7 billion Polaroid felt it\ndeserved for all the trouble Kodak had caused it. The award was also less than the $2.5 billion analysts had estimated. Still, it gave\nPolaroid its best payday ever, and it added $675 million in after-tax income in 1991. For Kodak, it was the last affront in what had\nbeen a disastrous mistake.\n\nPatent protection proved to be the one competitive advantage that pushed Kodak out of the instant photography business. That\nthe push came nine years after Kodak originally entered the industry only testifies to the company\u2019s wealth, technical talent, and\ndetermination, not to the quality of its strategic planning. The inescapable facts are that Kodak had only lost money in instant\nphotography, it had never taken leadership from Polaroid, and it was surrendering market share even as the market itself was\nshrinking. From the perspective of October 1985, when Judge Zobel ordered Kodak to get out of town, it was already obvious that\nKodak had made a big mistake.\n\nBut it ought to have been sufficiently clear in 1972 or thereabouts that Kodak would have a difficult time making a profit\nin instant photography. Polaroid enjoyed all the competitive advantages\u2014the customers, the proprietary technology, and the\neconomies of scale. It was clearly determined to fight to the death. Kodak was large and powerful enough to make an inroad, at\ngreat cost to itself and to Polaroid. But it was soon obvious that anything it did\u2014promotions, lower prices, new models, technical\nadvances, expensive advertising\u2014Polaroid would match and generally exceed. The net result of Kodak\u2019s entry was to turn an in-\ndustry that had been decently profitable for a single company into one that was a money loser for one competitor and less reward-\n\ning for the other.\n\f"}, "003197.png": {"text": "AFTERMATH\n\nInstant photography was not Kodak\u2019s only unfortunate initiative in the 1970s. At the same time it was going head-to-head with\nPolaroid, it took on Xerox in the copier market. Management\u2019s rationale was that it had both the technology to make copiers anda\nsales force already in place to market them. Its existing microfilm equipment business was starting to decline and Kodak thought\nit had the infrastructure in place to sell and service copiers. It began with high-end models. The cheapest Ektaprint sold for\n$45,000, but it planned to offer less expensive, \u201cconvenience\u201d copiers once it had its foot in the door. Because the machines would\nneed servicing, the rollout was confined at first to fifty major cities. \u201cThe day we deliver,\u201d the Kodak marketing head said, \u201cwe have\ntwo servicemen already in place.\u201d\n\nKodak's experience in the copier business paralleled its history in instant photography, except for the cease-and-desist injunc-\ntion and the $873 million penalty. By the time it chose to enter, another company was already established as the dominant firm.\nKodak invested heavily, in time, money, and talent, to build an acceptable product and gain entry. Its Ektaprint copiers were better\nthan the comparable Xerox models when they were introduced in 1975. But Xerox caught up and surpassed Kodak, which had\nspent nine years developing the original Ektaprint and another seven before it came out with an improved machine. As in instant\nphotography, Kodak had an early burst of success, captured a respectable piece of the market, and then started to lose ground as\nthe incumbent responded. Kodak hung around longer in the copier business, turning to Canon to manufacture lower-volume ma-\nchines and using software to incorporate its copiers into desktop publishing and prepress systems. Still, whatever it tried, Kodak\nalways seemed to be playing catch-up. Xerox introduced a high-volume digital machine in 1990. Kodak only began working on one\nin 1994. Having sold its copier sales and servicing business to Danka in 1996, it continued as a manufacturer for three more years\nbefore finally selling that operation to the German company Heidelberger Druckmaschinen, the premier manufacturer of printing\npresses.\n\nWhile management attention and resources were being consumed by these unproductive ventures, Kodak failed to protect its\n\ncore business, giving up ground to Fuji and other entrants. In the 1970s, it let Fuji gain entrance into the paper business with a\n\f"}, "003198.png": {"text": "lower price strategy, and was slow in responding with its own price cuts. Fuji also made inroads into Kodak\u2019s basic film business.\nKodak's return on capital declined from roughly 40 percent in the 1970s to under 10 percent in the early 1990s (figure 13.4). It\nrecovered somewhat later in the decade, but its returns remained below 20 percent. In the wake of its adventures in instant pho-\n\ntography and copiers, Kodak ceased to be one of the leading American corporations.\n\n50%\n\n40%\n\n20%\n\n10%\n\n1970 1975 1980 1985 1990\n\nwees Pastman Kodak\n\n \n\nlaroid\n\nFIGURE 13.4\n\nEastman Kodak and Polaroid pretax return on invested capital, 1970-94\n\f"}, "003199.png": {"text": "Polaroid fared even worse. Profitability shrank dramatically with Kodak\u2019s entry into instant photography, recovered somewhat\nwhen Kodak left the business, and then collapsed with the advent of digital photography. Ultimately, its decline ended in bank-\nruptcy.\n\nTwo might-have-beens are raised by this extended tale of woe. First, could Polaroid have done more to discourage Kodak from\nentering the instant photography business? The answer is almost certainly no.\n\nThere were more than enough obvious clues in place about how Polaroid would react to Kodak\u2019s entry, and sufficient evidence\nabout what competition between them was likely to do to Kodak\u2019s profitability. Any reasonable reading of the situation should\nhave convinced Kodak not to enter the business. Under these circumstances, it is not clear that there was anything else Polaroid\ncould have done to deter Kodak.\n\nSecond, could Kodak have pursued a more Kiwilike or Foxlike strategy and entered the instant photography business success-\nfully, if on a smaller scale? Again, the answer seems to be no. Unlike the airline and network television businesses, the instant\nphotography market was not easily divisible. The large, upfront development costs of Kodak\u2019s entry meant that pursuing the\nwhole market was probably the only viable strategy. On its part, given its attitude and its sense of its role in life, Polaroid would al-\nmost certainly have contested vigorously any Kodak initiative, however small. Elephants are still elephants even when they tread\nlightly. The only economically sensible decision for Kodak was to stay out of the market altogether.\n\nFinally, Kodak seems to have consistently misunderstood its own competitive advantages and those of the companies it\ndecided to challenge. It saw instant photography and photocopiers as adjacent markets into which Kodak could easily extend\nits expertise, its customer relations, and the value of its brand. In practice, the technology in both was different enough so that\nthe incumbents had no problem meeting and surpassing Kodak's offerings. The existing sales force was not much help in selling\ncopiers, and the service department proved a major cash drain. More to the point, each market had a powerful incumbent who was\nnot going to accept Kodak\u2019s entrance without a struggle. As a result, neither market was a natural or easy extension of its existing\n\nfranchise.\n\f"}, "003200.png": {"text": "Meanwhile, Kodak did not aggressively defend the markets that it did dominate\u2014photographic paper and film. It did not force-\nfully contest Fuji\u2019s arrival in the United States, and by the time it responded, Fuji had gained more than a foothold. Eastman Kodak\n\nwas a global company that did not realize how local, as measured in market space, its advantages really were.\n\f"}, "003201.png": {"text": "CHAPTER 14\n\nCooperation without Incarceration\n\nBigger Pies, Fairly Divided\n\nTHE VIEW FROM OLYMPUS\n\nIn formulating strategy, there is a natural progression of perspectives from unrestrained competition through a mix of competi-\ntion and cooperation to a more purely cooperative viewpoint. We have followed that progression in this book. We began with an\nanalysis of competitive advantages. Then we considered companies as economic agents concerned only with their own capabili-\nties, which they seek to exploit without regard to how others might react to whatever they do. We noted that there were two situa-\ntions in which this type of competition takes place.\n\nOne is in markets where the number of competitors is so large that managing mutual interactions is both impractical and of\nlimited value to anyone acting alone. These are markets in which there are no barriers to entry. The other situation is one with an\n\nelephant surrounded by ants\u2014Wal-Mart in its stronghold, Intel and Microsoft on the desktop. There are barriers to entry, and the\n\f"}, "003202.png": {"text": "companies that benefit from competitive advantages do very well, especially if they know how to exploit those advantages. But\ntheir success does not entail any measure of cooperation with their smaller rivals. What these two situations share is a model of\ncompetition among agents that is unmediated by any recognition of common interests.\n\nWhen there are several firms operating within the barriers, all equipped with competitive advantages, opportunities for the\nexploitation of mutual benefits becomes an important issue for strategy. Elements of competition are still present, certainly, but\nnow there is the possibility of doing better by taking the actions and reactions of others into account. We explored these situations\nthrough the lens of traditional game theory, examining effective methods of balancing competition with cooperation within the\ncompetitive situations most likely to occur\u2014the prisoner\u2019s dilemma and entry/preemption games. We turn now to another per-\nspective, looking at these inherently complicated situations purely as opportunities for cooperation.\n\nAdding a viewpoint that stresses cooperation to the existing analysis of direct interactions among agents enables us to\nhighlight things that otherwise might remain unnoticed. First, there are some interactions that are inherently dominated by the\npossibilities of cooperation. The first priority of software and hardware firms in the data-processing industry is to produce the best\nsystems possible, to which they all contribute. The competition of dividing up the rewards from building those systems is a gen-\nuine but nevertheless secondary concern. Suppliers and distributors, whether of physical goods or media creations, face similar\nimperatives. Even producers and end-use customers, who have generally been regarded as on opposite sides of the market, almost\nalways have mutual interests in seeing that users get the most benefit from the product involved. In these cases, the cooperative\nperspective is essential to formulating effective strategies.\n\nSecond, in other competitive situations, face-to-face bargaining is a common form of interaction, one that need not run afoul\nof antitrust laws. Relationships between unions and employers are the most obvious example. In fact, almost all interactions\nbetween large organizations that are part of the value chain, from raw material to a product in the hands or mind of the ultimate\ncustomer, involve a significant degree of face-to-face bargaining. As contemporary theories of negotiation have recognized, these\n\nexchanges are more successfully approached from a cooperative, rather than an adversarial, perspective.\n\f"}, "003203.png": {"text": "Finally, even in situations that are predominantly competitive, a cooperative perspective will often yield useful strategic\ninsights. For example, it is possible, at least in theory, to develop a model of what an industry would look like if run cooperatively\nwith maximum efficiency as the yardstick. In this model, all the agents would behave rationally, and together their actions would\nproduce the optimal industry outcome. Taking its cue from this analysis, a high-cost producer, finding itself frozen out entirely\nunder this fully cooperative arrangement, must look for and exploit any less than rational behavior on the part of its more efficient\ncompetitors. Using this analysis, other firms might decide to swap business units with one another, to take advantage of their\nstrengths and reduce their direct competitive exposure. Though this Olympian vantage point is admittedly utopian\u2014how the\nworld would work if everyone were reasonable, farsighted, and fair\u2014it still has practical applications. For all these reasons, the co-\noperative viewpoint belongs in the portfolio of strategic perspectives.\n\nIn the organization of this book, the cooperative perspective rests on the branch where competitive advantages do exist and are\nshared by more than one competitor (location 3 in figure 14.1). It is acomplement to the analysis utilizing classical game theory,\n\nparticularly the prisoner\u2019s dilemma game discussed in chapter 8 and the entry/preemption game covered in chapter 11.\n\nOUTCOMES FIRST\n\nAdopting a cooperative perspective requires that we modify the focus of the analysis in important ways. Until now, we have\nconcentrated on the capacities of firms (competitive advantage) and on their actions (competitive strategies). Outcomes\u2014the\ndistribution of rewards among the firms\u2014has been treated merely as an incidental consequence of these primary forces. The co-\noperative perspective turns this priority on its head. The focus is on outcomes: what overall level of rewards are possible (through\noptimizing an industry) and how they are to be allocated among participants (through the principles of \u201cfairness\u201d). Tactical or\n\nstrategic considerations and underlying capabilities now become secondary.\n\f"}, "003204.png": {"text": "Manage Competitive\nYES Advantage @)\n\nSingle Dominant Firm?\n\n  \n \n\nGame Structure!\n\nSimulation\nPrisoner's Dilemma\nEntry/Preemption\n\nCOMPETITIVE @) Cooperation\u2019\nADVANTAGE? Bargaining\n\nYES\n\nNO\n\n(Many Competitors)\nOperational Effectiveness:\nEfficiency, Efficiency, Efficiency\n\nFIGURE 14.1\n\nCooperation and bargaining within the book\n\nThis reversal of significance rests on the assumption that in a cooperative environment, once participants have jointly decided\non where they want to go, the mechanics of how to get there\u2014which agent does what action\u2014will be relatively straightforward.\n\nEach player will naturally \u201cdo the right thing\u201d necessary to achieve the outcome on which everyone has agreed. Cooperation, by its\n\f"}, "003205.png": {"text": "very nature, precludes wasteful conflicts in which differences in capabilities might affect outcomes directly. For this reason, the\ncapabilities of individual agents matter only to the extent that they determine the set of attainable joint rewards and the appropri-\nate division of those rewards.\n\nThere are two important constraints that limit this set of attainable joint rewards. First, some outcomes are simply not feasible,\ngiven the economic and technological realities of the situation. In the absence of a service station infrastructure able to supply\nhydrogen to automobiles on demand, the fuel cell is unlikely to be widely adopted as a transportation engine, no matter how co-\noperative the automakers, regulators, and fuel cell development companies can be. The set of attainable joint rewards refers only\nto those outcomes that are actually possible. Second, the set is also constrained by the reward level that each participant could\nachieve should cooperation break down. Cooperation is unlikely to be sustained by voluntary participants if any of them can do\nbetter by refusing to cooperate.\n\nIn the coming pages we address the two main features of a cooperative strategy analysis\u2014maximizing joint rewards and divid-\n\ning the gains fairly.\n\n+ Maximizing the attainable joint rewards. This is concentrating first on the size of the pie (fully exploiting joint\ngains) rather than on how it is divided (getting as big a piece as possible). In the language of bargaining, this\nmeans seeking at the start to identify win-win possibilities. Only after these have been exhausted is it time to at-\ntend to the trade-offs between bargainers. There is an upper boundary to the set of feasible outcomes, that is, the\nbest of all possible worlds currently attainable. This upper limit is defined as the line beyond which there are no\njoint actions that might expand the overall pie without requiring sacrifices from some of the participants. Things\nare as good as they are going to get, and they can\u2019t get better without somebody doing worse. Because the full\nexploitation of these joint gains is the essence of cooperation, we will lay out some of the most important steps\n\nfirms can take to make their industry as profitable as possible.\n\f"}, "003206.png": {"text": "+ Dividing the gains in rewards according to the principles of \u201cfairness.\u201d A stable outcome depends on fairness. If\ncooperation is to be sustained among a group of economic agents over any extended time, then all the partic-\nipants have to feel that they are being treated fairly in the division of the rewards. Dissatisfaction, especially\nwhen buttressed by a justifiable claim of unfairness, will inevitably lead to a breakdown in cooperation. In fact,\nindividual firms will never enter into a cooperative arrangement in the first place if they feel that the rewards\nthey will garner within the arrangement are not commensurate with the value they contribute. We will examine\ncarefully what constitute \u201cfair\u201d divisions of the pie in different cooperative situations. Companies that have a\nsound concept of fairness conditions should enter cooperative arrangements with a realistic sense of what they\ncan expect to gain, not so low as to allow themselves to be exploited nor so unreasonable as to be disappointed.\n\nwhen their unwarranted aspirations are unfulfilled.\n\nOPTIMIZING AN INDUSTRY TO MAXIMIZE OVERALL REWARDS\n\nIf our first goal is to make our industry as profitable as possible\u2014to achieve the best possible joint outcomes\u2014where do we start?\nWe could try to expand the market for the industry\u2019s products or services, to keep other industries from encroaching on our turf,\nto keep down the costs of the things we need to buy as inputs, to make sure that our customers do not collude to keep their bids for\nour offerings artificially low. These are the kinds of moves we would make if we were simply running a single firm, only now the\nscale would be larger and the tactics modified to account for the fact that we are members of a group.\n\nOne thing we would certainly do is to organize the industry for maximum efficiency, to avoid wasting any resources through\nunnecessary duplication of effort or poor design of the processes required. Again, a single firm also wants to operate as efficiently\nas possible, but its task is simpler because it does not have to coordinate so many separate operating centers. To achieve the highest\n\npossible level of industry-wide efficiency, it helps to think of the industry as governed by a single intelligence capable of directing\n\f"}, "003207.png": {"text": "the behavior of all the constituent firms. That thought experiment should produce a model equivalent to how the industry would\nrun if it were a coordinated monopoly.\n\nThe conventional view of a monopoly is that it is solely concerned with charging the highest appropriate price\u2014the price that\nproduces the greatest profit. But this is far too narrow a description of monopoly behavior. There are a number of dimensions to\ncooperation that are at least as important for industry performance as pricing. And pricing itself needs to be understood as part\nof a broader set of decisions that involve more than setting a single monopoly price for the industry. Effective cooperation has to\n\nmanage:\n\n+ Pricing levels across the many subsegments that make up an entire industry\n\n+ The level and the location of the industry\u2019s production capacity\n\n+ Allocation of production to the most efficient facilities\n\n+ Cost discipline in the acquisition of resources\n\n+ Coordination of distribution and service facilities to reduce overlapping resources and keep costs down.\n\n+ Organization of research and development to eliminate duplication, to disseminate innovations appropriately,\nand to provide incentives for continuing improvement in industry operations\n\n+ Product line management to eliminate redundancy and fully cover the relevant niche markets\n\n+ Coordination of advertising and promotion to enhance the effectiveness of industry-wide promotion while avoid-\ning the clutter of competing and mutually neutralizing messages\n\n+ Synchronization of information systems to reduce working capital requirements and ensure that information is\nreliably disseminated to the relevant operating units\n\n+ Rationalization of overhead expenditures to prevent inefficient duplication and to take advantage of economies\n\nof scale possibilities\n\f"}, "003208.png": {"text": "+ Joint risk management to reduce financing and other related costs, many related to the fluctuations in individual\n\nfirm demands that beset every industry\n\nThe list of potential areas of cooperation is both long and, in many instances, not troubled by a concern with antitrust violations.\nOn the other hand, it is undoubtedly optimistic to think that this high level of cooperation can be established and sustained in the\nmidst of a competitive market economy. To repeat, our purpose is to describe an extreme situation, portions of which are clearly\nattainable and are in actual practice.\n\nMuch can be accomplished if firms simply exercise competitive restraint in areas remote from antitrust laws. For example,\nfirms can improve their profit margins by operating in niches where there are few direct competitors. Everyone is made better off\nif, instead of going head-to-head in every niche, each firm picks a territory that it has pretty much to itself. Territory can be defined\nby geography, product type, service specialization, or the characteristics of target customers. So long as these segments are not too\nclosely related, the companies are unlikely to be tempted to compete with one another on price.: With each company reigning in\nits particular niche, the industry will have what is known as effective yield management\u2014in which customers who are willing to\npay more for an item will get the opportunity to do so, because their choice resides in a particular niche and they are not tempted\nto buy a lower-priced alternative in another niche, even if the two purchases look essentially equivalent to someone else.: From a\ncooperative perspective, price coordination is largely a matter of the effective positioning of firms across industry subsegments.\n\nManaging the capacity of an industry involves more than simply closing plants or other facilities if the market cannot absorb\nall the product being turned out. It also means ensuring that the facilities that are kept open are the most cost efficient in the\nbusiness. In an expanding industry, the strategy is to increase capacity of the most efficient firms and those that are most advanta-\ngeously located. In a declining industry, the goal is to first shut down the highest-cost and worst-situated producers. These choices\nseem natural enough, what the market might itself do over time in a competitive weeding out of unprofitable operations. In a co-\n\noperative environment, the results can be accomplished more quickly and with less pain. If functions like sales and production can\n\f"}, "003209.png": {"text": "be separated from one another, then firms with high production costs may be able to survive as marketing and sales organizations,\nbuying their product from the low-cost or best-situated producers. They have to specialize and excel at what they do, naturally, but\nthere is room for them in a cooperative universe.\n\nEfficient outsourcing, which is another way of describing this separation of functions, is a powerful means for reducing in-\ndustry-wide costs by channeling production to the lowest-cost firms. When this shifting can be accomplished painlessly, without\nincurring additional expenses, then there is little else that need be done to minimize costs in the industry. If shifting production is\nitself costly for one reason or another, then efficient firms may license their production technologies on appropriate terms to their\nless economical competitors. In either case, costs have been taken out of the supply chain across the entire industry.\n\nIf production can be concentrated among a few of the most efficient firms, then competition for resources will also be con-\nstrained. In any event, for essentially generic resources, such as generally skilled labor, widely used raw materials such as energy,\nand financing, no single industry is likely to have a significant impact on their prices. For specialized labor with particular talents,\ncompetition within the industry may drive prices upward. But with a small number of bidders, restrained by their cooperative\noutlook or skilled in deploying prisoner's dilemma strategies to control aggressive tendencies, it should not be difficult to manage\ncompetition for resources, at least in theory.\n\nIn coordinating distribution and service facilities for efficiency, niches are again the key. Firms that concentrate in specific\ngeographic or product spaces will operate more efficiently than firms that are spread thinly over large areas. Both the distribution\nand the service provision businesses tend to entail significant fixed costs whose level is determined by the geographic footprint of\nthe relevant market area. These functions share the cost structure characteristic of natural monopolies\u2014high fixed and low mar-\nginal costs with powerful economies of scale that keep a second supplier in a much inferior position.\n\nThe boundaries of the natural monopolies, in both physical and product space, extend as far as the economies of scale still\noperate, but no further. Once a distributor has exhausted all the territory it can serve with its existing infrastructure, for exam-\nple, it is on a level playing field when it moves further afield. The same situation holds for a service provider, like an information\n\ntechnology maintenance organization. When it needs an entire new set of specialists to service customers with different needs or\n\f"}, "003210.png": {"text": "equipment, it has come to the limits of its economies of scale. But within these boundaries, a cooperative configuration in which\ncertain firms dominate particular areas should be both efficient and stable, since these firms should enjoy competitive advantages\nover potential entrants, so long as they also benefit from some degree of customer captivity.\n\nResearch and development is easier to coordinate on paper than it is in practice. Theoretically, the underlying elements of\nefficiency are simple to define. Duplicative research activities are to be avoided, meaning that firms should not overlap one an-\nother in their research programs. Information should be widely shared, to foster benefits from the spillover value even of research\nthat is tightly focused. Unrestrictive cross-licensing arrangements can broaden the application of research results to the product\ndevelopment efforts of different firms with nonoverlapping specialties. And the levels of research and development expenditures\nshould be set to take into account both the direct benefits to the firms paying the bills and the indirect benefits to other firms in\nthe industry. In a cooperative arrangement, there are going to be external benefits, and they should be considered when funding\nlevels are set. Whether these expenditure levels would be higher or lower than those in a fully competitive industry is impossible\nto say a priori. The elimination of duplication argues for lower expenditures; wider dissemination of benefits pushes in the oppo-\nsite direction.\n\nCoordinating product lines and the advertising campaigns are the same kind of tasks in a cooperative industry as they are\nwithin an individual firm. There are trade-offs, and a balance has to be struck. On one side are the benefits of offering a full range\nof products and messages; on the other side are the inevitable losses through cannibalization from competing product lines and\npromotional campaigns. Each additional product or advertisement may take as much or more from existing business as its adds\nincrementally to total sales. Among firms in an industry, concentration in subsegments helps to avoid cannibalization, especially\nwhen closely related products or territories are in the hands of the same firm. For advertising and the deployment of a sales force,\nefforts to win business by running ads proclaiming that \u201cour product is better than their product,\u201d or by making direct sales calls\non acompetitor\u2019s customers, are practices to be avoided.\n\nCoordinating information systems, especially across firms within the same supply chain, is a growing reality that has not been\n\na subject of antitrust enforcement. Similarly, agreement among competitors on common information standards and formats, like\n\f"}, "003211.png": {"text": "MP3 in digital audio or IEEE 802.11x (WiFi) in wireless communications, is widespread and uncontroversial, at least to date, from\nan antitrust point of view. Everyone regards the Betamax versus VHS battle in videotape, and the costs that contest imposed on\nfirms on both sides and on customers who made the wrong choice, as something to avoid.:\n\nOverhead efficiencies are often achieved by outsourcing to specialists. ADP, for example, has made a living in several busi-\nnesses, one of them payroll processing across many industries, another back-office processing for investment companies. It has\nadded value by achieving measurable economies of scale from handling the mass of transactions supplied to it by many firms\nwhich, had they decided to keep this function in-house, would have nowhere near the volume to match ADP\u2019s costs. In some cases,\nthese services are provided not by pure third parties but by leading firms within the industry, like large banks that process credit\ncard and other transactions for smaller banks. These economies are not difficult to identify in theory, nor have they been difficult\nto achieve in practice, even without a fully cooperative organization of functions.\n\nFinally, there is the amorphous but crucial question of the distribution of risk. The insurance industry exists to shift some\nkinds of risks from individuals and firms to companies specializing in accepting risk at a price. But there are many kinds of risks\nthat companies face, not all of them insurable by traditional methods. All industries face fluctuations in demand for their offer-\nings. Price wars often occur when demand shrinks. They are a natural result of firms responding in their own interests, but like all\nprice wars, they make everyone worse off, especially when there is less business to go around. Increases in capacity unwarranted\nby additional business create their own imbalance between supply and demand. In both cases, price and capacity coordination re-\nquire competitive restraint to minimize damage and control risk.\n\nFluctuations in input prices, either locally or globally, have traditionally been automatically smoothed out with contracts that\nincorporate cost sharing between suppliers and customers and across firms in the industry that are differentially affected by such\nchanges. More recently, the same type of insurance has been provided by hedging\u2014the use of derivative contracts to shift risk\nfrom one party to another. In a coordinated industry, arrangements of both kinds would be widespread.\n\nFrom a strategic perspective, a detailed and comprehensive picture of what the industry would look like in its most effective\n\nconfiguration serves as a guide to the kind of cooperative arrangements that a firm ought to pursue, through explicit negotiations\n\f"}, "003212.png": {"text": "or other means. It also establishes goals that the company\u2019s management should set for itself. The examples we present in the fol-\nlowing chapter reveal how far a fully cooperative approach may take an industry. But even where extensive cooperation does not\nseem practical, a picture of the industry from a cooperative perspective helps to define the strengths of a particular company. The\nroles that the company would play within a cooperative configuration, and the market positions it would occupy, highlight the\nspecific competences that the company brings to the industry and thus the areas in which it should focus its efforts. Only after it\nhas made these decisions is it time to turn to the question of what rewards it might reasonably expect to earn from these focused\n\nactivities.\n\nUTILIZING \u201cFAIRNESS\u201d PRINCIPLES TO DIVIDE THE SPOILS WHILE SUSTAINING COOPERATION\n\nThe mathematician John Nash won the Nobel Prize in Economics for, among a few other things, initiating work on the principles\nof \u201cfairness\u201d for determining the division of rewards in an industry that has achieved a stable cooperative organization (a coopera-\ntive equilibrium). Other economists have built on Nash\u2019s efforts, so that now the principles are well established. Here we will focus\non three: individual rationality, symmetry, and linear invariance.\n\nBefore we turn to the principles and their practical strategic implications, it is important to understand what \u201cfairness\u201d means\nin this context. It is more than a matter of justice. For cooperation to be sustained, all of the cooperating parties need to be satisfied\nwith the returns they receive from continuing to cooperate. If any player becomes sufficiently dissatisfied, it will inevitably aban-\ndon its cooperative behavior. Noncooperation from a single player may lead to a cascading collapse in cooperation by others.\n\nAcommon example of the perils of discontent occurs in price competition. When a firm becomes unhappy with its share of\nthe market at cooperatively maintained high prices, it will lower its own prices to gain business. Competing firms are not likely to\n\nstand by idly as their customers decamp. They protect themselves and drop their own prices. In short order, the price declines may\n\f"}, "003213.png": {"text": "spread throughout the industry. To keep the ball from unraveling in the first place, all the companies have to believe that they are\n\nbeing treated fairly in the current arrangement. This perceived fairness is essential to the stability of cooperation.\n\nINDIVIDUAL RATIONALITY\n\nThe first condition of fairness is that no firm in a cooperative arrangement should receive less than it could obtain in a noncoop-\nerative setting. Clearly, a company that can do better by not cooperating is not going to continue to cooperate. In the language of\nformal game theory, this condition is referred to as \u201cindividual rationality.\u201d Unless it makes sense for each firm to cooperate, mean-\ning that each firm does at least as well by cooperating as by refusing to cooperate, then cooperation will not be sustainable. In this\nsense, the original division of the spoils will not be fair.\n\nBecause of the fairness condition, it is important to consider the outcome that firms can achieve when they do not cooperate.\nIn John Nash\u2019s term, these are \u201cthreat point\u201d outcomes, the \u201cthreat\u201d being noncooperation and a myopic pursuit of one\u2019s individual\ngoals. In the language of negotiation theory, the same outcome is referred to by the acronym BATNA\u2014the best alternative toa\nnegotiated agreement. Whatever the name, it is the yardstick against which the firm\u2019s rewards under a cooperative arrangement\nare measured. In organizing a fair division of the spoils, the noncooperative outcomes for all the participants have to be taken into\naccount.\n\nThe requirement of individual rationality has powerful implications. In many situations, it alone determines the distribution\nof cooperative rewards. Consider the case in which a number of firms contribute to a final end-user product in the information\ntechnology area. Some firms produce components. Other firms assemble the components into various types of equipment. Still\nothers combine equipment, software, and service support to produce applications systems that are sold to end users. Clearly, firms\nat each stage in this value chain have incentives to maximize the final price of the item sold and to minimize the total costs of pro-\nducing it. This is a clear instance where cooperation both is beneficial to firms and does not run afoul of antitrust laws. Despite the\n\ngroup interest that the firms have in securing the highest return on the item in question, the question of how this overall industry\n\f"}, "003214.png": {"text": "return is to be divided among participants at each stage of the production process\u2014components, equipment, systems, and support\n\u2014still needs to be settled.\n\nThe individual rationality requirement on its own may provide an answer. Let us assume that component production and\nequipment assembly are businesses in which there are no barriers to entry and no incumbent competitive advantages. Systems\nintegration, on the other hand, is characterized by economies of scale in both software creation and service support, and by a suffi-\ncient degree of customer captivity to nourish the economies of scale. If the component and equipment makers existed in a world\nwithout cooperation, new entrants and internal competition would drive their economic profit to zero, meaning that they would\nearn a return on their invested capital equal to the cost of acquiring that capital. The threat point, or BATNA, for these companies,\nthe point at which they would be better off without cooperating, is at this level of reward, when they earn no more than their cost\nof capital.\n\nThe dominant systems integrators are in a very different position. They do benefit from competitive advantages, and they\nearn more than their cost of capital under the noncooperating regime. Component and equipment suppliers who do not want to\ncooperate can be replaced readily from the sea of potential new entrants able to produce at the same cost as the original firms. As a\nconsequence, the threat point return of the systems integrators, their BATNA, is equal to their profits under full cooperation. They\ncollect for themselves all the benefits from cooperation. They do not have to share with the component and equipment makers,\nwho have no better alternatives available. So it is competition within the component and equipment assembler markets that en-\nforces cooperation from these companies without their getting any share of the excess profitability.\n\nThe principle involved here is a general one. Firms that operate without competitive advantages should not expect to earn re-\nturns above their cost of capital even when they work in a cooperative environment. All those firms that expect to prosper over the\nlong run based on relationships they have with companies like Wal-Mart, Staples, Microsoft, Intel, and other dominant companies\nare almost certainly deluding themselves. They should count on earning their cost of capital and nothing more. At the same time,\nthe Wal-Marts, Staples, Microsofts, and Intels of the world should not expect their suppliers, distributors, and other cooperators to\n\naccept returns below their cost of capital, at least over time. If the powerful companies do not let the cooperating firms earn their\n\f"}, "003215.png": {"text": "costs of capital, these firms will ultimately leave the business, and the supply of replacements will dry up. This is the principle of\nindividual rationality at work on both sides of the negotiating table. As they say in country music, if you don\u2019t bring anything to\nthe dance, you shouldn\u2019t plan to bring anything home. On the other hand, you don\u2019t have to return home with less than nothing.\nThe principle of individual rationality implies that the only benefits of cooperation that are subject to divvying up are those\ngains above the noncooperation outcomes, that is, gains that are the benefits to cooperation itself. When, among all the cooper-\nating companies, only one firm enjoys competitive advantages over its actual and potential rivals, it will reap all the rewards. In\nmany instances, however, more than one firm benefits from competitive advantages and has some claim on the cooperative gains.\nIn the personal computer industry supply chain, both Microsoft and Intel enjoy significant competitive advantages. What consti-\ntutes a \u201cfair\u201d division of the spoils in instances like these? Fortunately, there are additional fairness conditions that govern their\n\nallocation.\n\nSYMMETRY\n\nNash used the term symmetry to describe a second fairness condition. Under the principles of symmetry, if all the legitimate\nclaimants to the benefits of joint cooperation, that is, all those enjoying competitive advantages and therefore not forced to cooper-\nate by competitive pressure, look essentially the same, then they should divide the benefits of cooperation equally. Like individual\nrationality, the symmetry condition has to be satisfied in cases where it applies in order for cooperation to be sustained success-\nfully over time. If, among essentially identical cooperating firms, some of them consistently appropriate a disproportionate share\nof the benefits of cooperation, then the firms that have been shortchanged are going to be dissatisfied, and legitimately so. Firms\nwith authentic grievances will not cooperate indefinitely. The companies that have been successful in grabbing more than their\nshare of the spoils may do well in the short run, but over time their greed will undermine cooperation, to the detriment of every-\none. Mutual recognition of the force of the symmetry condition\u2014how it is crucial to sustaining a cooperative equilibrium\u2014should\n\nhelp forestall dysfunctional wrangling over sharing the gains.\n\f"}, "003216.png": {"text": "If two firms in an industry both enjoy competitive advantages, cooperation requires that both participate. Then, if the benefits\nof cooperation can be shared between them so that each dollar of benefit surrendered by one firm is transferred to the other one,\nthe division of the benefits should be equal. Regardless of any differential in size, power, or other important characteristics of the\nfirms, the benefits of cooperation\u2014the total returns earned that exceed the sum of their individual noncooperation returns\u2014\ndepend equally on both firms, and both firms have equal access to them. The firms are equal in that each is essential for there to be\nany benefits of cooperation, and therefore, according to the symmetry condition, they ought to expect to share in them equally. If\neither makes a determined effort to seize more than an equal share, that move will ultimately undermine the cooperation between\nthem, hurting them both. As in so many other areas of business strategy, a calculated restraint on aggression is essential to long-\nterm success.\n\nThe situation that most commonly meets these symmetry criteria in practice occurs when there are competitive advantages\nin some links along a value chain that runs from raw material producers to end user suppliers. Firms in subsegments without\ncompetitive advantage should earn returns on investment just equal to their long-term costs of capital. Firms enjoying exclusive\ncompetitive advantages within distinct subsegments must cooperate with one another to maximize overall profitability. They can\nthen divide these profits seamlessly by varying the prices charged to downstream segments. Lower prices charged by an upstream\nmonopolist that reduce its revenue and profit by $100,000 per month should add an identical amount to the revenues and profits\nof the downstream monopolist, given that prices to the end user and the quantity sold remain at their cooperatively determined\noptimal levels.\n\nSuppose that the total economic profit from the final product offering is $10 million per month at the maximum. The mechan-\nics of the transactions between the segments allow this amount to be divided up in any way between two or more advantaged\nfirms supplying constituent parts of the final product. They accomplish this transfer by varying the price at which they hand off\ntheir output to downstream firms. In practice, the individual rationality condition will place constraints on how the division actu-\nally works. Suppose that if cooperation breaks down, the upstream firm will earn $2 million in economic profit, the downstream\n\nfirm $4 million. The benefit of cooperation of $4 million (10 - 2 - 4) depends equally on both firms. Thus, above the threat point,\n\f"}, "003217.png": {"text": "they have equal access to and an equal role in the creation of this benefit. Symmetry requires that they share the $4 million equally,\nleaving the upstream firm with a total of $4 million in economic profit (2 +2) and the downstream firm $6 million (4 + 2). Both\nfirms, having an interest in sustaining mutually beneficial cooperation, should independently seek to reach such a \u201cfair\u201d outcome.\nOtherwise, either one may decide that it is being treated unfairly and might take some aggressive action which would lead to a\nbreakdown of cooperation. The breakdown would have adverse consequences for both firms.\n\nThis principle applies in cases where there are more than two firms serving as complementary suppliers along a value chain. If\n\n   \n\nthese companies want cooperation to be sustained, then there has to be a mutually satisfactory division of its benefits. Microsoft\nand Intel have avoided explicit competition over the cooperative benefits in the PC industry, based on the principle of equality\n\nas measured by threat point returns. To date, Microsoft has reaped a larger share of total industry profits than Intel, because it\n\nhas had virtually no competition whereas Intel has had AMD and other potential CPU makers at its heels. This arrangement may\nchange should Microsoft encounter a serious threat to its dominance, perhaps from Linux. By contrast, in a case we describe in\nthe next chapter, Nintendo\u2019s aggressive attempt to garner a disproportionate share of the video game industry\u2019s profits left other\nparticipants discontented. Their dissatisfaction created an opening for Nintendo's competitors, who moved in and undermined its\n\nposition.\n\nLINEAR INVARIANCE\n\nThe need for fairness applies to situations in which several firms, all with competitive advantages, occupy the same segment in the\nvalue chain and divide the market horizontally. In this case, the fairness principle dictates that if there are two firms in a segment,\nand one of them has twice the size or strength of the other, then its portion of the benefits from cooperation should be twice as\nlarge. Nash used the term linear invariance for this version of the fairness requirement. It works by assigning shares of a coopera-\ntively exploited horizontal market in proportion to the cooperating firms\u2019 relative economic positions\u2014to each his own, in other\n\nwords. In the next chapter, we discuss a declining industry with chronic excess capacity. The participants managed to sustain a\n\f"}, "003218.png": {"text": "profitable cooperative arrangement among themselves over a long period by adhering to the linear invariance application of the\nfairness principle. It can serve as a model, to those many industries beset by ruinous competition, of what cooperation, coupled\n\nwith a mutually acceptable \u201cfair\u201d division of industry returns, can achieve, as measured by industry profitability.:\n\nPURELY HYPOTHETICAL?\n\nThe cooperative perspective is instructive even where there is no chance that the companies in a particular industry will be able to\novercome their antagonisms and work out some kind of cooperative arrangement. It can identify potential areas of cooperation,\neven if they are limited to only one or a few of the areas we listed earlier in the chapter, like specializing research and develop-\nment to avoid duplicating one another's efforts. It is also useful in highlighting a firm\u2019s genuine strengths by pointing out where\nit would fit if the industry were organized cooperatively. In this respect, it can help clarify realistic expectations and terms for\nprospective strategic alliances and relationships between suppliers and purchasers.\n\nFinally, if a firm\u2019s own prospective position within a cooperative configuration of an industry does not look promising\u2014at the\nextreme, the firm has no reason for existing if there is cooperation because, for example, it is a high-cost supplier\u2014this informa-\ntion provides an important strategic insight into the company\u2019s future. Its survival will depend on the failure of the other compa-\nnies in its industry to cooperative effectively with one another. If it wants to continue, it will have to improve its position before\nthe stronger market participants learn to cooperate successfully. By recognizing the ultimate consequences for itself if others\ncooperate, the firm\u2019s management can get a sense of how long it has to live and how far it has to go to survive. These are essential\npieces of information for formulating a useful strategy for such a disadvantaged firm. Such insights add to the overall value of a\ncooperative viewpoint, which is an indispensable supplement to the more standard forms of competitive analysis. In the area of\n\ncompetitive analysis, it is important to keep in mind the fundamental complexity of the problems at issue. Clarity depends on a\n\f"}, "003219.png": {"text": "picture built up carefully from a group of simplifying perspectives. A fully cooperative view of the world, however unrealistic in\n\npractice, is a perspective that contributes meaningfully to that clarity of vision.\n\f"}, "003220.png": {"text": "CHAPTER 15\n\nCooperation\n\nThe Dos and Don'ts\n\nSuccessful cooperation is neither common nor easy. The rival firms have to find a way to work in harmony to advance their joint\ninterests, and they have to do it legally, to avoid drawing down the wrath of the agencies charged with preventing and punishing\nrestraint of trade. The episodes presented in this chapter represent three potential outcomes of a potentially cooperative arrange-\nment.\n\nIn the first, Nintendo allowed its drive to dominate and its sense of in-vulnerability blind it to the need for more jointly\nbeneficial relationships with its suppliers and customers. As a result, they were only too happy to see competitors encroach on\nNintendo\u2019s turf and cut it down to size. The second example describes the successful cooperative arrangement established by the\nproducers of lead-based gasoline additives. They made the most of an industry condemned to a slow death by environmental regu-\nlations. Finally, the two major auction houses, Sotheby\u2019s and Christie\u2019s, decided to get together and end their practice of competing\n\nby lowering prices. Unfortunately for them, the \u201cgetting together\u201d took the form of overt and illegal collusion, which sent one of\n\f"}, "003221.png": {"text": "the principals to prison and others into retirement. We suggest that they could have accomplished most of their goals without\n\nsuch ruinous consequences.\n\nHOW TO BREAK A VIRTUOUS CIRCLE: GAMES NINTENDO PLAYED\n\nBy the time Nintendo entered the market for home video games in the mid 1980s, the industry had already experienced two\nbooms and two devastating busts in its short life. In 1982, U.S. consumers spent $3 billion on consoles and games; in 1985, the\nfigure had dropped to $100 million. The situation was not very different in Japan until Nintendo and its little plumber Super Mario\nbrought life and income back into the industry. Starting in Japan in 1983, and then in the United States in 1986, it sold its 8-bit\ngame consoles into millions of homes. These consoles were Nintendo's equivalent of Gillette\u2019s razors; it made its money selling the\ngames. In Japan, the average console owner bought twelve game cartridges; in the United States, he bought eight of them. (We say\n\u201che\u201d advisedly, since the typical gamer was a boy between eight and fourteen years old.) By 1989, sales in North America recovered\nto $3 billion. And Nintendo had by far the largest share of this market, around 95 percent in Japan, 90 percent in the United States.\nBetween consoles, games, royalties, and other sources, Nintendo's own global sales exceed $4 billion in 1992.\n\nNintendo succeeded largely by improving the quality of the games available. In the late 1970s, it had entered the arcade game\nsector with its first hit, Donkey Kong. Unlike the home console market, the coin-operated arcade business did not collapse in the\nnext decade; revenues of $5 billion in the mid 1980s indicated that the demand for a quality game experience was still strong. The\narcade machines were more powerful and much more costly than home consoles, and the arcade owners had control over which\ngames ran on the machines. A critical problem that had plagued Atari and the other first-generation console makers was a flood\nof low-quality games, many of them unlicensed and even counterfeit, that swamped the market. The console makers derived no\nrevenue from these intruders, and the poor quality of their games\u2014at times they simply didn\u2019t work\u2014undermined the whole\n\nindustry.\n\f"}, "003222.png": {"text": "Nintendo solved these problems. Its first hit for home console, Super Mario Brothers, was its own creation, as were some of\nthe other early successes. And it improved the technology of the game console both to guard against unapproved, low-quality\ngames and to make the systems more powerful, though not more costly, in order to produce an experience more like that of arcade\ngames. Each game cartridge included two microchips, one to hold the game, the other a coded security chip produced by Nintendo,\nwithout which the cartridge would not play on the Nintendo console. The game chip also carried code common to all games that\nran on the console. By off-loading some of the functions from the console to the cartridge, Nintendo was able to lower the console\ncost and make the hardware less expensive, even while it was raising the cost of game software. The console sold for $100 at retail\nwhen it was introduced in Japan in 1983; game cartridges sold for around $40.\n\nThe Nintendo approach succeeded from the very beginning. The company sold over 1 million consoles in Japan in 1983, 2\nmillion the following year, 3 million in 1985, and almost 4 million in 1986. It had to modify the design of the console to enter the\nAmerican market, making it look more like a computer and less like a toy. But after some initial hesitation on the part of retailers,\nthe system took off and sales grew even more rapidly in the United States than in Japan. In 1989, more than 9 million customers\nbought the system in the United States, and they supplemented those purchases with more than 50 million game cartridges. By\n1990, at least 70 percent of American households with boys aged eight to fourteen owned a video game system. More than 90 per-\n\ncent of them were Nintendos.\n\nTHE NINTENDO SYSTEM\n\nThe management of Nintendo understood from early on that the availability of a variety of high-quality games would be the\ndriving force in the business. They also knew that they did not have the creative resources within their company to turn out\nenough games to meet the demand. With the costs of writing a single game at around $500,000, it was expensive and risky to try\nto produce all the games themselves, since a game, like a movie, could fail to attract an audience. They turned to licensing, allow-\n\ning other companies to write games for the Nintendo system. The original licenses in Japan went to six firms, all with direct or at\n\f"}, "003223.png": {"text": "least relevant experience in the game world. Under the terms of the license, Nintendo was to receive a royalty of 20 percent on the\nwholesale price of the games. Cartridges sold at wholesale for $30; each sale produced $6 for Nintendo.\n\nThough they had to spend a lot of money on game development and pay Nintendo a 20 percent royalty, the original six\nlicensees got very generous terms when measured against those imposed by Nintendo on all subsequent game writers. The forty\nor so additional licensees that had signed up by 1988 also paid the 20 percent royalty. In addition, they had to let Nintendo do all\nthe manufacturing, for which it charged them around $14 per unit. The initial order, for a minimum of 10,000 units, needed to\nbe paid for in advance. When Nintendo started a similar program with outside developers in the United States, the initial order\njumped to 30,000, and the cartridges were delivered at Kobe, Japan, FOB (free on board, meaning the buyer owns the goods when\nthey leave the loading dock and must pay for the shipping), leaving it to the game writers to import and distribute them in the\nUnited States.: Nintendo itself contracted out the manufacturing of the game cartridges to Ricoh, paying roughly $4 per cartridge.\nThe $10 margin between the $14 it charged and the money it paid Ricoh went to Nintendo. When the original six licenses expired\nin 1989, they were reissued with the manufacturing clause included. Some of the licensees grumbled, but they stayed with Nin-\ntendo. There was nowhere else to go.\n\nNintendo further controlled the game writers by limiting the number of titles they could produce in any year to five. It tested\nthem for quality and regulated the content; it would not license games that it regarded as too violent or sexually suggestive. And\nas part of the license, the game writers could not offer games for other video console systems for two years. They were locked in to\nNintendo. Given the overwhelming market share that Nintendo commanded, they virtually had no choice. It was write for Nin-\ntendo with the prospects of producing a few profitable hits, or write for the other consoles and live in a universe competing for the\n10 percent of the market Nintendo did not own.\n\nNintendo was equally dominant in its relationship with game retailers. When Nintendo had initially tried to sell its game\nconsole into the U.S. market in 1985, toy retailers were unresponsive. They had been burned with the precipitous decline of the\nearlier-generation game machines, and may still have been trying to dispose of their unsold inventory of Atari VCS systems.\n\nNintendo decided to change the design of the machine and distribute it through electronics retailers. Even then, it needed to sell\n\f"}, "003224.png": {"text": "them on consignment, charging stores only for the units they actually sold. But the system quickly became popular, and Nintendo\nmoved from being a petitioner to a powerful vendor calling the shots.\n\nEven retail giants like Wal-Mart, Kmart, and Toys \u201cR\u201d Us had to pay for their shipments virtually upon receipt, rather than\nusing the extended terms common in the toy industry. Wal-Mart sold Nintendo systems exclusively, and all the retailers adhered\nto Nintendo\u2019s suggested retail pricing for systems and game cartridges. Nintendo insisted that its retailers establish prominent\nNintendo game centers in their stores, and they readily complied. Because Nintendo actually shipped fewer cartridges than the\nretailers ordered, and fewer than the customers wanted, they could reduce allocations to any of the merchants who would not play\nby Nintendo\u2019s rules.\n\nNintendo\u2019s success and its treatment of retailers and game writers drew critics, including the head of the House Subcommittee\non Antitrust, Deregulations, and Privatization. In 1989, he asked the Justice Department to investigate some of the company\u2019s\npractices. Two years later, Nintendo signed a consent decree with the Federal Trade Commission and some states\u2019 attorneys gen-\neral agreeing to stop fixing retail prices. But its dominance among retailers and game writers was largely unaffected. There were\nstructural reasons that explained its continuing strength.\n\nBy the late 1980s, the shape of the video game industry had stabilized in the form shown in figure 15.1. The game console pro-\nducers were at the center of the industry. They designed, distributed, and promoted the machines on which the games are played.\nThey sometimes did the manufacturing themselves, assembling them from purchased chips and other components, but just as\nfrequently, like Nintendo, they subcontracted out manufacturing. They produced some of their own games, but these constituted\n\na relatively small fraction of the games available.\n\f"}, "003225.png": {"text": "Component\n\nManufacturers\n\nand System\nAssemblers\n\nRicoh\n\nNEC\n\nMatsushita\n\nFujitsu\n\nMotorola\n\nOther smaller\ncompanies\n\nGame Writers\nAtan\nNintendo\nHudson\nTaito\nKonami\nBandai\n\nElectronic arts\n\nSega\nTaino\nNamco\nActivision\nAcclaim\n\nGame Console\nProducers\nActivision\nNintendo\nSega\n\nRetailers\n\nToy Stores\n\nMass merchants\n\nElectronics\nstores\n\n \n\f"}, "003226.png": {"text": "FIGURE 15.1\nMap of the video game industry, late 1980s\n\nDuring its rise to dominance, Nintendo faced competition in this segment from Atari, Activision, and Sega. Some early console\nproducers like Coleco, Mattel, and Magnavox had disappeared by then, but newcomers like Sony and Microsoft entered the in-\ndustry. By the early 1990s, this segment was dominated by Nintendo. Component and chip producers, who also often assemble\nsystems for the game console companies, included well-known electronics and chip companies, as well as smaller and more ob-\nscure electronics manufacturers. This sector was highly competitive, and the console companies were just one of many groups\nof customers, and a relatively minor one. Games were designed and produced by a large number of creative firms, including the\nconsole producers themselves. Hudson, Electronic Arts, Taino, Komani, Bandai, Namco, and Taino were prominent names in this\nsector. Finally, both consoles and game cartridges were distributed through toy stores like Toys \u201cR\u201d Us, mass merchants like Wal-\nMart, electronics stores like Circuit City, and other specialty retailers.\n\nBecause the manufacturing sector was highly competitive and only peripherally dependent on home video games, the three\nkey sectors were game writers, console producers, and retailers. From the later 1980s through the early and mid 1990s, Nintendo\nstood out as the dominant player. Looking at the industry from a cooperative perspective, the most efficient configuration was to\nhave a single system at the center of the market. Game writers would have to bear the expense of producing only one version of\neach game, and they would have access to the complete universe of potential customers. Retailers would need to stock titles for\nonly one system, and thus could offer more games with lower inventory expense than if they needed a version for each competing\nconsole. Game players would have to learn to operate only one system and would be able to play all available games on that one\nconsole.\n\nEven the objection that a single dominant supplier would have no incentive to innovate and keep up with rapidly changing\n\ntechnology would not apply. The fixed research and development costs of bringing out new generations of technology would be\n\f"}, "003227.png": {"text": "lower with a single system supplier than with multiple suppliers developing overlapping and duplicative technologies. Successive\ngenerations of consoles with upgraded capacities could be introduced in an orderly sequence, like the innovations for the Wintel\nplatform for PCs, instead of in haphazard fashion that rendered earlier generations of games obsolete before replacements were\nfully available. Finally, profits for the entire industry could be maximized with a strategy of pricing the consoles to break even and\nmaking all the profits on the sale of games.\n\nIf Nintendo had been willing to share the benefits of this organization with the game writers and the retailers, there was no\ninherent reason why the strategy should not have survived several generations of technology. On the other hand, if Nintendo\npersisted in trying to capture a disproportionate share of industry profits, then its position would survive only so long as its com-\n\npetitive advantages were sustainable.\n\n\u2018WHICH COMPETITIVE ADVANTAGES?\n\nFrom the time it entered the video game market with its own console system, Nintendo's success was sufficient to suggest that it\ndid enjoy competitive advantages in the industry. It had an overwhelming and stable share of the market throughout the period,\ncontrolling 95 percent of the console business in Japan, 90 percent in the United States. The business was highly profitable. From\n1984 through 1992, Nintendo averaged over 23 percent return on equity. On these two quantitative measures, Nintendo passes\nthe incumbent competitive advantage test, at least in the period before 1992. The stock market certainly priced Nintendo as if it\nowned a powerful franchise. In 1991, its market capitalization of 2.4 trillion yen (over $16 billioin in 1991 exchange rate) was ten\ntimes the book value of its equity. It had a higher market value than Sony and Nissan, firms considerably larger and more estab-\nlished. But if someone examined the sources of these competitive advantages in 1991, it was not at all certain that they would be\n\nsustained into the future.\n\nCaptive Customers?\n\f"}, "003228.png": {"text": "Its large installed base of 8-bit video game consoles gave Nintendo some degree of customer captivity, due to the switching costs a\ncustomer faced once he had bought the machine. No Nintendo owner was going to buy a game cartridge (or CD-ROM, which was\nbecoming an alternative format) not compatible with his machine. But the strength of this customer advantage was weakened by\ncertain inherent features of the video game business.\n\nThe customer base turned over quickly. The fourteen-year-old boys became fifteen, reduced their game-buying habits, and\ngave up their spot to younger kids turning eight or nine who did not already own a game console and so were not as committed to\nNintendo.\n\nThe price of the console, relative to the cost of a game, was low. With the games costing $40 or more, a replacement console at\n$100 or $150 was no more expensive than a few games.\n\nNew technology in the form of faster chips able to process broader streams of data (16, 32, 64, and 128 bits) was becoming\navailable, and at prices not much more than Nintendo\u2019s 8-bit warhorse. Bigger and faster microprocessors meant more realistic\ngames. At some point, the quality differential between a fast new machine and a tired Nintendo would become large enough so\nthat both the new younger customers, getting their first consoles as presents, and their older brothers, demanding to keep up with\nthe youngsters, would make the switch, and all of Nintendo\u2019s arsenal of software would do it little good. Also, games get boring.\n\nThe demand for new games is like Pac-Man; it eats the value of the existing collection.\n\nBetter Technology?\n\nNintendo was clever in putting a security chip in each of the cartridges it produced, but the chip itself was standard issue. There\nwas nothing proprietary about its technology; it had no meaningful patents. In the drive to keep the cost of its console down, it\nbought commodity parts from suppliers like Ricoh. To stop a company that had found a way around its security chip from selling\nunlicensed games, it pressured the gaming magazines not to carry ads from the intruder. Nintendo was largely an assembler of\n\nstandard parts, and it even contracted out much of the assembly. Nintendo did not owe its profitability to superior technology.\n\f"}, "003229.png": {"text": "Economies of Scale?\n\nA potential licensee needed to spend around $500,000 in creating a game. But even with the variable margin squeezed by Nin-\ntendo to $10 per copy, that fixed cost was absorbed by the first 50,000 copies sold, which represented only a tiny fraction of the\ntotal annual unit sales. With annual video game cartridge sales of 50 million units, to reach the break-even point, a particular\ngame would have to capture only about one-tenth of 1 percent of the market. The design and production of the game consoles also\nexhibited few economies of scale. Research and development costs were relatively low. Manufacturing consisted of simple assem-\nbly operations, not a process in which there are likely to be any identifiable scale economies. Between 1987 and 1992, Nintendo\nitself averaged only about \u00a514 ($100) in fixed assets for every \u00a5100 in sales, and this ratio did not decline significantly over time as\n\nNintendo grew.\n\nThe Virtuous Circle\n\nWhat Nintendo did have working in its favor was the virtuous circle of network externalities. Once the Nintendo system had\nestablished a substantial installed base, more outside software companies wanted to write games for it, which made the console\nmore popular, meaning even more games, and on and on. The virtuous circle extended to retailers as well as game writers. Because\nretailers were reluctant to carry competing consoles and games, customers could find Nintendo products much more easily than\nany alternatives. And Nintendo, a great marketing organization, established displays in 10,000 outlets where customers could try\nout the system and the games. Having dedicated real estate within a retail store is every manufacturer\u2019s dream. Retailers, on the\nother hand, are generally reluctant to cede control over their primary asset: selling space. As a result, dedicated retail space is only\nmade available to dominant manufacturers. Controlling this space reinforces their dominance, and so on.\n\nThe extraordinary penetration of Nintendo products also provided the company with the scale necessary to publish a maga-\n\nzine exclusively for Nintendo video game players to boost sales of its games. The magazine accepted no advertising; it rated games,\n\f"}, "003230.png": {"text": "previewed new releases, and offered tips on playing current games. It was priced to break even, and by 1990 it had a larger circula-\n\ntion, at 6 million copies per month, than any other magazine in the United States dedicated to children.\n\nBREAKING THE CIRCLE\n\nDespite all these benefits that reinforced its position, including the fact that the efficient configuration for this industry mandated\na single console supplier, Nintendo was still vulnerable. Its virtuous circle rested on two advantages that turned out to be less solid\nthan Nintendo assumed. One was the enormous installed based of Nintendo\u2019s console; the other was the cooperative relationship\nbetween Nintendo, the game writers, and the retailers.\n\nThe first advantage would be wiped out by each new generation of technology. As the chips advanced from 8- to 16-, 32-, 64-,\n128-, and even 256-bit processors, the graphical quality and power of the new machines would render the old systems and games\nobsolete. Nintendo's installed base of 8-bit machines would not be attractive to either the game writers or the retailers, who sold\ngames primarily for the new systems.\n\nThe second advantage, its relationships up- and downstream, might then tide Nintendo over until it had built up a dominant\ninstalled base of new-generation systems, but only provided that the writers and the stores felt they had mutually beneficial rela-\ntionships with Nintendo. Game writers would then reserve their best next-generation games for the introduction of Nintendo sys-\ntems, and stores would continue to provide Nintendo with unequaled store space. But if Nintendo had bullied these constituencies\nand grabbed a disproportionate share of industry profits, leaving the writers and retailers waiting for the opportunity to escape\nNintendo\u2019s grip, then the opposite would happen. The best new-generation games would be retained for Nintendo\u2019s competitors,\nwho would be welcomed by the retailers with shelf space rivaling Nintendo\u2019s.:\n\nNintendo did not play well with others. It did not share industry returns fairly. The terms it imposed on game writers and\ndistributors helped to make it rich, but they did not endear it to its neighbors in the value chain. Nintendo treated the game writers\n\nparticularly poorly. In the typical game cartridge, there was roughly $26 of margin between the wholesale price of $30 and the\n\f"}, "003231.png": {"text": "manufacturing cost of $4. Nintendo took $16, or 60 percent, for itself. The game writers, who incurred all the costs and risks of de-\nvelopment and distribution, received $10, or less than 40 percent.\n\nNintendo upset the game writers in other ways. It limited them to five new titles per year. This restriction protected Nintendo\nfrom becoming too dependent on one software provider and ensured that no game writer could become successful enough to\nconsider creating its own console system. But it frustrated the game writers, especially the most talented ones, and limited their\npotential returns. There was also the censoring of content that limited violence and sexuality. And Nintendo persistently shipped\nfewer console and game units than retailers ordered during the crucial Christmas season. This imposed shortage may have en-\nhanced the Nintendo mystique, but it cut into the sales and profits of the game writers and retailers, who were also alienated by\nNintendo\u2019s aggressive payment schedules and demands for in-store displays.\n\nSega brought out a 16-bit console in Japan in 1988 with better graphics and sound than the 8-bit Nintendo standard. Still, Sega\ninitially found it difficult to induce outside developers to produce games for the system. Sega itself adapted some of the games it\nhad created for the arcade market, but sales remained slow. The company did not back off, however. It introduced the machine\nin the United States in 1989, selling it for $190. Games retailed between $40 and $70. Sega targeted these games at the content\nniches left uncovered by Nintendo\u2019s censoring policy. Still, like Nintendo in its early days, Sega had a difficult time selling the ma-\nchines. Whereas Nintendo had Wal-Mart and Toys \u201cR\u201d Us as its primary retailers, Sega had to rely on software stores like Babbage\u2019s.\n\nBut its fortunes changed in 1991, when a new executive decided to package both the console and its popular game Sonic the\nHedgehog for $150. That did the trick. The Sega machine took off, and game writers rushed to supply product for it. Nintendo had\ndelayed introducing its own 16-bit system, not wanting to cut into its thriving 8-bit empire. It followed Sega into the 16-bit mar-\nket, but not in time to prevent the entrant from gaining enough scale so that it had no problems securing games or distribution.\n\nBetween 1992 and 1994, the two companies battled for leadership, using all the weapons in a marketer\u2019s arsenal, including\ndeep price cuts and heavy advertising. If it were a video game, one newspaper suggested, it would be called \u201cMarketing Kom-\nbat,\u201d an allusion to the wildly popular game Mortal Kombat. Each company claimed to be the market leader, but it didn\u2019t matter\n\nwho had won the larger share. Nintendo was the clear loser. Hand-to-hand combat in the video game trenches undermined the\n\f"}, "003232.png": {"text": "profitability it had enjoyed when it reigned supreme in the center of the virtuous circle. Sony\u2019s entrance with a 32-bit machine in\n1995 just raised the competition to a higher megahertz. In that year, there were eight or nine companies with 32-bit or better con-\nsoles vying for a piece of the action.\n\nNintendo\u2019s dominant position was undercut by its own decisions. It chose to milk its 8-bit franchise rather than immediately\nrespond to Sega in the 16-bit world. Also, its policy of keeping shipments below demand inadvertently handed customers to Sega.\nBut even before Sega\u2019s Sonic the Hedgehog showed up, Nintendo had prepared the ground for Sega and subsequent competitors.\nOnce Sega had established its credibility, the retailers and especially the game writers rushed to its support. It was the game writ-\ners who really undermined Nintendo. Conventional wisdom in the video game industry is that the distinctiveness of the product\nlies in the software. To cite one particular ad, \u201cIt\u2019s in the game.\u201d By alienating the game writers, Nintendo gave \u201cthe game\u201d to Sega\nand Sony.\n\nThere is no certainty that a cooperative strategy would have prevented the software firms from signing up to develop games\nfor Sega and Sony. All we know for certain is as soon as Sega showed a little traction with its 16-bit player, they rushed to supply\ngames for its system. The developers were delighted to have multiple console makers in the market, even though it cost more to\nturn out games for different platforms. They were able to negotiate better deals with the hardware companies. In fact, power had\nshifted from Nintendo to the developers. \u201cIn the game industry,\u201d according to a BusinessWeek story, \u201ccontent rules. No matter how\ntechnologically advanced a console may be, it\u2019s doomed without enticing game titles.\u201d Now Sega, Sony, Nintendo, and ultimately\nMicrosoft were the supplicants, offering the developers better terms on the costs of producing a CD (PlayStation machines used\nCDs rather than game cartridges) and reduced royalty charges. They also began to help with development expenses. Because of the\nmore complex graphics now demanded, development could cost up to $10 million per game, twenty times the average when Nin-\ntendo\u2019s 8-bit standard held sway.\n\nNintendo went from a company with a dominant position in an industry and a high return on capital to one competitor among\nmany with at best ordinary returns on investment, in large part because it did not play well with others. It claimed so much of the\n\nindustry profit for itself that both developers and retailers were ready to support new consoler makers. To see how savvy compa-\n\f"}, "003233.png": {"text": "nies can manage to do well by working together, we look next at a grubbier industry with nothing like the glamour or future of\n\nelectronic games\u2014the providers of lead-based additives for gasoline.\n\nLEAD INTO GOLD: GETTING ALONG IN THE GASOLINE ADDITIVE BUSINESS\n\nConsider an industry with these characteristics:\n\n+ Its product is acommodity\n+ There is substantial overcapacity\n- Demand is guaranteed to decline rapidly\n\n+ It gets bad press and bad marks from government agencies and public interest groups\n\nUnder these circumstances, it is difficult to believe that the businesses operating within this industry would be able to make any\nprofit and inconceivable that they would earn exceptional returns.\n\nThe managers of companies producing the lead-based additives used to boost octane ratings of gasoline (reduce knocking)\nwere able to pull off this difficult feat because they knew how to pull together. Even after the Federal Trade Commission took\nexception to some of their business practices, they found ways to cooperate and share the wealth. They responded to shrinking de-\nmand by reducing their own capacity. One by one the companies left the business altogether, selling out to the remaining players\nor simply shutting down. By the time the last of them had exited, in the late 1990s, they had had a twenty-year history of making\nmoney in a bad business.\n\nIn 1974 there were four U.S. companies in the lead-based additive industry: Ethyl, DuPont, PPG, and Nalco. Together they\n\nproduced around 1 billion pounds of these chemical compounds. The Ethyl Corporation had been in the business since 1924,\n\f"}, "003234.png": {"text": "originally as a joint venture between General Motors and Standard Oil of New Jersey. A patent protected it from competition until\n1948, when DuPont entered the business to capture some of the market and the attractive returns Ethyl was earning. (In fact,\nDuPont had done production for Ethyl until the expiration of the patent allowed it to sell the additive for itself.) PPG, through\n\nits purchase of Houston Chemical Company, and Nalco were encouraged and assisted in getting into the business by Mobil and\nAmoco, respectively. These big refiners were major users of the additives, and they sought to spur competition and reduce their\ncosts by sponsoring additional firms in the additive business. In every instance these hopes were disappointed. Ethyl managed to\nco-opt each successive entrant, limit competition, and sustain industry profitability.\n\nProspects for the industry changed sharply in 1973, when the Environmental Protection Agency issued regulations intended\nto implement parts of the Clean Air Act of 1970. The regulations were intended to phase out the use of lead-based additives over\ntime. They relied on two tools. First, starting with model year 1975, all new cars sold in the United States had to be equipped with\ncatalytic converters designed to reduce harmful exhaust emissions from automobiles. The converters could not operate properly\nwith lead-based additives in the gasoline, so refiners had to produce unleaded gas for all new cars. Second, the EPA tried to deal\nwith lead directly by reducing the amount refiners could put into their gasoline. Ethyl was able to delay the implementation of the\nregulation until 1976, but after that the quantity of permissible lead per gallon, and thus the total market for the additives, began\na steady decline. The billion pounds of additives sold in the mid 1970s was reduced to around 200 million pounds ten years later,\nand to almost nothing by 1996. Part of the drop came as cars sold before 1975 grew old and left the roads; part came from the reg-\nulations on grams of lead per gallon.\n\nAlthough the medical case against lead in the air was disputed for a time, the hazardous nature of the additive compounds was\nalways clear. They were flammable and explosive, toxic in contact with the body, and dangerous to breathe. Refineries tried to keep\nno more than a ten-day supply on hand to minimize the dangers. The compounds required special equipment both for transporta-\ntion and for storage. Still, the companies were able to ship the liquid in common carriers. The ability to use common carriers rather\n\nthan company-owned and dedicated fleets fit perfectly with the commodity nature of the cargo.\n\f"}, "003235.png": {"text": "THE LEAD ADDITIVE INDUSTRY\n\nThe structure of the industry that produced and bought these compounds was uncomplicated. A small number of chemical com-\npanies bought raw materials, especially lead, processed them into two different additives, tetraethyl lead (TEL) and tetramethyl\nlead (TML), and sold them to gasoline refiners. Nalco used a different process to make its TML, but in practice its additives were\ninterchangeable with the others. All the producing companies were diversified, especially DuPont and PPG. Even Ethyl, the pioneer\nand the company with the largest market share, derived only 17 percent of its sales from these additives. Their customers were\nbasically domestic and offshore gasoline refineries, principally those operated by large integrated oil companies. After the EPA\nbegan to limit use in the United States, the producers tried to maintain their sales by finding foreign customers. They did sell some\ncompounds abroad, but because of high shipping costs and the hazardous nature of the material, these sales were generally from\nplants also located overseas. There were also non-U.S. companies in this market.\n\nRaw materials accounted for most of the costs of production. All the producers needed to buy lead. Ethyl and DuPont made\nmost of the rest of their inputs; PPG and Nalco relied more on outside suppliers. No doubt there were cost differences among the\nfour companies, but not so much as to encourage any of them to take advantage of a position as low-cost producer.\n\nIt is difficult to see any significant competitive advantage that distinguished one firm in the business from another. Ever since\nthe original Ethyl patent expired in the 1940s, none of them had proprietary technology. Their customers, especially the largest of\nthem, bought from more than one additive producer. Contracts generally ran for one year. When they came up for renewal, the re-\nfiners encouraged the producers to compete for their business in the only way that made a difference\u2014price.\n\nNo refiner tried to differentiate its own gasoline by claiming that its lead came from Ethyl or DuPont. So although there were\nestablished relationships between sellers and customers, and perhaps some switching costs if the formulations were different,\nthere was nothing so powerful in the nexus between producer and refiner to indicate customer captivity. A maverick additive pro-\n\nducer could have expanded its business at any time, simply by lowering its prices.\n\f"}, "003236.png": {"text": "The organization of production into a small number of plants\u2014never more than seven\u2014to supply the whole industry suggests\nthat there may have been some economies of scale. But the large plants did not drive out the small ones, indicating that scale\neconomies were limited. And without some customer captivity, economies of scale in themselves do not create a sustained com-\npetitive advantage.\n\nBarriers to entry are another story. An insurmountable barrier protected the four firms in the business. The EPA's regulatory\nannouncement in 1973 posted an unmistakable Do Not Trespass sign for any firms contemplating entering the lead-based addi-\ntive industry. Even if some company could have secured the necessary permits from local authorities\u2014highly unlikely given the\nconcerns about atmospheric lead\u2014who would want to build a plant to produce a chemical scheduled to disappear? By putting the\nindustry on a certain path to extinction, the EPA ensured that the existing firms would have the business to themselves, to profit\n\nas best they could during the slow path to disappearance.\n\nCOOPERATION AMONG FRIENDS\n\nIn seeking to encourage some price competition among the lead additive producers, the major oil companies had always been\ndisappointed. New entrants to the industry quickly went native. They learned to play along with the incumbents and to frustrate\ntheir sponsors. Perhaps the regional concentration of the industry had something to do with the ease of acclimation. Except for\none DuPont facility in New Jersey and another in California, all the plants were on the Gulf Coast in Texas or Louisiana, within a\nthree-hundred-mile radius of one another and near to the refineries they supplied. The engineers running the plants came from.\nsimilar backgrounds. In any case, both before and after environmental regulations signaled the ultimate end of the industry, the\nplayers had found ways of working together to keep in check what otherwise might have been brutal competition.\n\nMost of the methods they used were checks on themselves, to make it more difficult to give customers discounts or otherwise to\n\ndeviate from established prices:\n\f"}, "003237.png": {"text": "+ Uniform pricing. Prices were quoted to include both the cost of the chemicals and the cost of delivery. By including\ntransportation in the quoted price, the suppliers prevented themselves from offering a hidden discount with a\nlower delivery charge.\n\n+ Advance notice of price changes. When one of the suppliers wanted to change\u2014raise\u2014the list price of the additive,\nthe contracts called for it to give its customers thirty days\u2019 notice, during which time they could order more sup-\nply at the existing price. Until 1977, the additive manufacturers issued press releases to announce these changes,\nbut then ceased on advice of counsel. The refiners tried to induce other suppliers not to follow the leader in\nraising prices, but almost always to no avail. There were thirty price increases in the five years starting in 1974,\nand all of them held. Ethyl and DuPont were the initiators, with PPG and Nalco following suit. The solidarity\ncontinued even after the press releases stopped. The thirty-day advance notice of price increases meant that any\nsupplier wishing to maintain the lower price had to signal that intention thirty days before the increases by other\nfirms went into effect. If it gave the signal, the other firms would simply rescind the announced price increases\nand the deviant firm\u2019s intransigence would yield no benefit, other than to the customers.\n\n+ Most-favored-nation pricing. Applied not to import duties but to the actual prices charged for the chemicals, this\npolicy assured every customer that it was getting the best price available. More to the point, it put the suppliers\nina self-imposed straitjacket, preventing them from offering any special discount to a particular customer on the\ngrounds that they would have to give the same break to everyone. Ethyl and DuPont put the clause in their con-\n\ntracts, and Nalco followed suit on many of its own.\n\nRounding out these pricing tactics was another practice the four suppliers adopted: joint sourcing and producing. Simply put,\n\nan order placed with one supplier might be delivered from another supplier\u2019s plant, depending on location, availability of chemi-\n\f"}, "003238.png": {"text": "cals, and other practical considerations, like relative productivity. The four manufacturers maintained a settlement system among\nthemselves, netting out all the shipments made for one another and paying only the balances. Capacity, production, and sales fig-\n\nures for 1977 reveal the joint sourcing program in operation (table 15.1).\n\nTABLE 15.1\n\nCapacity, production, and sales of lead-based additives, 1977 (millions of pounds)\n\nCapacity Production Sales\nEthyl 475 37% 432 48% 312 35%\nDuPont 544 45% 250 28% 317 35%\nPPG 113 A, 97 11% 150 17%\nNalco 137 11% 122 14% 121 13%\n1,269 100% 901 10046 900 100%\n\nDuPont had the largest capacity but trailed Ethyl in production. The two had comparable sales volume. Clearly Ethyl brewed\nmore additive than it sold, supplying some of DuPont\u2019s and also PPG\u2019s customers. Joint sourcing eliminated much of the cost differ-\nential among the suppliers, who could all take advantage of Ethy!\u2019s efficiency. Taking cost out of the equation removed whatever\nincentive the low-cost producer might have to gain market share at the expense of the other three firms and minimized overall\nindustry costs. Market share of sales varied only slightly from year to year. In 1974, Ethyl controlled 33.5 percent of the market; in\n1977, the number had inched up to 34.6 percent. Indeed, there was a remarkable consistency in share changes. A large company\nwith a share of the market below 35 percent tended to increase share, whereas a comparable company with more than 35 percent\nof the market generally lost share. For the small competitors Nalco and PPG, this focal share was 15 percent. It appears that none of\n\nthe firms labored to increase its share of the market permanently.\n\f"}, "003239.png": {"text": "The stability of market share of sales coupled with joint sourcing led to an unusual rationality in capacity management. Since\nhigh-cost plants tended to operate at low capacity under joint sourcing, they were the plants most likely to be shuttered as overall\ndemand declined. In 1980, Ethyl closed its oldest plant in Houston. DuPont followed a year later, shutting its Antioch, California,\nfacility. PPG left the business entirely in 1982. Joint sourcing created an incentive structure that both eliminated excess capacity\nand closed the least-efficient plants first. The net result was a strategy to manage capacity in order to minimize overall industry\n\ncosts.\n\nENTER THE FEDERAL TRADE COMMISSION\n\nEventually, the four additive companies must have been doing something wrong because they came to the attention of the FTC for\nalleged anticompetitive practices. In 1979 the commission charged that four of their marketing practices were in violation of Sec-\n\ntion 5 of the Federal Trade Commission Act:\n\n+ The thirty-day advance notice of list price changes\n- Issuing press releases about these changes\n+ Selling the product on a uniform delivered price basis\n\n- Using most-favored-nation pricing clauses in contracts\n\nBecause of these practices, the FTC contended, the four producers were able to \u201creduce uncertainty about competitors\u2019 prices,\u201d and\nthus reduce or even eliminate price competition in the lead-based additive market. Even though the practices themselves were not\nunlawful, by using them to maintain price uniformity and stability the producers were accused of breaking the law. The complaint\n\nsaid nothing about the policy of joint sourcing.\n\f"}, "003240.png": {"text": "Two years later an administrative law judge upheld most of the complaint. Price signaling was out. Instead of preannouncing a\nprice change to the industry, now the producers had thirty days after it had gone into effect to make the change public. The most-\nfavored-nation clauses were forbidden, on the grounds they \u201cdiscourage discounting and promote price uniformity.\u201d The judge\nsaid nothing about the Robinson-Patman Act, which prohibits a seller from price discrimination among buyers. The judge found\nthat the four producers constituted an \u201coligopoly,\u201d and as such, were proscribed from practices that were not in themselves illegal.\n\nIt took two additional years, until 1983, for the FTC itself to reaffirm most of the judge\u2019s ruling. Even though there was no collu-\n\nsion to fix prices, the commission wrote, the companies had restrained competition. Ethyl and DuPont were ordered to stop:\n\n- Announcing price changes before a time agreed upon between the company and the purchaser\n+ Offering a single price to include delivery regardless of destination\n\n- Guaranteeing customers that they would receive the lowest price available to any customer\n\nThe commission did not uphold the prohibition on press conferences announcing price changes. It excluded Nalco from the ruling\nbecause Nalco was an acknowledged price follower. By 1983, PPG was no longer in the industry.\n\nAt the time of the ruling, the companies had already stopped announcing price changes beforehand. They were able to replace\na single price (uniform delivered pricing) with FOB pricing (in which the buyer owns the goods when they leave the loading dock\nand pays directly for shipping). Under either approach, the producers could not hide discounts by subsidizing shipping costs. As to\nmost-favored-nation pricing clauses, they might be removed from contracts but maintained in practice. What customer, after all,\ndid not want assurance that nobody else was getting a better price?\n\nEven when barred from using some of the specific tactics the additive makers had employed to curb their own competitive\njuices, they continued to be masters of the prisoner\u2019s dilemma game. By the time the FTC had issued its ruling, they had had years\n\nof experience in effective cooperation. So next to nothing changed as a consequence of the FTC\u2019s intervention. The industry con-\n\f"}, "003241.png": {"text": "tinued its mandated decline and the producers continued to earn money even as they sold less of the additives. In 1981, Ethyl\u2019s\nadditive business accounted for 17 percent of its sales and 33 percent of its profits. Since the capital employed had no substantial\n\nliquidation value, the return on capital was extraordinary.\n\nEXIT THE PRODUCERS\n\nIf the Federal Trade Commission\u2019s ruling had no discernible effect on the effectiveness of cooperation among the lead additive pro-\nducers, environmental regulations both within the United States and abroad continued to reduce demand. Suppliers responded.\nby closing plants, investing the cash from lead-based additives into other products, and remaining focused on working for mutual\nbenefits. Nalco left the business, but Ethyl and DuPont continued production, Ethyl at a plant in Ontario, Canada, DuPont in New\nJersey. The other major international player was Associated Octel, a company based in England but with Great Lakes Chemical,\nheadquartered in Indiana, as the majority owner. Until July 1994, DuPont supplied Ethyl with much of its product. After DuPont\nclosed its operations, Ethyl turned to Octel, signing an agreement in 1996 which guaranteed Ethyl a dedicated portion of Octel\u2019s\nproduction to sell through Ethyl\u2019s distribution channels. Ethyl then ceased production at its Ontario plant. The two companies pro-\nclaimed that they would continue to compete with one another in the sale and marketing of lead antiknock compounds.\n\nOctel remained in the business for one reason: it was highly profitable. In 1994, Octel earned $240 million of operating profit\non sales of $520 million, a margin of almost 47 percent. All the rest of Great Lakes Chemicals earned $162 million on revenues of\n$1,480 million, a margin of 11 percent. Great Lakes used its profits from lead-based additives to make acquisitions, preparing for\nthe day when the lead business would be entirely gone.\n\nEthyl displayed a similar disparity between earnings in lead-based additives and everything else, even though it was largely a\nreseller of chemicals made elsewhere. Between 1994 and 1996, the additives accounted for 23 percent of the company\u2019s total sales\nand 63 percent of its profits. In 1998, after its additive revenues had declined to $117 million, it still made $51 million in operating\n\nprofits, a 44 percent return. The rest of the company had operating margins of 11 percent.\n\f"}, "003242.png": {"text": "How energetically Ethyl and Octel competed for the small business remaining was revealed in 1998 when the FTC reentered\nthe scene, charging that the arrangement the companies had reached violated antitrust laws. Octel and Ethyl settled with the\ncommission by agreeing to change some features of the original contract. Under the new arrangement, Ethyl could buy more than\na fixed portion of Octel\u2019s output and Octel would have to sell Ethyl all that Ethyl wanted to serve its current and new customers\nin the United States. Ostensibly this would increase competition between them, as would the other changes. The amount Ethyl\nwas charged would no longer be tied to Octel\u2019s retail price. The companies would no longer disclose their prices to one another.\nThe companies agreed to notify the commission in advance of any acquisition of assets used in the distribution of the compounds\nwithin the United States or manufacture anywhere in the world. Finally, there would also be prior notification of any proposed\nagreements with other competitors to sell them lead-based antiknock additives.\n\nIf it intended to protect American consumers, the FTC might have better looked elsewhere. Lead additives had virtually disap-\npeared from the U.S. market, and they were vanishing elsewhere in the world as well. And no provisions in this ruling would do\nmuch to guarantee vigorous competition. Neither Ethyl nor Octel was going to cut prices to secure a somewhat larger share of a\ndying but still lucrative business. Octel, with the world as its market, continued to enjoy high margins on sales (table15.2). After\na tough year in 2000, its operating income recovered even as its revenue declined. As Ethyl and Nalco before it, Octel used its cash\nflow from TEL (one of the lead-based additives) to expand its specialty chemicals business. Like them, its returns from specialty\nchemicals did not come close to what it was making in the lead additive business.\n\nOctel will be the last to leave. But like all the other producers that departed before it, it will make a graceful exit, at least as mea-\nsured by profitability. By cooperating with one another even while complying with antitrust laws, these companies experienced a\n\nlong history of turning lead into gold.\n\nTABLE 15.2\n\nOctel Corporation sales and operating income by segment, 2000-2002 ($ million)\n\f"}, "003243.png": {"text": "2000 2001 2002\n\nTEL\n\nSales $ 300 $ 265 $ 257\nOperating income $ 59 $ 69 $ 118\nMargins 20% 26% 46%\nSpecialty Chemicals\n\nSales $ 122 $ 156 $ 181\nOperating income $ 11 $ \u00ab13 $ \u00ab+10\nMargins 9% 8% 6%\n\nKEEP YOUR DISTANCE: SOTHEBY\u2019S AND CHRISTIE\u2019S TURN COOPERATION INTO A GENUINE PRISONER'S DILEMMA.\n\nFor all their heritage, prestige, and cachet, Sotheby\u2019s and Christie\u2019s, the two leading auction houses, were mediocre businesses.\n\nBy 1990 they dominated the auction markets for fine art and other expensive goods in Britain and the United States. They had\nsteadily encroached on the business of the art dealers by selling directly to collectors. Still, the volatility of the market for expen-\nsive paintings and the other luxury items that went under their hammers left the two houses vulnerable to the pain that a busi-\nness with high fixed costs feels when revenue shrinks. In 1974, in the aftermath of the oil embargo and recession, the two houses\nboth imposed a charge on buyers\u2014the buyer\u2019s premium\u2014where previously it was only the sellers who had paid. The auctioneers\nwere probably trying to help recycle some of the rapidly growing wealth in the hands of oil sheikhs from the Persian Gulf, who\n\nwere now in the market for trophy paintings.\n\f"}, "003244.png": {"text": "The buyer\u2019s premium gave Sotheby\u2019s and Christie\u2019s a new source of revenue and may have made it easier for them to compete\nwith one another by lowering the commission they charged to the sellers. And lower it they did. The tipsy art market of the late\n1980s sobered up starting in 1990. Japanese buyers for top pictures stopped bidding\u2014even stopped paying for works they had\nsupposedly bought\u2014the U.S. economy slowed, and the Gulf War made customers wary. The auction houses saw their business de-\ncline and turned to the oldest marketing ploy available: they cut prices.\n\nTo induce sellers to put their items up for auction, and to try to attract business from one another, Sotheby\u2019s and Christie\u2019s low-\nered their seller's commission, sometimes to zero. They also offered inexpensive advance loans on items to be auctioned during the\nnext round of sales. They started to print elaborate catalogs, often as a vanity inducement to the sellers. They gave lavish parties.\nThey even donated money to their sellers\u2019 favorite charities. None of these practices brought business back to where it had been in\n1989, and they certainly did nothing to improve the earnings of the houses (figure 15.2).\n\nWhen the going gets tough, the toffs get together. In 1992, Sotheby\u2019s changed the buyer\u2019s commission from a flat 10 percent of\nthe sale to a sliding amount that was intended to bring in more revenue. Seven weeks later Christie's followed suit. The timing is\ninteresting. By accounts offered to the courts, the first actual meetings between the heads of the two houses, A. Alfred Taubman\nof Sotheby\u2019s and Sir Anthony Tennant of Christie\u2019s, did not take place until 1993. Taubman, the shopping mall magnate who had\nserved as a white knight for Sotheby\u2019s in 1983, buying a controlling interest to keep it out of the hands of Marshall Cogan and\nSteven Swid, flew to London to meet Sir A., as he was identified in Taubman\u2019s records. According to the testimony of their respec-\ntive seconds, Diana D. (Dede) Brooks of Sotheby\u2019s and Christopher Davidge of Christie\u2019s, Taubman and Tennant directed Davidge\nand Brooks to work out details of an agreement under which the firms would not undercut one another on the commission rate\n\noffered to sellers.\n\f"}, "003245.png": {"text": "$500\n\n$400\n\n$300\n\n$200\n\n$100\n\n$0\n\n \n\nS100)\n\n \n\nmame Revenue\n\n\u2018Operating Income\n\nFIGURE 15.2\n\nSotheby\u2019s revenue and operating income, 1987-2002 ($million)\n\f"}, "003246.png": {"text": "In 1995, Christie\u2019s announced that it was changing its seller\u2019s fee from a flat 10 percent to a sliding scale, ranging from 2\npercent to 20 percent depending on the size of the sale. Over time, the arrangement came to include a \u201cno poaching\u201d clause on key\nstaff members and an accord not to subsidize the sellers by offering below market interest rates on loan advances. The companies\nalso shared their \u201cgrandfathered\u201d lists with one another, clients to whom they charged reduced or even zero fees. Neither was\nsupposed to pursue names on the other\u2019s list, nor to offer these same advantageous terms to people not on the lists. According to\nBrooks, Taubman wanted the houses to collude on the estimates they provided sellers as to the likely value of their art at auction,\nbut she told him that those decisions were made by the respective professional staffs of the two auction firms, who could not be\ncontrolled.\n\nRumors could not be controlled either. By 1997, it was widely known that the Justice Department was investigating the auction\nhouses for actions that violated antitrust laws. Perhaps Justice had been tipped off by customers who discovered, sometime in\nthe mid 1990s, that the firms would no longer offer lower commission rates and wondered how such solidarity might have been\nmaintained in the absence of collusion. Just before the end of 1999, Christopher Davidge cut a deal with the government. In ex-\nchange for no prison time for himself and other members of Christie\u2019s, he offered documents to prove the illegal behavior of Taub-\nman, Tennant, and their accomplices.\n\nIn 2000, the Justice Department pressured Diana Brooks to give up her former boss, Alfred Taubman, in exchange for a stay-\nout-of-jail card. She did her part, pled guilty, and in the end, Taubman was the only person to serve time. Sentenced to a one-year\nterm in 2001, he was released from prison after serving nine months. Each auction house paid a civil fine of $256 million, equal to\naround four years of Sotheby\u2019s average pretax profits in the years 1995-98. Sir Anthony Tennant always maintained his innocence,\nbut just to make sure, he stayed in England where he was safe from extradition on an antitrust violation.\n\nThe truly striking aspect of this story is how ineffective Christie\u2019s and Sotheby\u2019s were at cooperating to sustain profitability,\ndespite their illegal agreements. Profit margins at Sotheby\u2019s did grow between 1992 and 1996, as the art market recovered from\n\nits collapse in the early 1990s. After 1996, however, even as the art market improved, margins remained static. By 1998, with\n\f"}, "003247.png": {"text": "revenues at or near their precollusion 1989 peak, operating earnings at Sotheby\u2019s were only half their 1989 level. And with only a\nslight decline in 1999 sales, operating profits at Sotheby\u2019s fell by almost 50 percent.\n\nDavidge, his Christie\u2019s colleagues, and Diana Brooks may not have known how to play the cooperation game without violating\nantitrust laws, but they did know how to play the prisoner\u2019s dilemma game, at least in the first round. The New York Observer\ncommented about the prosecution, \u201cThey needed Mr. Davidge\u2019s notes and testimony to win conditional amnesty from the U.S.\ngovernment, under a controversial program in which the crook who squeals first in such a conspiracy gets off scot-free.\u201d Though\nscot-free may not always be part of the deal, the crook who squeals first always does better; otherwise, why would he or she squeal?\nThe more interesting question is what alternatives the two auction houses had to this illegal collusion as a way of ending a painful\nwar over price and perks.\n\nChristie\u2019s and Sotheby\u2019s, which together shared some 90-95 percent of the high-end auction market, should have been able to\nbenefit from economies of scale and significant customer captivity. Smaller and newer auction houses had made no inroads into\ntheir market share for many years. Also, at least until they entered their period of intense competition, both organizations were\nhighly profitable. The key to continued success was restraint on competition, which required primarily that they stay out of each\nother\u2019s way. Geographically, it was not really possible for two firms like these to divvy up territory. Each had major establishments\nin London and New York, as befits their British ancestry and the strength of the market in the United States. They also had satellite\noffices, and in some cases selling rooms, in major cities around the world. But these locations were more for acquiring material\nthan for auctioning it. For all expensive items, buyers come to the auction in the most cosmopolitan locations. So Sotheby\u2019s and\nChristie\u2019s both needed a presence in New York and London. In fact, they benefited from running their auctions almost simultane-\nously, because more buyers were enticed to make the trip to town.\n\nWith geography an unwieldy knife with which to slice the pie, field specialization\u2014product market niches\u2014remained the ob-\nvious choice by which to divide the business. Instead of selling everything from Cycladic figures and ancient Sumerian pottery to\n\npaintings by Roy Lichtenstein and Keith Haring, each house could have concentrated on particular periods and types of art. They\n\f"}, "003248.png": {"text": "could also have selected specialties from the broad range of other objects offered for sale, like antique Persian carpets, jewelry, and\nclocks and barometric measuring devices from the age of Louis XIV.\n\nThe auction houses handled such a variety of goods that, in theory at least, staking out a set of nonconflicting claims to\nterritory should have been fairly simple. Each field required overhead to support it, particularly the experts who validate claims\nabout authenticity, research provenance, and estimate a value for the item. If Sotheby\u2019s had become the place to go for eighteenth-\ncentury French paintings and decorative arts, and Christie\u2019s had emerged as the dominant firm for color field abstraction, then\nsellers would have had to choose an auction house on the basis of what they were trying to sell. A further advantage of such spe-\ncialization would have been a significant reduction in overall overhead costs, since substantial duplication of effort would have\nbeen eliminated.\n\nThere were two problems that would have made this type of division more difficult to accomplish in practice than on paper.\nFirst, estate sales may encompass a variety of works that don\u2019t fit neatly into any single auction house's specialization. Second,\nwhile Dutch master paintings from the seventeenth century may bring more at auction than Postimpressionist works, there are\nmany fewer of them outside of museums. So a fair division of the playing field needed to focus on the value to the auction house\nof a piece of the turf, not its attractiveness on any other basis. Despite these difficulties, it may have been possible for the firms to\nwork out an informal and tacit arrangement without colluding directly.\n\nIn 1992, before the first reported meetings of Taubman and Tennant, Sotheby\u2019s announced an increase in fees charged to\nbuyers, and Christie\u2019s came along after a decorous delay of seven weeks. Could Sotheby\u2019s have also announced that it was deem-\nphasizing its Egyptian and ancient Middle Eastern departments, and concentrating instead on Greek and Roman antiquities and\nthe period to AD 1200 in Europe? Christie\u2019s might have announced, some time later, that it was going strengthen its Egyptian\ndepartment and also its expertise in the early Renaissance. And, over time and more subtly than we are describing here, the two\nmight have divided up the map of the fine art and object markets like the European imperialists carved up Africa in the nineteenth\n\ncentury, hopefully to better effect. The estate sale issue would have been handled naturally, leaving it up to the executors to decide\n\f"}, "003249.png": {"text": "among the auction houses on the basis of their respective strengths. And nothing says that the estate property could not have been\n\nsold ina series of auctions.\n\nThe contrast between the histories of Nintendo and the auction houses, on the one hand, and the lead-based gasoline additive\nindustry on the other clearly points up the benefits of effective cooperation among firms. Just as clearly, it underscores the perils\nof inexpert cooperation that crosses the legality line. A well-formulated strategy will not immediately or solely look to salvation\nthrough cooperation. But the story of the lead-based additive industry demonstrates how useful a cooperative perspective can be\n\nunder the right conditions. The optimum situation is an industry where several firms coexist within well-established barriers.\n\f"}, "003250.png": {"text": "CHAPTER 16\n\nValuation from a Strategic Perspective\n\nImproving Investment Decisions\n\nSTRATEGY AND VALUE\n\nEven though investment decisions are generally strategic by anyone\u2019s definition of the term, the financial analysis employed to\nsupport these decisions generally ignores strategic issues. It is almost always built around calculations of future cash flows, both\nnegative during the investing phase and positive during the harvesting period, created by the investment. The cash flows are then\ndiscounted by an appropriate cost of capital, and all the cash flows added together produce the net present value of the investment.\nThe cash flows themselves are based on estimates of future sales, profit margins, tax rates, capital investment requirements,\nand the cost of capital. Underlying them are another set of estimates regarding market size and growth rates, attainable market\nshares, gross margins, overhead expense ratios, working and fixed capital requirements, leverage (debt to equity ratios), and the\n\ncosts of the components of the overall capital structure (cost of debt and cost of equity). Many of these variables, especially market\n\f"}, "003251.png": {"text": "share, margins, overhead expenses, and capital requirements, will depend on the intensity of future competition. But it is difficult\nto forecast precisely how competition will affect each of them. Moreover, competitive conditions do not influence these variables\nindependently; the intensity of competition affects many of them simultaneously.\n\nGiven these difficulties, it is not surprising that strategic insights are rarely integrated effectively into the investment decision\nprocess. Yet omitting an examination of the competitive environment simply because it cannot be neatly incorporated into a\nfinancial model ignores crucial information and impairs the quality of the analysis. The strategic perspective developed in this\nbook, particularly the emphasis on competitive advantages and barriers to entry, provides an alternative framework for invest-\n\nment planning that is in many ways superior to the net present value approach.\n\nTHE VALUE OF NET PRESENT VALUE\n\nThe core of any investment planning process is a method for ranking projects by their value to decide where capital should be\ndirected. The method ought to include the ability to value an entire company, since the purchase of a company is itself a potential\nproject. In theory, the correct value of a project is the value of future benefits discounted at an appropriate cost of capital, minus\nthe value of future costs, usually discounted at the same cost of capital. The result is mathematically equal to the value of the\npresent and future net cash flows appropriately discounted, the familiar net present value (NPV) of financial analysis. The problem\nis that although the method is true in theory, it is seriously flawed when put into practice.\n\nThe NPV approach has three fundamental shortcomings. First, it does not segregate reliable information from unreliable infor-\nmation when assessing the value of a project. A typical NPV model estimates net cash flows for several years into the future from\nthe date at which the project is undertaken, incorporating the initial investment expenditures as negative cash flows. Five to ten\nyears of cash flows are usually estimated explicitly. Cash flows beyond the last date are usually lumped together into something\n\ncalled a \u201cterminal value.\u201d A common method for calculating the terminal value is to derive the accounting earnings from the cash\n\f"}, "003252.png": {"text": "flows in the last explicitly estimated year and then to multiply those earnings by a factor that represents an appropriate ratio of\nvalue to earnings (i.e., a P/E ratio). If the accounting earnings are estimated to be $12 million and the appropriate factor is a P/E\nratio of 15 to 1, then the terminal value is $180 million.\n\nHow does one arrive at the appropriate factor, the proper price to earnings ratio? That depends on the characteristics of the\nbusiness, whether a project or a company, at the terminal date. It is usually selected by finding publicly traded companies whose\ncurrent operating characteristics resemble those forecast for the enterprise in its terminal year, and then looking at how the se-\ncurities markets value their earnings, meaning the P/E at which they trade. The important characteristics for selecting a similar\ncompany are growth rates, profitability, capital intensity, and riskiness.\n\nDespite the apparent precision, this approach is largely conjecture. Calculating the characteristics of an enterprise seven and\nmore years in the future is a very inexact exercise. Also, precise comparisons between enterprises rarely exist, so the selection of\ncomparison companies is subjective. Rolling dice to come up with an appropriate valuation factor seven years hence would be\nabout as precise.\n\nAn alternative to the ratio valuation approach is to assume that the project stabilizes after the end of the terminal year.\nProfitability, capital intensity, risk\u2014and hence the cost of capital\u2014and most importantly, annual growth in sales, profits, and in-\nvestment are all assumed to stay constant beyond the terminal year. By making these assumptions, it is possible to calculate a cash\nflow for the first postterminal year, that is, year eight if year seven is the terminal year. Then the present value of all postterminal-\n\nyear cash flows can be calculated from a familiar formula, namely\nTerminal Value=CF,,, + (R-G)\n\nwhere CF;,.; is the net cash flow in the first postterminal year, R is the cost of capital beyond the terminal year, and G is the annual\n\ngrowth rate for the same period (table 16.1).\n\f"}, "003253.png": {"text": "Since this terminal value measure consists of a cash flow figure (CF;, 1) multiplied by a valuation factor (1/(R-G), itis actually a\nversion of the factor-based approach (using a P/E) just described. While it does have the advantage of making explicit the assump-\n\ntions underlying the valuation factor, a closer look reveals just how inexact a factor-based approach can be.\n\nTABLE 16.1\n\nCash flows and terminal value\n\nYear 1 2 3 4 5 6 7 (terminal) 8 and beyond\n\n\u2018Cash flow explicit explicit explicit explicit explicit explicit explicit year 7 plus\ngrowth\n\nValue measure NPY NPV NPV NPV NPY NPV NPV CF,,,+(R-G)\n\n(Net Present\nValue of this\ncash flow)\n\nSuppose the projected net cash flow for year eight, the first year after the last explicit cash flow estimate, is $120 million. The\nprojected cost of capital going forward is 10 percent, and the projected growth rate after year seven is 6 percent. Then the terminal\nvalue of the enterprise, capturing the contribution of the cash flows from year eight forward, is $3 billion ($120 million + (0.10 -\n0.06)).: This is a simple calculation. But if the estimates of the cost of capital and the growth rate for these years are each off by 1\npercent, which is not a large error, then the terminal value could be as high as $6 billion ($120 million + (0.09 - 0.07)) or as low as\n$2 billion ($120 million = (0.11-0.05)). This three-to-one range of plausible terminal values represents the level of uncertainty\n\nthat applies to these calculations in practice.\n\f"}, "003254.png": {"text": "This wide range of plausible values has unfortunate implications for the use of NPV calculations in making investment deci-\nsions. Experience indicates that, except for the simplest projects focused on cost reduction, it is the terminal values that typically\naccount for by far the greatest portion of any project\u2019s net present value. With these terminal value calculations so imprecise, the\nreliability of the overall NPV calculation is seriously compromised, as are the investment decisions based on these estimates.\n\nThe problem is not the method of calculating terminal values. No better methods exist. The problem is intrinsic to the NPV\napproach. An NPV calculation takes reliable information, usually near-term cash flow estimates, and combines that with unreli-\nable information, which are the estimated cash flows from a distant future that make up the terminal value. Then, after applying\ndiscount rates, it simply adds all these cash flows together. It is an axiom of engineering that combining good information with\nbad information does not produce information of average quality. The result is bad information, because the errors from the bad\ninformation dominate the whole calculation. A fundamental problem with the NPV approach is that it does not effectively segre-\ngate good from bad information about the value of the project.\n\nAsecond practical shortcoming of the NPV approach to valuation is one to which we have already alluded. A valuation proce-\ndure is a method for moving from assumptions about the future to a calculated value of a project which unfolds over the course of\nthat future. Ideally, it should be based on assumptions about the future that can reliably and sensibly be made today. Otherwise,\nthe value calculation will be of little use.\n\nFor example, a sensible opinion can be formed about whether the automobile industry will still be economically viable twenty\nyears from today. We can also form reasonable views of whether Ford or any company in the industry is likely, twenty years in the\nfuture, to enjoy significant competitive advantages over the other automobile manufacturers (not likely). For a company such as\nMicrosoft, which does enjoy significant competitive advantages today, we can think reasonably about the chances that these ad-\nvantages will survive the next twenty years, whether they will increase, decrease, or continue as is.\n\nBut it is hard to forecast exactly how fast Ford\u2019s sales will grow over the next two decades, what its profit margins will be, or\n\nhow much it will be required to invest per dollar of revenue. Likewise, for a company like Microsoft, projecting sales growth and\n\f"}, "003255.png": {"text": "profit margins is difficult for its current products and even more difficult for the new products it will introduce over that time. Yet\nthese are the assumptions that have to be made to arrive at a value based on NPV analysis.\n\nIt is possible to make strategic assumptions about competitive advantages with more confidence, but these are not readily\nincorporated into an NPV calculation. Taken together, the NPV approach\u2019s reliance on assumptions that are difficult to make and\nits omission of assumptions that can be made with more certainty are a second major shortcoming.\n\nA third difficulty with the NPV approach is that it discards much information that is relevant to the calculation of the economic\nvalue of a company. There are two parts to value creation. The first is the resources that are devoted to the value creation process,\nthe assets that the company employs. The second part is the distributable cash flows that are created by these invested resources.\nThe NPV approach focuses exclusively on the cash flows. In a competitive environment, the two will be closely related. The assets\nwill earn ordinary\u2014cost of capital\u2014returns. Therefore, knowing the resource levels will tell a good deal about likely future cash\nflows.\n\nBut if the resources are not used effectively, then the value of the cash flows they generate will fall short of the dollars invested.\nThere will always be other firms that can do better with similar resources, and competition from these firms will inevitably pro-\nduce losses for the inefficient user. Even firms efficient in their use of resources may not create excess value in their cash flows, so\nlong as competition from equally efficient producers whittles away those excess returns. The crucial point is that in a competitive\nenvironment, resource requirements carry important implications about likely future cash flows, and the NPV approach takes no\nadvantage of this information.\n\nAll these criticisms of NPV would be immaterial if there were no alternative approach to valuation that met these objections.\nBut in fact there is such an alternative. It does segregate reliable from unreliable information; it does incorporate strategic judg-\nments about the current and future state of competition in the industry; it does pay attention to a company\u2019s resources. Because\nthis approach has been developed and applied by investors in marketable securities, starting with Benjamin Graham and contin-\nuing through Warren Buffett and a host of others, we will describe this alternative methodology in the context of valuing a com-\n\npany as a whole. Later we will show how the same basic valuation approach applies to other kinds of investment projects.\n\f"}, "003256.png": {"text": "ASTRATEGIC APPROACH TO VALUATION\n\nFIRST CUT: ASSETS\n\nThe most reliable information for valuing a company is the information on its balance sheet. Both the assets and the liabilities\nexist in the present and can in principle be inspected at any moment, even if they are intangible. Placing a value on them generally\nrequires no projection of future developments. For some of the balance sheet items, most obviously cash and marketable securities\non the asset side and short-term debt on the liabilities side, there is no uncertainty about their worth. For other items, the valua-\ntion is more involved. Still, the process of valuing assets and liabilities, even where judgments need to be made, is informative.\n\nThe first important judgment is whether the product market in which the company operates will be economically viable going\nforward. In the case of Ford, the question is whether the global automotive industry is likely to exist for the foreseeable future. If\nthe answer is no, then the value of Ford\u2019s assets is their liquidation value. Accounts receivable and inventory will have to be writ-\nten down from their balance sheet levels. The discount will be small for accounts receivable, since they are largely recoverable in\nliquidation. For inventories, the discount will be larger, since some items may be obsolete and worth little. The value of plant, prop-\nerty, and equipment (PPE) for a nonviable industry will depend on whether they are specific to the industry or general purpose.\nIndustry-specific PPE will be worth only its scrap value. General-purpose PPE, such as office buildings, will usually trade in active\nsecondhand markets, and these market values should be realized in liquidation. Intangibles, like brands, customer relationships,\nand product portfolios, will have limited or no value in liquidation. The liabilities must be subtracted from the value of the assets,\ngenerally at full value, since in any liquidation short of bankruptcy, they must be fully paid off.\n\nOn the other hand, if the industry is viable, then the assets employed will have to be reproduced at some point, and they should\nbe valued at reproduction cost. The reproduction cost of an asset is the cost of reproducing its economic function as efficiently as\n\npossible. For cash and marketable securities, there is no discrepancy between reported value and reproduction cost. For accounts\n\f"}, "003257.png": {"text": "receivable, the reproduction cost will actually be slightly higher than accounting book value. Receivables are essentially loans to\ncustomers generated by sales made in the normal course of business, and some of the loans will not be repaid.\n\nThe reproduction value of inventory is the cost of producing equivalent amounts of salable inventory, which may be higher or\nlower than the book figure, depending on whether LIFO or FIFO accounting is being used, and on the trends in production costs.\nFor PPE, the reproduction value is the cost of producing equivalent facilities from the cheapest source, either newly created or sec-\nondhand. Calculating this figure requires substantial industry knowledge, but it does not depend on projecting future cash flows.\n\nFinally, for a viable industry, intangibles like customer relationships, organizational development, workforce acquisition and\ntraining, and product portfolios will have positive reproduction costs.: These can be calculated by developing scenarios for pro-\nducing them efficiently. For example, the cost of a product portfolio is the R&D expenditure necessary to produce from scratch\nand make ready for sale an equivalent set of products. There may be private market transactions, in which a sophisticated buyer\npurchases intangibles for cash, that can be helpful in determining the reproduction value. For example, when a record company\nbuys an independent label with its stable of recording artists, or when a major drug company buys a start-up firm with a promis-\ning product, or when a cable company buys a local cable system with its customer contracts, a reproduction value has been put on\nthese intangible assets.\n\nCalculating the reproduction value of the assets of a firm in a viable business, just like establishing the liquidation value, does\nnot require projections into the future. The necessary information is all currently available. Also, in working down the balance\nsheet, the estimates of value move from the most certain (cash and marketable securities) to the least certain (the intangibles).\nThese distinctions are important; a valuation in which intangibles like brand equity are a significant part of the whole is less\ntrustworthy than one in which cash, receivables, and general-purpose PPE represent most of the total value. Finally, assets further\ndown the balance sheet require more industry expertise to calculate their reproduction values. But this expertise is no greater\nthan what is necessary to make any informed investment decision in the industry in question.\n\nThe merit of incorporating strategic analysis into the valuation process becomes apparent when we look at a company in an\n\nindustry without incumbent competitive advantages. Suppose, as an example, that the reproduction value of Ford\u2019s assets is $40\n\f"}, "003258.png": {"text": "billion. These assets are currently generating a cash flow of $8 billion per year. At a cost of capital of 10 percent, usually a reason-\nable assumption, the cash flow is worth $80 billion, twice the reproduction costs of the assets. This discrepancy is an open invi-\ntation. Under these conditions, an entrant into Ford\u2019s market or, more likely, another auto company seeking to expand, can create\n$80 billion in value for a $40 billion investment. With no barriers to stand in its way, the entrant makes the investment and moves\nin. But now, with more competition, the earnings begin to decline, both for Ford and for the newcomer. If they drop to $6 billion\nfor Ford, reducing the value of the investment to $60 billion, that is still sufficiently enticing for other firms to join. Only when\nthe value of future earnings has been driven down to the reproduction cost of $40 billion will the process of entry cease and the\nprofitability of the industry stabilize. In industries with no barriers to entry, competition will eventually make the reproduction\n\nvalue of the assets equal to the value of future earnings.\u201d\n\nSECOND CUT: CURRENT EARNINGS POWER VALUE\n\nAfter the assets and liabilities, the second most reliable piece of information for determining the value of a company is the cash\nflow the company can distribute over the near term. The source of this information is the current and recently reported earnings\nand cash flow statements. These returns represent only a small fraction of the company\u2019s value, but they can be used to answer\nan important question: If this level of net cash flow were to be sustained forever, neither growing nor shrinking, what would the\ncompany be worth? This figure is based on accounting information, which is relatively solid. It does call for extrapolation into an\nuncertain future, so it is less reliable than an asset-based valuation. But because it assumes no growth, it is less uncertain than\nstandard NPV calculations. We will refer to this second approach to valuation as an earnings power value. As we shall see, compar-\ning earnings power value with the reproduction costs of the assets sheds light on the competitive position of the firm in its market.\nThe starting point in determining the earnings power value of a company is the current net cash flow. Ideally, this number\nshould equal reported earnings, but because of accrual accounting, there is almost always a discrepancy between them. Also, for a\n\nvariety of transitory reasons, even current cash flow may differ from the sustainable average cash flow that can be extracted from\n\f"}, "003259.png": {"text": "a company\u2019s current operating situation. Therefore, to move from reported earnings to sustainable distributable earnings\u2014what\nwe are calling \u201cearnings power\u201d\u2014requires a number of adjustments. None of them are particularly challenging, but they may look-\ning daunting to people who have not spent much time reading financial statements.\n\nFirst, in order to eliminate the effects of financial leverage\u2014how much debt the company carries as a percentage of its assets\u2014\nthe place to begin is with operating earnings (EBIT\u2014earnings before interest and taxes), rather than net earnings. This allows us to\ndisregard both the interest payments a company makes and the tax benefits it gets from using debt financing.\n\nSecond, what are euphemistically called \u201cnonrecurring items\u201d have to be incorporated into the calculation. In an ideal world,\nthese charges would be infrequent, equally divided between positive and negative changes, and would not affect long-term\nsustainable earnings. But in the practice of some companies, the charges are frequent, they are overwhelmingly negative, and they\ncram into single years losses that have been incurred over many prior years and may be incurred in future years. Rather than one-\ntime, truly nonrecurring events, they are often attempts to enhance the perceived level of \u201cnormal\u201d earnings by collecting mis-\ntaken initiatives and segregating them into what management hopes will be dismissible lumps. A sensible way to treat them when\nthey appear regularly is to calculate their average level over a period of years, either in dollar terms or relative to sales, and to sub-\ntract this average level from the more recently reporting operating earnings before charges.\n\nThird, after eliminating these accounting manipulations, current earnings must be adjusted to account for any cyclical varia-\ntion that may cause them to be either above or below their sustainable level. There are a number of ways to make the adjustment.\nThe simplest is to calculate the average operating margins (EBIT divided by sales) over a period of years and then apply that aver-\nage margin to current sales to derive a current operating earnings level. Margins tend to fluctuate more severely over the business\ncycle than do sales. However, if sales are also sensitive to the cycle, they too should be adjusted to an average level.\n\nFourth, accounting depreciation as calculated for the financial statement may diverge widely from true economic depreciation.\nEconomic depreciation should equal the amount that needs to be spent in the current year to return a firm\u2019s capital stock at the\nend of the year to where it was at the start of the year. This figure is maintenance capital expense; it omits capital expenditures for\n\ngrowth. It depends on current prices of plant and equipment. Accounting depreciation relies on historical costs and conventional\n\f"}, "003260.png": {"text": "rules based on the rates at which plant and equipment have historically had to be replaced. Since equipment prices have been de-\nclining in recent years and accounting depreciation measures usually overstate the rate at which structures wear out, accounting\ndepreciation should generally exceed the actual expense required to maintain the capital stock (maintenance capital expense). The\ntypical adjustment will increase reported earnings. In contrast, in the inflationary environment of the late 1970s and early 1980s,\nhistorical costs were below replacement costs, and the typical adjustment reduced reported earnings.\n\nFifth, special circumstances may call for further adjustments: a consolidated subsidiary may be included as a reported share of\nequity earning rather than actual cash flow in potential earnings; a division\u2019s management may be insensitive to pricing opportu-\nnities, leaving its current earnings below its potential because of unexploited pricing power; a money-losing operation that could\nbe closed down may conceal the true extent of sustainable earnings in the rest of a company.\n\nFinally, taxes charged for accounting purposes may vary widely from year to year. The pretax operating earnings adjusted as\nindicated here should be converted to after-tax earnings using an average sustainable tax rate. The result of all this effort should be\na figure representing what a company without debt could repeatedly earn, after taxes, based on its most recently reported results.\nThis is the earnings power of a company, the amount of cash that it can distribute to its owners each year without impairing the\nproductive assets of the firm.\n\nEarnings power is an annual flow of funds. To convert it into earnings power value (EPV), which is the present value of all those\nflows in the future, the first step is to divide earnings power by the cost of capital. The cost of capital should be calculated as the\nweighted average of the cost of debt capital, after tax, and the cost of equity capital. It represents what the firm has to pay to in-\nvestors each year to attract the necessary investment voluntarily. The weighted average cost is the after-tax cost of debt capital\ntimes the fraction of capital raised through debt plus the after-tax cost of equity capital times the fraction raised through equity.\nThe sustainable ratio of debt to total capital should be the lower of two figures: either the amount of debt the firm can carry on\naverage without seriously impairing its operating performance, or the firm\u2019s historical average debt level. Because of the lower cost\n\nof debt financing due to the tax savings, the preferred figure is the first one. But if the management does not care to capture this\n\f"}, "003261.png": {"text": "advantage now or in the foreseeable future, then management\u2019s actual behavior is the relevant figure for calculating the average\ncost of capital.\n\nTo illustrate the process, consider a company with reported after-tax current earnings of $100 million. After adjustments, this\nfigure is raised to an after-tax earnings power of $135 million per year. The company is financed one-third by debt and two-thirds\nby equity. It pays 9 percent interest on its debt. The cost of its equity is 10.8 percent (that is the observed return on equity invest-\n\nments of comparable risk). With a tax rate of 40 percent, the weighted average cost of capital (R) is 9 percent:\nR=(1/3 x [9% x (1-40%)] + (2/3 x 10.8%)=9%\nWith a cost of capital of 9 percent, the earnings power value of the firm is $1.5 billion:\nEPV=$135 million = 0.09=$1.500 million\n\nThis represents the value of the ongoing operations of the firm, assuming no growth or deterioration in the future.:\n\nThe EPV calculated here is that of the firm as a whole. The value of the equity is this total value less the value of the firm\u2019s\noutstanding debt. Using the asset approach, the comparable value of the entire firm is the value of the assets, either liquidation or\nreproduction value, less the nondebt liabilities, such as accounts payable and accruals. The value of the equity is this figure minus\nthe debt liabilities. The reason for focusing on the overall firm rather than just the equity value is that the estimate for the entire\nfirm is more reliable, especially when the firm has a high level of debt.\n\nBecause growth has been excluded from this valuation, and because it uses current cash flow, not cash flow five to ten years\ninto the future, the EPV is far less subject to error than valuations dependent on establishing a terminal value some eight or ten\nyears in the future. A 1 percent error in estimating the firm\u2019s cost of capital will lead to a range of EPV values from $1,700 million,\nif the cost of capital is 8 percent, to $1,350 million if it is 10 percent. This is much narrower than the potential range of error using\n\nthe terminal value estimate which includes a rate of growth.\n\f"}, "003262.png": {"text": "However, if the concern is only with the equity value of the firm, then those errors can be greatly magnified. Suppose that the\nerror range on the EPV of the firm as a whole is plus or minus $150 million around the mean estimate of $1,500 million. This is\nplus or minus 10 percent, a small number as these things go. But if the firm has debt of $1,200 million, whose value is relatively\ncertain, then the entire $150 million error applies to the value of the equity, whose base level is now $300 million ($1,500 million\nless $1,200 million in debt). This is an error range of plus or minus 50 percent, which makes the estimate highly uncertain.\n\nTo understand fully the effect of leverage on risk, it is best to start with the overall enterprise value and then adjust from there\nto see the impact on the value of the equity portion. In what follows, therefore, the asset values and EPV will refer to the enterprise\n\nas a whole.\n\nPUTTING ASSETS AND EARNINGS TOGETHER: FRANCHISE VALUE\n\nLeaving aside the question of growth, assets and earnings powers value are two distinct ways to estimate the value of a firm. A\ncomparison between them can result in three possible configurations: EPV exceeds asset value; they are essentially equal; asset\nvalue exceeds EPV. Each configuration has strategic implications.\n\nIf the EPV exceeds the asset value, that means that the current level of enterprise earnings power is creating value in excess of\nthe reproduction cost of the assets. As we have seen, if there are no barriers to entry, newcomers attracted by these high returns\nwill enter the industry and continue to enter until the opportunity for value creation has been eliminated by competition. Un-\nless there are barriers to entry, an EPV that exceeds the reproduction cost of the assets cannot be sustained. Therefore, the only\ninstances in which properly calculated EPVs do exceed asset values are situations in which there are barriers to entry and incum-\nbents do enjoy identifiable and sustainable competitive advantages.\n\nThe difference between the asset value and the EPV is precisely the value of the current level of competitive advantages. We will\ncall it the \u201cfranchise value\u2019\u2014the excess return earned by the firm with competitive advantages. Whether a particular franchise\n\nvalue is sustainable, and thus whether the EPV is the appropriate measure of total value, can be judged from the size of the fran-\n\f"}, "003263.png": {"text": "chise value relative to sales, assets, and the competitive advantages at work. Clearly, the greater the franchise value, the more pow-\nerful must be the competitive advantages that create and are necessary to sustain it.\n\nConsider as an example a company with an asset value at reproduction cost of $1,200 million, an earnings power of $240\nmillion after tax, sales of $1,000 million, and a cost of capital of 10 percent (table 16.2). The EPV of this firm is $2,400 million. An\nentrant needs to earn $120 million after tax to cover its cost of capital ($1,200 million x 10 %). The excess return that must be\ndefended by competitive advantages, which is the franchise value, is $120 million after tax ($240 million current earnings minus\n$120 million competitive earnings). Since the after-tax income is 60 percent of pretax income, then the advantage comes to $200\nmillion pretax ($120 million + (1-.40%)). This amounts to a pretax margin on sales of 20 percent above the competitive margin\n($200 million = $1,000 sales).\n\nTABLE 16.2\n\nCalculating the franchise margin ($ million)\n\nAsset value $1,200\nSales $1,000\nEarnings power $240\nCost of capital 10%\nEPV (earnings power divided by cost of capital) $ 2,400\nTax rate 40%\nCompetitive earnings $120\n\nFranchise earnings (earnings power minus competitive earnings) $120\n\nPretax franchise earnings ($120 = (1-40%)) $200\n\f"}, "003264.png": {"text": "Franchise margin on sales ($200 + $1,000) 20%\n\nTo justify an EPV of $2,400 million, the firm must benefit from a combination of competitive advantages in higher prices due\nto customer captivity and lower costs due to either proprietary technology or economies of scale equal to 20 percent of sales. The\nvaluation decision\u2014whether to use the value of the assets or the value of the earnings power\u2014comes down to a strategic judg-\nment of whether the enterprise enjoys competitive advantages of this magnitude. Being able to compare the asset value to the EPV\nallows us to place the focus of the valuation decision directly and simply in the strategic arena, which is where it belongs.\n\nThe second possibility stemming from the comparison of asset value to EPV is that they are approximately equal. This is what\nwould be expected in the majority of industries where no firm enjoys significant competitive advantages. If an analysis confirms\nthat market share is unstable, that no firms are earning extraordinary returns on capital, and that there are no identifiable sources\nof competitive advantage, then we have an uncontested estimate of value, based on both the resource and the income method of\nvaluation, confirmed by strategic judgment. This figure is a much more reliable fix on the value of a firm than an NPV analysis\nalone.\n\nThe final possibility is that the asset value exceeds the EPV of the enterprise. Provided that both valuations have been done\nproperly, and that, for instance, the reproduction value of the assets was not used if the liquidation value was called for, then\nthe only possible source of this discrepancy is deficient management. The management is not producing returns commensurate\nwith the value of the assets being put to work. In this case, the strategic approach points to the critical question for evaluating the\ncompany, namely, what can be done either to improve or to replace management. The NPV approach is not likely to raise this issue,\n\nwhich points to a further shortcoming of this standard method of valuation.\n\nTHIRD CUT: THE VALUE OF GROWTH\n\f"}, "003265.png": {"text": "It is now time to integrate the effects of growth into this strategic valuation framework, by identifying the situations in which\n\ngrowth is bad, when it is neutral, and when it is good.\n\nWhen Growth Is Bad\n\nIn the last situation described, the one in which the asset value is higher than the EPV, growth will make things worse. Growth is\nsimply one way in which resources are put to work. The management is doing a poor job utilizing the resources it currently has.\nSuppose this management were to invest $100 million either in a new enterprise or to expand the current one. The cost of capital\nis 10 percent, which represents what, on average, that capital will earn elsewhere in projects of equal risk. If past performance is\nany guide, management will earn less than 10 percent on its investments. Without competitive advantages it will certainly not\nearn more. Suppose that management earns 8 percent on the $100 million, or $8 million per year. Since the capital cost is $10 mil-\nlion per year, paid to the new investors who put in the $100 million, the net benefits of the underlying growth to the old investors\nis a negative $2 million. So the first important fact about growth is that in the hands of poor management, or at a competitive\ndisadvantage, growth destroys value. In these circumstances, the more energetic the management in pursuing growth, the more\n\nvalue it will destroy.\n\nWhen Growth Is Neutral\n\nIn the second situation, where asset value equals EPV and strategic analysis confirms the absence of competitive advantages,\ngrowth neither creates nor destroys value. The company earns an average return, which is the cost of capital, and its return on\ngrowth will be the same. On the $100 million in new capital, it will return $10 million, all of which will go to the new investors\nwho have provided that capital, and there will be nothing left over for the existing owners. Its operating income goes up by $10\nmillion, but all of that goes to pay for the capital required. Growth on a level playing field, like entry into a market without compet-\n\nitive advantages, neither creates nor destroys value. In this case, leaving growth out of the valuation is entirely appropriate.\n\f"}, "003266.png": {"text": "When Growth Is Good\n\nOnly growth in the presence of existing competitive advantages creates value. This is the first situation described above, where\nEPV exceeds asset value and in which there are identifiable and sustainable competitive advantages. In this case, the return on the\n$100 million invested will exceed the annual cost of $10 million, leaving something for the old shareholders. If the reproduction\ncost of the assets is the first tranche of value, and the earnings power is the second tranche, then the value of growth is the third\ntranche (figure 16.1). Although a full NPV analysis can be useful in \u201cgrowth is good\u201d situations, to estimate the value of the enter-\nprise including growth, the strategic approach is even more essential. It highlights the one element that makes growth valuable,\nwhich is the existence of sustainable competitive advantages in a growing market. It also organizes the final value measure into\ntranches of increasing uncertainty.\n\nIn \u201cgrowth is good\u201d situations, the value of the assets may be small relative to the value including growth, but it does represent\nthe value that will endure if the competitive advantages evaporate and the barriers to entry come down. The second tranche, the\nexcess of earnings power value over asset value, represents the value of current competitive advantages without growth; this is\nthe next most reliable piece. The value of the growth is the most uncertain, both because it requires projections into the future and\n\nbecause it depends upon the ability to grow within a franchise, which is difficult.\n\f"}, "003267.png": {"text": "Valueof Growth\nOnly # the growth benefis \u2018TRANCHE?\ncompari re\n\nFranchise Value\nFranchise value from\n\nReproduction Costof Assets\n\nFree entry\nNe comperitve\n\n \n\nASSET VALUE EARNINGS TOTAL VALUE\nPOWERVALUE\n\nFIGURE 16.1\nThree tranches of value\n\f"}, "003268.png": {"text": "The strategic approach also provides insight into the possible magnitude of that growth. Since one of the distinguishing fea-\ntures of an industry with barriers to entry is stable market shares for the incumbents, then the growth of the individual firm will\neventually be limited to the growth of the industry. In many cases it may be easier to assess the growth rate for an industry than\nfor a single firm. Sometimes, however, the growth rate of the industry, say for microprocessors or PC software, may be highly un-\n\npredictable. In these cases, assigning a reliable value to the incumbents like Intel and Microsoft is simply impossible.\n\nCONCLUDING THOUGHTS ON VALUATION\n\nThe strategic approach to valuation\u2014asset value, earnings power value, assessment of competitive advantages, and the value of\ngrowth\u2014has been applied here to decisions to invest in a company as a whole. Such decisions pertain chiefly to financial market\ninvestments, whether by firms or individuals. This method of valuation has been developed primarily by generations of value\ninvestors, beginning with Benjamin Graham and David Dodd and continuing through people like Walter Schloss, Warren Buffett,\nMario Gabelli, and Seth Klarman.: Their successful records over long periods of time is part of the argument in favor of this\nmethod. For securities investments, there is an additional dimension that these investors bring to the process. When they have\nidentified a stock that their valuation indicates is selling for less than its actual economic value, they require a sufficient margin\nof safety, in Benjamin Graham\u2019s famous phrase, which is the size of the gap between the market price and the fundamental value.\nFor acompany in a competitive industry, that margin has to lie in the difference between the market price and the asset value.\nFor companies that do enjoy a sustainable competitive advantage, the difference may lie between the market price and the EPV,\ncertainly if the market price is not more than the asset value. In this situation, the value of the franchise would be the margin of\nsafety. And for those rare companies that can grow profitably, the value of the growth might provide the margin, so long as the\nshares are selling for no more than the value of the current earnings power. So strategic analysis is at the core of their investment\n\nmethod.\n\f"}, "003269.png": {"text": "FROM COMPANIES TO PROJECTS\n\nThe same method for valuation applies to investment projects on a scale smaller than entire companies. The strategic issues still\ndominate. The first step is to segregate the early investments, which create assets, from the subsequent income flows. The former\nconstitute the asset value of the project; the latter are the earnings power value, including growth. Any excess of EPV over asset\nvalue must be justified by identifying sustainable competitive advantages. Optimistic growth and margin assumptions incor-\nporated into a highly uncertain terminal value are not dependable. If no clear competitive advantages can be identified, then no\nmatter how rapid the growth forecast, it will not affect the value of the project. A business case analysis under these circumstances\nthat simply assumes no further growth once a project reaches maturity will generally provide a better valuation measure for in-\nvestment decisions than a fully developed but error-prone NPV.\n\nWithout competitive advantages, investments will generally return the cost of capital, meaning they will not add any value for\nthe existing owners. This is as true for projects like expansions into new territory and the development of new product lines as it is\nfor entire companies. The only exceptions come from superior management, which can use resources more efficiently than other\nfirms and so squeeze out higher returns. We discuss the positive potential of great management in the last chapter. On the other\nhand, investments made under the protective umbrella of a well-established competitive advantage will almost always be worth\ndoing, either to exploit opportunities or to secure the existing franchise. We discuss this issue more completely in the following\n\nchapter on corporate development.\n\f"}, "003270.png": {"text": "CHAPTER 17\n\nCorporate Development and Strategy\n\nMergers and Acquisitions, New Ventures, and Brand Extensions\n\nMergers and acquisitions, new ventures, and brand extensions\u2014all aspects of corporate development\u2014are unquestionably\nstrategic business functions. By all the traditional criteria for distinguishing between strategic and tactical decisions, corporate\ndevelopment issues qualify as strategic. The commitments in question are large, they involve the overall direction of the enter-\nprise, and they have long-term consequences.\n\nThe most common method for evaluating alternative courses of action in these areas is a business case analysis consisting of\ndetailed projections of future distributable cash flows discounted back to the present. But discounted cash flow, as we have argued\nin chapter 16, is by itself a critically flawed tool for making decisions of this sort. The values calculated to justify initiatives depend\non projections, into the distant future, of growth rates, profit margins, costs of capital, and other crucial yet highly uncertain vari-\nables. Also, a typical discounted cash flow analysis rests on a number of critical assumptions about the nature and intensity of fu-\n\nture competition that are rarely explicit and generally untested.\n\f"}, "003271.png": {"text": "The strategic framework we have developed in this book, especially the view that the most important determinant of strategy\nis whether an incumbent firm benefits from competitive advantages, applies directly to issues of corporate development. In fact,\nthe utility of this approach in clarifying decision making in this area is an important test of its worth. At a minimum, clarifying\nthe competitive environment in which new initiatives will succeed or fail should provide an essential check on whether the con-\n\nclusions of a discounted cash flow-based business case are reasonable.\n\nMERGERS AND ACQUISITIONS\n\nDecisions about mergers and acquisitions are essentially large-scale investment choices. They are based on an investment\napproach that has two main features. First, an acquisition is by definition a concentrated investment in a single enterprise or, in\nthose cases where a conglomerate is being acquired, in a limited collection of enterprises. The firm making the acquisition has the\noption of making a different kind of investment, either directly or by distributing the money to its owners. It or its shareholders\ncould purchase stocks in an economy-wide or even global portfolio of enterprises. Acquiring another company may help diversify\nthe business of a previously highly focused firm, but it will add much less diversification than buying a broad-based portfolio of\nshares. Considered from this perspective, an acquisition or a merger, like all concentrated investment strategies, entails more risk\nthan buying a portfolio of shares. There may be benefits to concentration that offset the additional risks involved. But unless these\nbenefits can be identified with some precision, an acquisition policy is a priori an inferior choice for a firm with capital to invest or\nto return to its shareholders.\n\nThe second feature of mergers and acquisitions makes this investment approach even more difficult to explain. Acquisitions\nof publicly traded companies are invariably made at prices higher than the market price of the shares before the intent to acquire\nis made public. These premiums, which historically have averaged about 30 percent above the preannouncement price, may run\n\nas high as 70 or even 100 percent. Premiums for acquiring privately held companies may historically have been lower, but when\n\f"}, "003272.png": {"text": "acquisition markets heat up, investment bankers are able to shop a private company around or conduct bidding contests. Under\nthese conditions, it is unlikely that the purchasing company is getting much of a bargain.\n\nTaken together, these features produce a concentrated and therefore risky investment made at a premium to the market price.\nAdding in the hefty fees paid to the investment bankers who underwrite and advise on any deal increases the costs to the in-\nvestors. Imagine being approached by a mutual fund salesman who is selling a fund that has limited diversification, sells for more\nthan the net asset value of the shares it owns, and carries with it an exceptionally high commission.\n\nAnother reason that acquisitions have to overcome a heavy financing burden merely to come out even is the cyclical nature of\nthe M&A business. When share prices are low, the acquisition market dries up; when prices rise, so does M&A activity. Instead of\nbuying companies when they are on sale, acquirers tend to go shopping when the targets are expensive. It is as if our mutual fund\nannounced in its prospectus that it would purchase shares only after they have gone up in price. Clearly, as an investment strategy,\n\nstandard merger and acquisition practice requires a substantial additional rationale.\n\nFINANCIAL AND STRATEGIC ACQUIRERS\n\nIt is common in merger and acquisition discussions to distinguish between acquirers that are simply making financial investment\ndecisions and those that have a strategic purpose in mind (figure 17.1). While the differences are not altogether clear, the general\nidea seems to be that the strategic acquirer brings something to the deal that will enhance the underlying operations of either\nthe target firm or the buyer itself. The financial buyer, by contrast, simply adds the acquired company to a portfolio of operations\nwithout changing the fundamental performance at either firm. Without such changes, a standard acquisition involves only a con-\ncentrated investment at above market prices with high transaction costs. It makes little or no business sense.\n\nThat leaves strategic acquisitions as the only kind that bear detailed consideration. In order for a merger or acquisition to be\njustified, the buyer has to contribute something to the combined enterprise. This contribution can be either of general value, like\n\nimproved management or a tax advantage, or, more likely, something highly specific, such as special industry-related technology,\n\f"}, "003273.png": {"text": "joint economies of scale, or a marketing position within the industry. This kind of combination, by definition, produces \u201csynergy,\u201d\nthat happy situation in which the whole is greater than the sum of its parts.\n\nFinancial (Investment Only)\n\n+ Concentrated (risky)\n+ Atapremium\n+ High transaction costs\n\nM&A Types\n\nStrategic (Synergies)\n\n+ No competitive advantage (ignore)\n\n+ Competitive advantages\u2019potential synergies:\n\u2014 Captive customers (don't expand)\n\n\u2014 Cost savings through production and economies\nof scale and tax savings\n\n\u2014 Better management (Is it worth the premium?\nWhat does it do to the buyer\u2019s performance?)\n\nFIGURE 17.1\n\nTypes of mergers and acquisitions\n\f"}, "003274.png": {"text": "Yet even in these presumably favorable circumstances, the history of strategic acquisitions has been painful for the share-\nholders of the acquiring company. Around the time of the acquisitions, the shares of the acquiring firm typically suffer a decline\nin price of roughly 4 percent, measured from twenty days before the deal is announced to the point at which it closes. The target\ncompanies, on the other hand, see their shares appreciate by more than 20 percent. The returns to shareholders of the acquiring\ncompany are dismal; the companies typically lose roughly 20 percent of their value over the next five years. Moreover, these fig-\nures may actually understate the negative effects of merger and acquisition transactions because many of the deals are done by se-\n\nrial acquirers, whose stocks may already be depressed in anticipation of more deals to come.\n\nTHE SEARCH FOR SYNERGY\n\nIt is not surprising that unrelated acquisitions, those of firms outside the acquirer's principal area of business, have shown espe-\ncially poor results, since if any synergies do occur, they are bound to be insignificant. Most of these combinations are subsequently\nundone, one way or another. Companies that make many of these kinds of acquisitions end up with low stock prices, relative to\ntheir peers, and themselves become takeover targets for a buyer who intends to break them up and sell off the parts.\n\nFor all acquisitions, judged by accounting measures of performance, the postdeal operating results of the combined firms\nexhibit little or no improvement. An early study of the divisions of the target companies found that their average performance\ndeteriorated after acquisition. Subsequent studies have identified some improvements in operating margins, but they tend to be\nin the range of 0.2-0.4 percent, not enough to cover the premiums paid to the targets.: At the plant level, the operating costs of\nthe target company plants are brought down, but this positive development is offset by a coincident weakening in the operating\nperformance of the acquiring company\u2019s plants. Given this history, checkered at best, it is important for evaluating potential ac-\nquisitions to identify those particular strategic factors that favor success.\n\nReviewing the diversification strategy of thirty-three large American companies in the period 1950-86, Michael Porter found\n\nthat these firms had divested many more of their acquisitions than they retained. From the combinations that worked, he identi-\n\f"}, "003275.png": {"text": "fied three traits as essential. First, the target company had to be in an \u201cattractive\u201d (profitable, fast-growing, etc.) industry. Second,\nthere had to exist synergies between the operations of the acquirer and the target. Third, the acquisition premium could be no\nmore than these synergies were worth.\n\nIn practice, the requirements for a successful acquisition are actually more clear-cut than even this short list suggests. The last\ncriterion is a matter of simple arithmetic. Obviously, if an acquirer pays too high a premium, it is going to destroy rather than cre-\nate value for its shareholders. The question is how to calculate the value of synergies that are likely to be realized in order to judge\nwhether the premium is excessive. The first two criteria, on closer examination, are so intimately connected as to amount to al-\nmost the same thing.\n\nOur contention in this book is that the definition of an \u201cattractive\u201d industry depends completely on one factor: the existence\nof incumbent competitive advantages or, using the alternative term, barriers to entry. Without these barriers, the process of entry\nby outsiders or expansion by incumbents will eliminate any returns above an industry\u2019s cost of capital. Firms with exceptional\noperating efficiency may produce extraordinary returns for a time, provided management stays focused and intact. But for an in-\ndustry to be \u201cattractive,\u201d so that even companies with merely good as opposed to stellar management can earn \u201cattractive\u201d returns,\n\nit needs to be protected by barriers to entry, with the incumbent firms enjoying competitive advantages.\n\nCOMPETITIVE ADVANTAGES AND SYNERGIES\n\nThe existence of synergies also depends on the presence of competitive advantages. The connection is clear. If the firm being\nacquired enjoys no competitive advantages, then the buying firm should be able to do on its own anything that might be done in\ncombination after the acquisition. Even if the acquiring firm lacks the skills internally to perform these things, it can always find\nother firms willing and able to do for it whatever the acquired firm does. Given an active marketplace, these other companies will\n\ncompete for the business of fulfilling these functions. Therefore, the acquired firm adds nothing of value to the combination,\n\f"}, "003276.png": {"text": "nothing that the acquirer cannot either do or hire someone to do. There are simply no synergies to be achieved when the acquiring\nfirm can operate as well without the acquisition as with it.\n\nSynergies moving in the other direction, from something the buyer contributes to the target, are equally unlikely. Because\nthere are no competitive advantages in the target firm\u2019s market, none will be available to the two companies after the combination.\nEven if the buyer could transport some of its existing competitive advantages into the new market, it would do at least as well by\nselling them to any firm in this market as it would by restricting the benefits solely to the single acquisition target.\n\nFor example, if a distribution company had established a deep and efficient infrastructure within a given geographic region, so\nthat it had some customer captivity and economies of scale, would it be better off buying one of its clients to lock in a distribution\narrangement, or simply offering its services to the companies that might use them most profitably? The absence of competitive\nadvantages in the target\u2019s market means that all the companies in that market are equally able to take advantage of anything the\nacquirer is providing. Therefore, without competitive advantages for the acquired firm, there will be no synergies from the combi-\nnation. And, as a direct consequence, \u201cattractive\u201d markets, namely those in which competitive advantages exist, are also the only\nones that may give rise to genuine synergies.\n\nMany expected synergies, even some that seem obvious, never materialize. If the acquired firm now has a strong brand image,\nbut no captive customers, it may appear that the acquiring company will be able to reap some benefits from this brand. By this\nlogic, Chrysler should have benefited from the Mercedes-Benz image after it was acquired. But strong brands are not in and of\nthemselves competitive advantages. In the luxury car market, Mercedes has a number of rivals; BMW, Jaguar, Acura, Lexus, and In-\nfiniti all maintain prestigious brand identities. If the benefits of these brand images could be transferred without impairment to a\ncompany like Chrysler, then Chrysler should have been willing to pay for this benefit directly, through licenses, fees, or other kinds\nof arrangements. And the companies with the brands for hire would have been eager to do business. So if the benefits of the brand\ncan be transferred, which is doubtful in most instances, there is nothing that restricts the synergies to an expensive merger or ac-\n\nquisition, nothing that can\u2019t be done more economically by a rental transaction.\n\f"}, "003277.png": {"text": "Captive Customers\n\nFrom the strategic perspective of this book, the first qualifying criterion to be applied to a merger and acquisition decision is\nwhether the target firm enjoys any competitive advantages. Competitive disadvantages are obviously not worth acquiring. How-\never, not all competitive advantages foster synergies. Customer captivity is not likely to travel well. Cola drinkers are among the\nmost loyal customers around. But this habitual consumption does not make them any more likely to buy a particular brand of life\ninsurance or even to favor a particular brand of salty snack or eat in a certain fast-food outlet. If Coca-Cola were to buy a cracker\ncompany, nothing about the combination would change a Coke drinker\u2019s habitual attachment to his or her existing cracker brand.\nAre Pepsi drinkers more loyal to Frito-Lay snacks than those who prefer Coke?\n\nIn financial services, the cost to a consumer of switching banks is not lessened when its existing insurance carrier is acquired\nby arival bank. The separate customer captivities involved with the family\u2019s insurance and banking decisions generally stand dis-\ntinct from one another. By their very nature, they are not undermined by a financial market transaction that combines an insur-\nance company with a bank. More generally, the idea that particular financial service firms (e.g., stockbrokers) could extend their\noperations through acquisitions to become \u201cfinancial supermarkets\u201d has led to recurrent failures.\n\nWhen AT&T acquired Teleport, a local telephone service provider with fiber-optic lines in a number of American cities, it\nexpected customers to be attracted to a single integrated telephone company providing both local and long-distance services.\nThings didn\u2019t work out that way. AT&T did not win the local calling business of many of its existing long-distance customers, who\nstayed with their local providers. Despite CEO Michael Armstrong\u2019s claim of \u201cpowerful financial and strategic synergies for both\ncompanies,\u201d the number of AT&T customers who opted for integrated local-long-distance service was negligible. So both logic and\nexperience indicate that competitive advantages arising from customer captivity do not travel in merger and acquisition packages.\n\nIn spite of all the promise, it generally turns out that there are no significant synergies available from this competitive advantage.:\n\nCost Savings\n\f"}, "003278.png": {"text": "After all the wishful thinking and deal-promoting propaganda have been cleared away, we are left with cost advantages\u2014most\nfrequently due to proprietary technology and economies of scale, fortified by some customer captivity\u2014as the only potential\nsources of synergies in merger and acquisition transactions. With only cost advantages to consider, the task of evaluating po-\ntential synergies is considerably less complicated. When there are proprietary production technologies in either the target or the\nacquiring firm, they can reduce costs provided they can be successfully adopted in the other company. The combined companies\nmay be able to realize joint economies of scale, mainly in the elimination of redundant fixed costs in distribution, marketing,\nresearch and development, and general overhead. The appropriate measure of the benefits of an acquisition is thus the size of the\nanticipated cost savings. Will they be large enough to offset the premium paid for the acquisition and therefore create some addi-\ntional value for the acquirer?\n\nIf company executives and the bankers promoting merger and acquisition deals were forced to justify the proposed combina-\ntions using this test, it is likely many transactions would never see the light of day. (Admittedly, one should never underestimate\nthe power of a compelling projection based on unwarranted hopes, a professional-looking spreadsheet, and an elegant PowerPoint\npresentation.)\n\nAOL\u2019s acquisition of Time Warner, for which it paid a premium of roughly $50 billion, was justified by $600 million of antic-\nipated annual cost savings. The cumulative value of these savings, appropriately discounted, was certainly less than $10 billion.\nAT&T bought cable properties where little or no cost savings were expected. It later sold them for about half of what it had paid. In\nlate 1997, when Sealed Air Corporation acquired the Cryovac packaging division of W. R. Grace for a premium of $3 to $4 billion, it\nidentified $100 million in annual cost savings it expected to realize. Discounted at 10 percent, these were cumulatively worth only\n$1 billion. The net result was a significant decline in Sealed Air\u2019s stock price. As a general rule, acquisitions at a premium to market\nprices need to be justified primarily with the costs savings that will ensue with the combination of the firms. Other vaunted syner-\ngies are considerably less likely to materialize.\n\nAcquisitions of private companies should meet the same cost savings test as that applied to the purchase of public companies.\n\nMany of these are essentially \u201cmake versus buy\u201d decisions, such as when major drug companies acquire drug development start-\n\f"}, "003279.png": {"text": "ups or when established record companies buy independent labels. The question is whether it is cheaper to obtain the products\ninvolved by internal development, licensing, or some other means short of an outright acquisition, which is generally an expen-\nsive way to go.\n\nIn some cases, it is clear that there is no alternative to acquisition, no other way to get hold of the desired product. But even in\nthese instances, cost discipline should not be abandoned. By definition, the target company does enjoy a competitive advantage\nin these cases. Neither the acquiring company nor, presumably, anyone else can produce an equivalent to the desired product. The\nvalue of the target in this case consists of its value as a stand alone company, calculated by the customary methods (as discussed\nin chapter 16 on valuation), plus the value of the synergies. As usual, these synergies will be realized largely in cost savings, either\nfrom proprietary process technology or joint economies of scale. If, for example, the acquiring firm has an extensive distribution\n\nnetwork through which to market and deliver the target\u2019s unique product, there are savings to be realized from economies of scale\n\n \n\nthat would not be available to the target firm were it to do the distribution on its own or hire someone else to do it.:\n\nMany mergers and acquisitions are also justified by the claim that the superior management of the acquiring company will\ndecisively improve the operations of the target company. This claim rests on two assumptions, both related to costs. The first is\nthat payroll costs will be lowered simply by getting rid of the inferior managers of the target company. Either the managers from\nthe acquiring company will take up these jobs without an increase in pay, or fewer and more capable people will be able to handle\nthe tasks at a lower cost of employment.\n\nThe second assumption is that there will be additional cost reductions from improved operations in the target firm. Other\nkinds of improvement are less likely. Marketing expertise tends to be industry-specific. For the acquiring company to have the\nskills to improve marketing at the target, it is likely to be in the same or a closely related business. But if this were the case, why did\nit need to make the acquisition in the first place? It could have reproduced the target company\u2019s marketing efforts itself without\nthe trouble of acquisition and reorganization. The benefits from better management will be largely confined to making the opera-\ntions of the target firm better or eliminating some of them entirely. With fewer personal ties, the acquiring company may have an\n\neasier time in cutting back on employees. The payoff will be in cost reductions, which should be measurable.\n\f"}, "003280.png": {"text": "An additional note of caution must be raised about the value of mergers and acquisitions that are to be justified by spreading\n\u201cgood management\u201d onto the target company\u2019s operations. Sometimes improvements in productivity at the target company,\nthough real enough, come at the expense of deterioration in productivity in the operations of the acquirer, eliminating any net\ngain. The attention of management, especially good management, is a scarce resource. It does not simply expand to cover all the\noperations for which it is needed. Deploying that resource to a target firm means diverting it from the acquirer\u2019s own operations. It\nis only the net improvement in overall performance that should be used to justify an acquisition. Also, the acquisition process it-\nself, which adds nothing of value to the combined firm\u2019s operations, is an enormous devourer of management attention.\n\nSome potential revenue gains may be expected from an intelligent acquisition. First, the increase in scale or efficiency that may\ncome with the merger may make some marketing efforts profitable that previously were uneconomic. Still, these new efforts are\nunlikely to be of more than minor value. If they were significant, they would have already been undertaken, as they would have\nbeen profitable even without the benefits of economies of scale or increased efficiency. Therefore, the additional profit from these\nmarginal efforts will be small even though the added revenue may be substantial. Second, if the merger eliminates a competitor,\nespecially a troublesome, noncooperating competitor, it may improve industry price discipline. However, these are precisely the\nacquisitions most likely to be contested by the antitrust regulators. Also, it makes more sense for a potential acquirer to let some\nother industry player incur the expense of the takeover premium than to play hero itself. There is a strong incentive to be a \u201cfree\n\nrider\u201d and watch from the sidelines.\n\nTHE M&A BOTTOM LINE\n\nThe strategic bottom line for mergers and acquisitions is that two fundamental requirements have to be met to warrant the effort\nand expense. First, there must be competitive advantages to produce the synergies that yield sustained benefits. Second, the syn-\nergies must consist largely of cost savings. Thus, for any additional value to be created by the combination, the takeover premium\n\nwill have to be less than the clearly identified and realistic cost savings. There may be instances in which superior management\n\f"}, "003281.png": {"text": "will be able to improve the operations of the combined companies without benefit of a competitive advantage, but for reasons we\nhave discussed, primarily limitations on the key resource of management attention, these instances will be infrequent. Finally, a\nrigorous justification of the takeover premium must set it against the benefits that a cooperative arrangement among independent\ncompanies might achieve without a merger or acquisition. If bargaining can produce most of the gains of direct combination, the\npremium paid must be minimal to be fully warranted.\n\nWhen the acquisition is paid for in stock rather than cash, the calculations may need to be adjusted. In the AOL-Time Warner\nmerger referred to earlier, AOL clearly overpaid, based on the size of potential cost savings compared with the premium over mar-\nket price. But AOL used its own stock, which by almost any valuation measure was grossly inflated, for the purchase. Buying Time\n\u2018Warner with a debased currency made the deal a profitable one for AOL shareholders, although it took a while for that fact to be-\ncome apparent. While it is generally better to be on the selling rather than the buying side in M&A transactions, when the acquirer\npays with its own stock, using a currency whose future value it knows much more about than anyone else, then even the target\nmust exercise care.\n\nIf a proposed transaction makes no business sense if done with cash, the only reason for doing it with stock is that the ac-\nquirer\u2019s shares are overvalued. The choice of stock or cash payment does not affect the underlying economics of the transaction.\nThe acquiring company would never choose to use stock if its management felt that its stock was trading in the market at less than\nits true value. Historically, the stock market has treated acquisitions for stock more harshly than those done with cash, and the\n\nshare price of the acquiring company has declined more severely upon the announcement of the deal.\n\nVENTURE CAPITAL\n\nVenture capital investing is a second area in which strategic considerations ought to play an important role. Like mergers and\n\nacquisitions, venture investments are strategic decisions. They involve large resource commitments, they have long-lived conse-\n\f"}, "003282.png": {"text": "quences, and they can shape the overall direction of a business. From the strategic perspective developed here, the outcomes of\nventure capital decisions depend critically on the actions of other potential entrants into the markets into which the ventures are\nbeing launched. Even new industries with enormous promise can be sinkholes for venture investments if there are no barriers to\nentry. The history of the disc data storage industry is a telling example of how enthusiastic venture investors can saturate an at-\ntractive market with new entrants, almost all of whom lose money.\n\nAccording to conventional wisdom, success in venture capital investments depends upon two factors: the quality of the\nbusiness plan and the capabilities of the venture team itself. In practice, only the second of these considerations should count for\nmuch. By their very nature, venture capital investments take place in new or underdeveloped markets without entrenched, dom-\ninant competitors. Proprietary technologies, the venture investors hope, will be developed as the venture progresses. But when\nthey start out, almost by definition, no firms have access to such technologies. Developing captive customers may be the goal of\nthe venture, but at inception the customers in these nascent markets are up for grabs. Finally, though it may hope to grow rapidly\nand achieve economies of scale\u2014hence the mantra \u201cGet big fast\u201d\u2014no new venture begins life with that kind of advantage over its\ncompetitors. So, while a well-conceived venture business plan should look to the ultimate creation of competitive advantages, that\nvision is not itself a competitive advantage. Truly lucrative opportunities will attract other new ventures with a similar vision and\nacomparable plan. The larger the potential prize, in other words, the smaller will be the probability of winning the prize. There are\nmany smart venture capitalists and no barriers to entry in generating business plans.\n\nThe quality of the venture plans is not totally irrelevant. Poor plans usually lead to poor returns. But plans that rely on general\nfeatures, like identifying large markets and describing potential competitive advantages, are unlikely to pinpoint genuinely attrac-\ntive opportunities.\n\nThe design of a successful venture business plan involves making delicate trade-offs between the size of the ultimate returns\nand the chance of realizing those returns. Crafting such plans requires a thorough knowledge of the industry and a dense network\n\nof industry contacts. But those are attributes of venture investors. Indeed, they are two of the principal resources that the venture\n\f"}, "003283.png": {"text": "sponsors, whether independent venture capital firms or corporate development departments, bring to a venture opportunity.\nThere are no generally applicable characteristics of \u201cgood\u201d business plans.: All good business plans are local.\n\nAn accomplished venture sponsor should also be able to assess the quality of a venture\u2019s management team. The sponsor\nshould have a network of contacts that include skilled professionals who can be recruited to fill in gaps in the original team, poten-\ntial customers who can help refine the venture\u2019s product offerings, and firms that can provide special facilities or other essentials\nthat the venture needs to deliver its offerings. The sponsor should also be able to modify and refine the business plan to target\nthose niches in which there is the greatest probability of success. The founders of Compaq originally approached Ben Rosen with\na plan to develop and sell disk storage devices. He liked the venture team but not the proposal, and he redirected them toward the\nemerging PC business, where they could challenge IBM at the high end of this market.\n\nVenture sponsors are ultimately in the knowledge business. They have to create and maintain information collection networks.\nThey bring together knowledge of technologies, markets, people, and other essential resources and try to combine these ingredi-\nents to produce a well-functioning entrepreneurial organization. Like other industries in which there are no barriers to entry, suc-\ncess in venture capital ultimately depends on how efficiently the venture operation is run, which means how effectively venture\nsponsors remain focused within their core circles of competence. Ultimately, it is the people that matter, not the business plans in\n\nwhich they invest.\n\nECONOMIES OF SCOPE AND LEVERAGING EXISTING CAPABILITIES\n\nVentures that grow out of existing businesses usually differ in two ways from the stand-alone undertakings commonly funded by\nventure capitalists. First, extensions of current operations are more likely to address well-established markets than newly develop-\ning ones. Entering established markets is actually more difficult than moving into new ones. Barriers to entry are much more likely\n\nto exist in already functioning markets. If there are incumbent competitive advantages, they will work against the new venture.\n\f"}, "003284.png": {"text": "The best it can hope for is a level playing field. So although extending an existing operation may seem like an easier and more cer-\ntain opportunity than beginning an enterprise from scratch, the nature of the market may actually weigh against it.\n\nThe second differentiating factor between extensions and stand-alone start-ups is that elements of the current operation\u2014\nbrand images, distribution systems, research and development programs, overhead support systems\u2014can often be used to benefit\nthe new venture. These are \u201ceconomies of scope,\u201d and they may convey advantages on the new venture that competitors who oper-\nate solely in the target market do not enjoy.: If that is the case, it would seem obvious that the new venture will be profitable. Yet on\ncloser examination, it turns out that sustained profitability depends on whether the venturing firm has a competitive advantage\nin its original market.\n\nIf there are no barriers to entry in that market, then the profits it enjoys from its expansion into a related area will draw com-\npetitors who can copy what it did\u2014that is, who can operate in both the initial and adjacent markets and benefit from the same\ncost advantages that the original firm enjoys. At that point, the expansion strategy becomes solely a matter of efficient operations.\nThe exceptional profits the original firm was earning from moving into the new market wither away, as is generally the case when\nthere are no barriers to entry. The venture decision, then, rests on the status of competitive advantage. If one exists, then moving\ninto a related market is a good idea. If one doesn\u2019t, success depends on operational efficiency and the competence of the people\ninvolved. Only when there are sustainable competitive advantages in the original market do economies of scope add something to\n\nthe basic imperatives\u2014chiefly, to operate efficiently\u2014of a new venture.\n\nEXPLOITING BRANDS\n\nOne of the more obvious venture opportunities for extending an existing business is the use of an established brand to introduce\nproducts into a new market. The strategic principles are no different here than in most other new ventures. The payoff will likely\n\ndepend on efficiency.\n\f"}, "003285.png": {"text": "It is important to understand the sources of the value that a brand provides. Brands are not by themselves a type of competitive\nadvantage, although some aspects of brand-related consumer behavior may lead to competitive advantages. To cite it one more\ntime, Mercedes-Benz has not been able to leverage its first-class brand image into exceptional investment returns, which are an\nessential sign of competitive advantage. Brands are assets. Like other assets, they produce income, but they require both initial\ninvestments at the time of creation and continued spending to sustain their established status. In this regard, they are just like\nproperty, plant, and equipment\u2014they need cash at the start to build or buy, and cash each year to ward off the withering effects\nof depreciation. Also, like a specialized piece of equipment, a brand is best used with the product for which it was developed. The\nvalue created by a brand is the difference between the costs of starting and maintaining it and the income the brand itself brings\nin, generally in the form of a higher margin that the branded product can command. In a market without competitive advantages,\ncompetition among brands will eliminate any return in excess of the investment required to develop and nourish the brand. In\nthis regard, brand investments are no different from any other investments in competitive markets: they return the cost of capital\nand do not provide any net economic value to the firm.\n\nAll this would be more apparent were it not for the intangible nature of brand investments, which permits misconceptions to\nflourish. Most branded products fail to establish themselves in the marketplace. In figuring the average cost of creating a success-\nful brand, these failed efforts have to be included in the calculation. The expected cost of creating a lucrative brand, which incor-\nporates the probability of success (and failure), will be many times the actual investment made to get a specific successful brand\noff the ground. The future net income for which the brand is responsible has to be understood as a return on this expected cost,\nsince no new brand is a certain winner. If, for instance, the chances of success are one in four for a new brand, then the return on\ninvestment is the present value of future net income divided by four times the actual investment made.\n\nSince investments in failed brands conveniently disappear from view, it is natural to confuse overall returns on brand invest-\nments with the returns on only those brands that have succeeded. This is a major error, and in seriously overestimating the return\non brand investments, it leads to the unwarranted conclusion that brand creation is a source of competitive advantage. Certainly\n\nthere are brands that contribute to a company\u2019s competitive advantage\u2014Coca-Cola, Marlboro, Gillette, Intel, and other famous\n\f"}, "003286.png": {"text": "names\u2014but there are even more brands, widely known, instantly recognizable, even iconic, that labor on without producing any\nsuperior return for their corporate owners: Coors, Travelers, FedEx, AT&T, Xerox, Honda, Cheerios, McDonald\u2019s, and on and on.\n\nBrands are associated with competitive advantages when they lead to customer captivity and, more powerfully, when that\ncaptivity is combined with economies of scale in the underlying production process. We need to distinguish between brand value,\nwhich is the premium that consumers will pay for a product with a particular brand, and economic value, which is additional\nreturn on investment that the brand helps generate. Coca-Cola is the world\u2019s most valuable brand not because it commands a\nremarkable price premium. It doesn\u2019t. No one is going to pay thousands of dollars to be identified as a Coke drinker, although they\nmay pay that much to drive a Mercedes or wear Armani clothing. Brands of Scotch whisky, like Johnny Walker or Chivas Regal,\nhave a much higher brand value than Coca-Cola, but also a much lower economic value.\n\nCoca-Cola\u2019s brand is valuable for two reasons. First, there is a remarkable degree of habit formation associated with cola drinks\nas a category. We noted earlier that even regular beer drinkers are much less attached to their brand than their cola-drinking\ncounterparts are. When they dine out, they often order a beer from the country whose cuisine they are enjoying, whereas cola\ndrinkers stick with Coke or Pepsi, if it is available. The strength of attachment shows up in the higher market share stability in the\ncola market, another sign of customer captivity. Compare that stability with the performance of brands in fashion-driven markets.\nThough brands are essential to operate in fashion markets, they are also victims of the desire for novelty that rules those markets.\nFashion customers are by definition novelty seekers, and brands alone do not create habits or captivity. In the food business, habit\nand customer captivity vary directly with frequency of purchase. Food products purchased every day show greater market share\nstability than fast-food chains, which in turn have more stability than full-service restaurant chains. Brand images are important\nfor all these food segments, but they only create a competitive advantage when frequent purchases establish habit strong enough\nto encourage customer captivity. Venture strategies to extend brands into new markets need to take this distinction into account.\n\nThe second reason that the Coca-Cola brand has great economic value is the existence of economies of scale. Coca-Cola enjoys\nthem in its distribution function and, to a lesser extent, in its advertising. Fixed costs in both areas are large relative to variable\n\ncosts, which means that for an entrant to be viable, it must capture a substantial part of the cola market. But the strength of\n\f"}, "003287.png": {"text": "customer captivity makes this task almost impossible. As Coca-Cola exploits its brands by selling its colas well in excess of costs,\nprovided it can get Pepsi to go along, it does not have to worry about losing share to cola upstarts who try to win business with a\nlow price strategy.\n\nAt the same time, many of the costs of creating a new brand are fixed by the size of the target market and do not increase with\nmarket share. The same distribution economies of scale that protect Coca-Cola\u2019s dominant market share apply as well to brand cre-\nation. Coca-Cola can spread the costs of new brand creation (in advertising, product development, promotion to the distribution\nchannels) across many more potential customers than can its rivals, except Pepsi. Thanks to these economies, the company enjoys\ncompetitive advantages in creating and maintaining a new brand. Coca-Cola and other firms with strong franchises are much\nmore likely to profit from brand extensions than companies in markets without barriers to entry. But because it has a powerful\ncompetitor, Coca-Cola will need to anticipate how Pepsi will respond.\n\nBy contrast, when Microsoft considers extending its brand by adding new applications to its Windows operating system,\nprojected revenue gains need not be adjusted downward to account for competitive reactions. With fixed costs as the dominant\ncomponent in Microsoft\u2019s franchise products, incremental profit margins on the added revenue are likely to be high and stable\nso long as Microsoft's competitive advantages remain intact. Successful product introductions actually strengthen Windows\u2019s\ncompetitive advantages. They raise the costs of switching to alternative operating systems, and they fill gaps in the application\nportfolio that might constitute entry points for potential competitors. An Internet browser application made Netscape a threat\nto the Windows empire until Microsoft incorporated that function into the operating system at no additional cost to consumers.\nEffective exploitation and protection of competitive advantages generally lead to aggressive brand extension strategies.:\n\nEven for a firm with a competitive advantage, brand extensions into markets that lie outside the company\u2019s existing franchise\nwill usually be less profitable. The competitive nature of the new market will cut into both revenue and profit margins. If there are\nany exceptional returns, they will come only to the extent that leveraging an existing brand image may lower the cost of entry.\nAnything more than that will be eliminated by competitors who are willing to pay the full price of entry. If this market is within\n\nreach of other companies that are also trying to extend their brands, then any excess returns will be reduced by these competitors.\n\f"}, "003288.png": {"text": "The value of these brand-extending opportunities can also be decreased by any impairment of the brand or cannibalization of de-\nmand in the established side of the business. Business plans that promise returns above these modest levels have probably ignored\nthe impact of future entry and competition.\n\nIn sum, the value of migrating an established brand into another market, particularly a competitive market with no barriers\nto entry, is due entirely to the cost savings available from not having to build a brand from scratch. These savings are part of the\nefficiency imperative that applies to all business functions necessary for a successful entry into a new market. For example, Micro-\nsoft\u2019s foray into the video game market with the Xbox requires a much higher level of cost management and focus than did the ex-\n\ntension of its basic Windows franchise from the desktop onto servers or personal digital assistants.\n\nIn each of the three areas of business development we have discussed\u2014mergers and acquisitions, venture investing, and brand\nextensions\u2014understanding the strategic context imposed by other economic agents is necessary for making informed decisions.\nApproaches that focus narrowly on financial details or marketing issues are essential for the effective implementation of a well-\nformulated plan, but without a grasp of the competitive environment, they will miss the forest for the trees. In the absence of com-\npetitive advantages and barriers to entry, new initiatives have only one strategic imperative: the efficient use of all the resources\n\nthey require.\n\f"}, "003289.png": {"text": "CHAPTER 18\n\nThe Level Playing Field\n\nFlourishing in a Competitive Environment\n\nMANAGEMENT MATTERS\n\nA tenet of the prevailing wisdom in the literature on business strategy is that companies should operate only in markets in which\nthey possess some sort of competitive advantage. This is not our position, even though we have dwelled at length on the signifi-\ncance of incumbent competitive advantages\u2014on the need to identify them, understand their source, and to exploit those that a\nfirm enjoys. The fact is that companies with sustainable competitive advantages are the exception, not the rule. Most firms in most\nmarkets do not benefit from competitive advantages, and when these advantages do not naturally exist, they are difficult to create.\nIt is true that many firms may have the potential to enjoy competitive advantages in some markets. A company that chooses its\nniche market wisely, works assiduously to develop customer captivity, and organizes its operations to achieve economies of scale\n\nmay be able to emerge from the pack and become the dominant firm in a market, now protected by barriers to entry.\n\f"}, "003290.png": {"text": "Still, these triumphs are infrequent, no matter how brilliant the plan and flawless the execution. Instead of being protected by\nbarriers to entry, most firms operate on a level playing field where they confront a large and frequently elastic set of competitors.\nFirms in this position (position 5 in figure 18.1) have a single strategic imperative: they need to focus relentlessly on being as effi-\n\ncient and effective as possible in all of their business operations.\n\nManage Competitive\npe Advantage\nIs It You?\n\nNo\n\u201cSA. You are an ant;\nEXIT GRACEFULLY\n\nSingle Doniinant Firm?\n\nCompetitive Advantage: NO Game Structure!\nYES Simulation\n\na Prisoner's Dilemma\n\nEntry!Ps i\nALL MARKETS try: neice\nCooperation!\n\nBargaining\n\nCompetitive\u201d Advantage:\nNO\n\nOperational Effectiveness:\nEfficiency, Efficiency, Efficiency\n\f"}, "003291.png": {"text": "FIGURE 18.1\n\nWhere we are in the book\n\nEfficiency clearly means controlling expenses up and down the line: raw material, labor, plant and equipment, utilities, even\ntravel and entertainment. It also requires a productive return on the money spent. Output per hour of labor is the standard mea-\nsure of productivity, but the concept also applies to the returns on marketing campaigns, research and development, technology\nand other capital expenditures, human resources, financial management, and all the other functions that make up a modern busi-\nness. The rewards from superior management that stresses efficiency and productivity can be comparable to those arising from\nstructural competitive advantages. Well-managed companies have been able to outperform their peers over long periods of time in\nindustries without identifiable structural competitive advantages. Contrary to prevailing economic assumptions, all firms are not\nequally good at exploiting technologies or market opportunities. These potential differences in management effectiveness must be\n\nincorporated into any comprehensive treatment of strategy.\n\nTHE PRODUCTIVITY FRONTIER\n\nHigh productivity is the source of our modern standards of living, both in material consumption available to us and in the quality\nof employment. Consider the differences between a life spent mining coal and one spent teaching, nursing, or doing virtually\nanything else. It is only from the growth of productivity that we get the economic dynamism that allows quality-of-life improve-\nments. A historical perspective makes this conclusion inescapable. Compared with life four centuries ago, people of modest means\n\nin the developed world live longer, healthier, and materially more comfortable lives than did the elite in 1600.\n\f"}, "003292.png": {"text": "The traditional discussion of productivity growth ascribes it to increases in potential output that arise from capital invest-\nment, a more educated workforce, and advances in technology. Policy prescriptions focus almost exclusively on reducing govern-\nment debt to drive interest rates lower and stimulate private investment; spending money on education to raise the productive\nabilities of the workforce; and using either incentives or direct government expenditures in support of research and development.\n\nThere is an alternative perspective, one that has received far less attention. According to this view, most firms operate well\nwithin the \u201cproductivity frontier,\u201d which represents the limits of the possible given the availability of capital, the quality of the ex-\nisting labor force, and the state of current technology. Higher productivity comes primarily not from extending the frontier but by\nbetter employing existing resources to close the gap between what is possible and what is actually achieved. The crucial factor, and\nthus the chief source of economic progress, is good management, especially management that pays close attention to efficiency.\nFrom this perspective, operating efficiency is at least as important as structural economic conditions in accounting for a firm\u2019s per-\nformance relative to its peers.: The evidence strongly favors this second view.\n\nEvidence for the importance of management in achieving superior productivity shows up in many ways:\n\n\u00abSome companies do better.\n+ Things can change in a hurry.\n- Manufacturing productivity has been transformed.\n\n+ Case studies tell the tale.\n\nSOME COMPANIES DO BETTER\n\nFirst, at the company level, there are large and persistent differences in performance across firms within any industry. Table 18.1\n\npresents data on the cost of processing life insurance premiums for three mutual life companies from 1988 through 1991. The\n\f"}, "003293.png": {"text": "gap between Northwestern Mutual, the acknowledged industry leader in efficiency, and Connecticut Mutual, perhaps a laggard,\nwas enormous. Even Phoenix Mutual, considered to be average for the industry, had costs two to three times as high as North-\nwestern Mutual's. And these distinctions persisted. In 2002, Northwestern Mutual's costs were still less than half those of Phoenix\nMutual's.:\n\nIn the telephone long-distance market after deregulation, there were equally striking variations across companies. Long-dis-\ntance costs are largely fixed. National providers must have national networks with similar software and control capabilities. The\nincremental capacity necessary to handle additional traffic adds little to the cost of the basic infrastructure. Because billing and\ncustomer services are largely automated, they also are primarily fixed-cost items. The costs of advertising campaigns and a sales\nforce ought not to differ significantly from one national carrier to another. Yet in spite of these similar requirements, in the early\n1990s AT&T ran its long-distance network with around 120,000 employees. MCI managed the same tasks with fewer than 50,000.\n\nSprint got by with an even smaller head count.\n\nConnecticut Mutual Phoenix Mutual Northwestern Mutual\n1988 20.9% 16.7% 6.8%\n1989 19.8% 15.7% 6.9%\n1990 20.2% 14.9% 7.4%\n1991 20.9% 15.6% 6.3%\n\nTABLE 18.1\n\nHow productivity varies in the life insurance industry (general expenses as a percentage of premiums)\n\f"}, "003294.png": {"text": "Similar differences of this magnitude\u2014costs at the leader sometimes one-half or even one-third of those for the typical com-\npany\u2014have been observed in many other industries and for very specific processes, like issuing bank cards.: These disparities are\nnot transitory. Like the superior performance of Northwestern Mutual, they tend to persist for many years. Nor are they attribut-\nable to proprietary technology. These differences are as common among simple, low-capital-intensive, low-tech operations as they\nare among sophisticated, capital-intensive, high-tech firms.\n\nIna particularly striking example, differences in performance of up to 40 percent existed for extended periods among the for-\nmer Bell Telephone operating companies, both in terms of total cost per access line and with respect to more detailed performance\nareas like costs per customer service order processed (table 18.2). Yet these former siblings used the same basic equipment, the\nsame support systems, and the same unionized labor operating under a common national contract. Some of these telcos improved\nproductivity just as others saw it decline. Disparities in productivity across national economies mirror these intercompany differ-\nences and cannot be accounted for by divergences in either technology (which is globally available), capital investment, or labor\n\nforce quality. The only plausible explanation of these divergences is difference in the quality and attention of management.\n\f"}, "003295.png": {"text": "Company\n\nNew England Telephons\nNew York Telephones\nSouth Central Bell\n\nUS West\n\nMlinois Bell\n\nBell of Pennsylvania\n\nTABLE 18.2\n\nProductivity differences among former Bell operating companies\n\nTHINGS CAN CHANGE IN A HURRY\n\nCost per Access Line\n4988 19091 Change\n$482 $4360 -9.5%\n$531 \u00ab$564 6.2%\n$482 $430 -10.6%\n$489 =69$401 _-18.0%\n$384 \u00ab6 $384 0.0%\n$368 \u00ab= $388 5.4%\n\nCustomer Service\n\nCost per Access Line\n1988 1991 Change\n$41.70 $46.10 10.6%\n$4760 \u00a9 $49.30 3.6%\n$38.10 $40.40 6.0%\n$38.80 $32.40 -16.5%\n$36.00 $39.70 10.3%\n$29.60 $36.20 22.9%\n\nAsecond piece of evidence that management matters is that patterns of change in performance are highly episodic. At the com-\n\npany level, costs in some years fall dramatically\u2014up to 20 percent\u2014and performance improves just as sharply. The motivating\n\nforce is often competitive pressure. As we have seen, Compaq responded to its crisis in 1991 by tripling sales per employee over the\n\nnext three years. In other years, performance can remain level or even deteriorate. Companies and industries regularly move from\n\f"}, "003296.png": {"text": "one pole to the other, from significant improvements to stasis to decline, without the impetus of new technology or changes in the\navailability of capital.\n\nIn contrast, changes in potential output almost certainly occur at a slow and measured pace, and almost by definition, move\nonly ina single direction: upward. A company can change its workforce only gradually, and the pool from which that workforce is\ndrawn changes even more slowly. Even high levels of new investment in any single year have only a relatively small impact on a\ncompany\u2019s overall capital stock. We also know that most kinds of technology diffuse slowly and steadily throughout both compa-\nnies and industries.\n\nThe discrepancy between the brisk rate at which performance can vary and the much slower pace at which the factors that\ndetermine potential output\u2014technology, capital investment, and quality of the labor force\u2014change suggests that management\n\ninterventions, both positive and negative, are responsible for most of the improvements, and the declines.\n\nMANUFACTURING PRODUCTIVITY HAS BEEN TRANSFORMED\n\nThird, the experience of productivity growth in manufacturing in the United States in the five years between 1980 and 1985\nspeaks strongly for the importance of management. From the end of WWII until 1970, manufacturing productivity in the United\nStates grew at an annual rate of around 3 percent. But from 1970 to 1980, annual growth dropped to0.7 percent. This performance\nwas far behind that in most of the other advanced industrial countries. Japan, Germany, and Italy outpaced the United States.\nCanada and Britain did only slightly better.\n\nAsa result, the late 1970s and early 1980s were the years of America\u2019s \u201cdeindustrialization,\u201d when it appeared only a matter of\ntime before all U.S. workers would be serving food to Japanese tourists, in buildings that Japanese investors had already purchased.\nYet instead of continuing in this direction, between 1986 and 1991, productivity growth in U.S. manufacturing accelerated by\nabout 2 percent per year, both absolutely and relative to most other major manufacturing countries. By the late 1990s, faster pro-\n\nductivity growth in the United States had made it an unrivaled economic superpower.\n\f"}, "003297.png": {"text": "This remarkable turnaround cannot be accounted for by the conventional economic sources of productivity growth. Govern-\nment budget deficits and real (i.e., post-inflation) interest rates in the United States were far higher in the late 1980s than they had\nbeen in the late 1970s. The workforce did not benefit from any large influx of new workers substantially superior to existing em-\nployees. The educational performance of schools had improved only slightly, if at all, since the 1970s. Research and development\n\nexpenditures had fallen, relative to those in the other industrialized countries, over the same period.\n\nTABLE 18.3\nManufacturing productivity relative to the United States, 1970-80 and 1985-91\n\n1970-80 1985-91\nJapan 5.2 higher 2.3 higher\nGermany 2.0 higher -1.1 bwer\nCanada 0.2 higher 2.6 lbwer\nItaly 2.4 higher Oeven\nUnited Kingdom 0.2 higher 1.1 higher\n\nWhat had changed for the better was the attitude, training, and focus of American managers. Prior to 1980, management\neducation in the United States had concentrated more on finance and marketing than on operations. But starting in the late 1970s,\nalmost certainly induced by the intensity of overseas competition, that emphasis began to change. Techniques and goals like\nbenchmarking, reengineering, quality circles and total quality management, just-in-time production systems, and six sigma stan-\n\ndards helped to focus management attention on operational performance.\n\f"}, "003298.png": {"text": "The improvement in manufacturing productivity has been sustained well past the point at which firms were threatened with\nextinction if they did not reform their operations. The rate of growth has accelerated without significant increases in the rate of\ncapital investment, without measurable improvements in the quality of the labor force, and without a ballooning of spending on\n\nresearch and development. The one constant has been the revived emphasis on operational efficiency in management.\n\nCASE STUDIES TELL THE TALE\n\nThe fourth and final kind of evidence on the importance of management comes from detailed case studies. These appear in anum-\nber of sources, but they convey a uniform message. Differences in productivity across firms and plants are surprisingly large and\npersistent, and these differences are due predominantly to differences in management performance. Three examples illustrate the\n\ngeneral findings of these studies.\n\nCase One: Connecticut Mutual\n\nJust before Christmas 1990, a manager newly arrived from another company convened a task force whose goal was to increase\nproductivity by 35 percent over the next two years in administrative support operations. She had had success at her previous po-\nsitions in setting just such an arbitrary target and meeting it, and she intended to use the same tactic at Connecticut Mutual. The\ndivision involved had around 500 employees at the time the project began. The goal was to reduce that figure by around 175 full-\ntime equivalent employees. In the first year, a labor force reduction of 20 percent was realized, against a target of 25 percent. By all\nmeasures, service quality improved and useful output increased, despite the drop in staffing. For the second year, the target was 15\npercent of the remaining workforce; the actual result showed a 6 percent decline (table 18.4).\n\nBut the entire reduction was achieved during the first half of the year. At midyear, the company\u2019s chief executive announced\nhis pending retirement, eighteen months hence. Both the manager of the project and the heads of the cooperating departments\n\nturned their attention to the succession process. Productivity improvements stopped for the remainder of the second year and all\n\f"}, "003299.png": {"text": "of the final year. The critical driving force in the improvement process was clearly management attention. When it focused else-\nwhere, the process ground to a halt.\n\nThe contributions of factors other than management attention to this performance improvement were limited. There was no\nupgrading of the labor force, no influx of new, highly trained workers. The technology used tended to be well-seasoned, usually\nfive to seven years old. Attempts to use cutting-edge technology were usually failures. Capital investments, both tangible and\nintangible, were essential. But as table18.5 indicates, the returns on these investments were substantial.: These results are typical\nof performance improvement projects. When the projects involve a coordinated management effort, the returns range from 50 to\neven 100 percent or more. When the expenditures are less focused, the returns are smaller by an order of magnitude. The essential\n\ninput is management.\n\nTABLE 18.4\n\nHead count changes at Connecticut Mutual (full-time equivalents)\n\nPlanned Actual Change asa\nChange Change % of Total Workforce\n1991 -125 -100 \u201420%\n1992 -61 -28 -6%\n1993 3 0 Ab\n\nTABLE 18.5\n\nExpenses and savings at Connecticut Mutual ($ million)\n\f"}, "003300.png": {"text": "Capital Incremental Annual\nInvested Expense Savings\n\n1991 $3.6 $2.2 $1.7\n1992 $0.7 $0.5 $3.7\n1993 $0.8 $0.5 $45\n\nCase Two: Bank Credit Card Operations\n\nIn this second example, management's attention was diverted not by a succession struggle but by more fundamental problems.\nThe credit card operations of a major bank, widely regarded as the industry leader in efficiency, saw its administrative expenses\nrise sharply in all areas between 1992 and 1994 (table 18.6). In 1991, credit card loan losses had increased as a result of the 1990-\n91 recession. Initially, this familiar cyclical problem did not cause alarm. But when the level of losses persisted into 1993, after the\nend of the recession, all efforts were focused on fixing that problem. It was in the wake of this diversion of management's attention\nthat productivity deteriorated. The loan losses represented a larger financial challenge, and stemming them was the correct prior-\n\nity. But the figures indicate how difficult it is to maintain a focus on efficiency while fighting fires elsewhere.\n\nTABLE 18.6\n\nCredit card operations: Efficiency and loan losses (1990=100)\n\nNet Cash\nFlow\n-$4.1\n$2.5\n$3.2\n\f"}, "003301.png": {"text": "Administrative Net Credit\n\nExpense Losses\n1990 100 100\n1901 108 180\n1992 103 158\n1908 128 127\n1904 131 101\n\nCase Three: Responding to a Strike\n\nDuring a two-week strike in 1989, at a former Bell Telephone operating company, 52,000 workers, out of a total of 74,000\nemployees, walked off their jobs. It fell to the remaining 22,000 managers and other nonunion employees to keep the phone sys-\ntem running. In the first week of the strike, all but 1,000 of the managers filled in for the striking workers. But by the end of the\nsecond week, on-the-job learning had proceeded so rapidly that half of the managers could return to their regular work, leaving\nonly 11,000 to do the jobs of the strikers. Essentially all the management work that had been done before the strike was then\nbeing performed. The only two tasks of the prestrike phone company that were not getting done were connecting new residential\ncustomers where the jobs involved rewiring of the network, and constructing new outside plant (lines, poles, junction boxes).\nAnalysis of these tasks indicated that roughly 4,000 additional workers would have been required to get them done. It appears that\nin responding to a crisis, the company was able to perform all its prior tasks with 26,000 workers, about one-third of its prestrike\nlabor force. The effort represented a tripling of productivity with no new capital or technology, but with a very intense application\n\nof management attention.\n\f"}, "003302.png": {"text": "To summarize these studies and extend their implications, productivity improvement projects at the firm level have enormous\nreturns on the capital necessary to fund them. These returns are so high that their attractiveness is unlikely to be affected by\nchanges in the cost of capital of even 5 to 10 percentage points. Changes in a company\u2019s operating workforce associated with these\nsuccessful projects were small to nonexistent. In most cases, it was the same workers who perform at high levels after these inter-\nventions who were performing at lower levels before they were introduced.\n\nThe head count, however, may have declined. The technologies employed tend to be seasoned, trailing edge rather than leading\nedge. Research suggests that attempting to take advantage of untried and innovative technologies often creates more problems\nthan it solves. (For a number of companies, the true software \u201ckiller-app\u201d has been a fully integrated, enterprise resource planning\npackage; difficulties with implementing it effectively put some firms out of business.) The critical element in successful perfor-\n\nmance improvement is sustained, focused management attention.\n\nMANAGEMENT AND COMPANY PERFORMANCE\n\nThe importance of focused attention emerges from other, broader analyses of good company management. In the study of compa-\nnies making the transition from ordinary to outstanding performance described in Jim Collins\u2019s modern management classic Good\nto Great, almost all the firms that flourished began the change by adopting a simple and clear strategic focus. Kimberly-Clark sold\nits mill and concentrated on marketing paper products. Walgreen\u2019s and Kroger focused on simple, basic retail businesses in well-\ndefined geographic markets. Wells Fargo concentrated on basic banking on the West Coast. Nucor focused on certain kinds of steel\nmaking and marketing. Abbott Laboratories dedicated itself to particular kinds of medical supplies. Gillette concentrated on razor\ntechnology and shaving products, Philip Morris on cigarettes, Circuit City on appliance retailing (although, to its detriment, it did\nnot try to dominate any particular geographic region), and Fannie Mae on mortgages. Even Pitney Bowes, which expanded its at-\n\ntention beyond postage machines, was more focused than its potential rivals like Addressograph or Xerox.\n\f"}, "003303.png": {"text": "The subsequent experience of some of these companies underscores the indispensable role of management attention. Where\ngreat companies\u2019 performances have deteriorated, there appears to be some important dissipation of management focus. Gillette\nmoved into batteries; Circuit City tried to compete nationwide in an increasingly complex product arena. Walgreen\u2019s expanded na-\ntionally. Philip Morris has had to fight for its life in the courts, when it wasn\u2019t buying or selling food and beverage businesses.\n\nCompanies with outstanding performance have tended to be narrowly focused on particular industries or even subsegments\nof industries. The great exception to this rule is General Electric.: Yet even its history is not completely at variance with the overall\npattern. Before Jack Welch became CEO in 1981, his predecessors had abandoned its strategic principle of being either the first or\nthe second firm in every market in which it had a presence. Instead, GE had entered sectors like natural resources, where it could\nnot hope to achieve that goal. At the time Welch took over, GE had returns on equity of 17-18 percent over the previous fifteen\nyears. Without the entry into natural resources, made in the first half of the 1970s, its results would have been stronger.\n\nOver the subsequent twenty-two years, with Welch in charge, return on equity rose to roughly 24 percent, while overall growth\nin earnings accelerated. This performance made GE the most valuable company in the world by the year 2000. It was not achieved\nby simplification of GE\u2019s segment focus. Although Welch did exit the natural resource business, much of its success was attrib-\nutable to GE Capital Corporation, General Electric\u2019s profitable expansion into a broad range of financial services. The company\nalso bought a television network (NBC) and developed a separate medical products group. Under Welch, it expanded from six seg-\nments, including a stand-alone international division, to eleven.\n\nBut Welch did reinstitute the policy of each GE business being either first or second in a market, or else getting out. At the same\ntime, its decentralized segments were strongly refocused on operational efficiency and continuing cost reduction. Early in his ten-\nure, Welch was awarded the nickname \u201cNeutron Jack,\u201d acknowledging his forceful effort to reduce the workforce and cut costs (the\n\u201cneutron\u201d bomb is a nuclear device capable of killing people without damaging physical property). While GE entered a number of\ndisparate businesses, its strategic principles were clear, unambiguous, and easy to apply. A simple strategic mandate allowed man-\n\nagement at the operating level to concentrate on efficiency. The net result was outstanding business performance.\n\f"}, "003304.png": {"text": "The important lesson to be drawn from all of this experience, as it relates to both productivity growth and overall business\nperformance, is that effective strategy formulation is not the only source of superior returns. Without a doubt, strategy does mat-\nter. Pursuit of unrealistic strategic goals guarantees poor business outcomes. Warren Buffett has observed that when management\nwith a good reputation meets an industry with a bad reputation, most often it is the reputation of the industry that survives. Ill-\nconceived initiatives that ignore the structure of competitive advantage and competitive interactions is a leading cause of business\nfailure.\n\nHowever, strategy is not the whole story. An obsession with strategy at the expense of the pursuit of operational excellence\nis equally damaging. There is simply too much evidence of variability among strategically identical firms, and of the speed with\nwhich performance can be improved without any changes in the larger economic environment, to discount the importance of\nmanagement.\n\nStrategy formulation should have three underlying goals. The first is to identify the competitive universe in which the com-\npany operates, and to locate its position regarding competitive advantages and barriers to entry. If the company does enjoy com-\npetitive advantages, the second goal is to recognize and manage effectively competitive interactions with other firms on whom the\ncompany\u2019s performance critically depends. The third goal, which applies to all companies whether or not they benefit from com-\npetitive advantages, is to develop a clear, simple, and accurate vision of where the company should be headed. This vision should\nallow management to focus the greater part of its attention on getting there. The approach to strategic analysis offered in this book\n\nhas been designed to help managers accomplish these goals.\n\f"}, "003305.png": {"text": "APPENDIX\n\nMethods for Measuring Return on Resources or Investments\n\nIn assessing a company\u2019s performance, there is a serious drawback in focusing on income, whether operating or net income, rela-\ntive to sales. These measures are revealing when looking at a single company\u2019s performance over time, or comparing firms within\none industry. But since industries differ in the amount of assets they need to generate a dollar of revenue, and companies differ on\nhow they raise the capital to pay for the assets, margin comparisons that cross industry boundaries are apt to be misleading. So\nseveral additional methods have been used to make more sensible comparisons between firms in different industries and sharpen\nthe test for the presence of barriers to entry.\n\nOne approach is return on assets (ROA), in which net income is divided by the total assets in the firm. A second is return on\nequity (ROE), which is net income divided by the book value of the equity on the balance sheet. This figure measures the returns\nto the owners of the business\u2014how many dollars they receive for each dollar they invested. A third measure, and the one we nor-\nmally prefer when all the data are available, is return on invested capital (ROIC), which counts the returns both to shareholders and\n\nto lenders. A company earning money can jack up its ROE by increasing leverage\u2014raising debt and reducing the portion of assets\n\f"}, "003306.png": {"text": "funded by equity\u2014without in any way improving its operations. More debt generally means more risk, but ROE by itself provides\nno information on debt levels. ROIC solves that problem by treating both debt and equity as invested capital.\n\nThere are a number of ways to calculate both the numerator (earnings) and the denominator (invested capital). For the numer-\nator, we favor the same adjusted operating earnings figure that we use in calculating the margin on sales, and for the same reasons:\nno consideration of tax management skills, interest rates, or exceptional items. For the denominator, we take all the assets and\nthen subtract the non-interest-bearing current liabilities. These include accounts payable, accrued expenses, taxes payable within\nthe year, and a few miscellaneous items. They reflect the sources of funds a company gets just by being in business and on which it\ndoes not need to pay interest. We also subtract surplus cash, defined as all cash in excess of 1 percent of revenues, on the grounds\nthat the surplus is not necessary for running the business and could be used to pay down debt or buy back equity. The result is the\ntotal of the necessary assets that have been funded by debt or equity. There are more sophisticated and intricate ways of figuring\n\ninvested capital, but this approach is generally adequate and relatively easy to calculate.\n\ntotal assets\nminus non-interest-bearing current liabilities (NIBCLs)\nminus surplus cash (in excess of 1 percent of revenue)\n\nequals invested capital\n\f"}, "003307.png": {"text": "NOTES\n\nMany chapters draw heavily on business school cases for both narrative and quantitative information. All the relevant cases are\ncited at the beginning of the references for each chapter.\nUnless otherwise noted, the figures that represent time series variables like operating income and return on invested capital are\n\nbased on data from the companies\u2019 annual reports and 10K filings, as compiled and recorded in the Compustat database.\n\nCHAPTER 1\n\n4 Michael Porter, Competitive Strategy: Techniques for Analyzing Industries and Competitors (New York: Free Press, 1980).\n\nCHAPTER 4\n\n72 Hewlett-Packard printer share, Hewlett-Packard Web site (www.hp.com), citing IDC reports.\n\f"}, "003308.png": {"text": "74 Apple\u2019s school share, Education Week on the Web, May 15, 2002. The diagram is reproduced with the permission of Harvard Busi-\n\nness School Publishing.\n\nCHAPTER 5\n\nWal-Mart\n\nHarvard Business School, Case 9-387-018, Wal-Mart Stores\u2019 Discount Operations, \\1986.\n\n96 Target segment data from Target annual reports, 1994-2001.\n\n\u2018Wal-Mart segment information, annual reports 1996-2002 and Form 10K filings.\n\nCoors\n\nHarvard Business School, Case 9-388-014, Adolph Coors in the Brewing Industry, 1987.\n\nCHAPTER 6\n\nMichael van Biema, Bruce Greenwald, and Charlotte Kaufman, \u201cCorporate Rebirth: Compaq Computer,\u201d Columbia Business School\n\nCase.\n\f"}, "003309.png": {"text": "CHAPTER7\n\nPhilips\n\nHarvard Business School, Case 9-792-035, Philips\u2019 Compact Disc Introduction (A).\n\n138 Sony history is available on the company\u2019s Web site.\n\nCisco\n\n147 and following: Paul Johnson, \u201cCisco and the Network Hardware Tornedo,\u201d in Geoffrey A. Moore, Paul Johnson, and Tom Kip-\npola, The Gorilla Game: Picking Winners in High Technology, Revised Edition (New York: HarperBusiness, 1999); Paul Johnson, \u201cAn\nOpen Letter to Warren Buffett Re: Cisco Systems,\u201d Robertson Stephens & Company Report, February 20, 1997; Paul Johnson, Re-\nsearch Reports on Cisco Systems, Inc., November 5, 2001, May 16, 2002, Robertson Stephens & Company.\n\n149 Cisco annual reports, 1996-2003.\n\n150 Infrastructure, \u201cRouter Market Stabilizes, Cisco Continues to Dominate,\u201d May 16, 2003.\n\nCHAPTER 9\n\nHarvard Business School Cases:\n\f"}, "003310.png": {"text": "9-387-108, Coca-Cola Versus Pepsi-Cola (A), 1986\n\n9-387-109, Coca-Cola Versus Pepsi-Cola (B)\n\n9-387-110, Coca-Cola Versus Pepsi-Cola (C)\n\n9-391-179, Coca-Cola Versus Pepsi-Cola and the Soft Drink Industry\n\n9-794-055, Cola Wars Continue: Coke vs. Pepsi in the 1990s\n\n9-799-117, A Hundred Years War: Coke vs. Pepsi, 1890s-1990s\n\n193 Footnote, Warren Buffett in talk at Columbia Business School, May 9, 2002.\n\n194 New Coke introduction, Jack Honomichl, \u201cMissing Ingredients in \u2018New\u2019 Coke\u2019s Research,\u201d in Esther Thorson (Ed), Advertising\n\nAge: The Principles of Advertising at Work (Lincolnwood, IL: NTC Business Books, 1989).\n\n198 Quotes from Goizueta and Ivester in Patricia Sellers, \u201cHow Coke Is Kicking Pepsi\u2019s Can,\u201d Fortune, 134:8 (October 28, 1996): 70-\n84.\n\n198 Patricia Sellers, \u201cCrunch Time for Coke,\u201d Fortune, 140:2 (July 19, 1999): 72-78.\n\n199 The \u201crational player\u201d phrase is from Beverage World, December 1999; see also the issue of January 15, 2000.\n\f"}, "003311.png": {"text": "CHAPTER 10\n\nHarvard Business School, Case 9-387-096, Fox Broadcasting Company, 1993.\n\nCHAPTER 12\n\nHarvard Business School, Case 9-390-025, The U.S. Airline Industry, 1978-1988,1990.\n\n238 Benjamin Graham, The Intelligent Investor, Fourth Revised Edition (New York: HarperBusiness, 1973), p. xiv.\n\n239 Buffett quote, from a talk at the Kenan-Flager School of Business, University of\n\nNorth Carolina, on the PBS video Warren Buffett Talks Business, 1995.\n\n248 Iverson quote, in Forbes, September 14, 1992.\n\n251 pay cut to ward off Continental, in USA Today, September 22, 1994.\n\n252 entrance of many new airlines, Economist, November 15, 2004.\n\n253 Iverson quote, in New York Times, May 22, 1995. Accumulated losses, from testimony of Danny Wright, President and COO of\nKiwi International, before the House Committee on Transportation and Infrastructure, Federal Document Clearing House, March\n\n22,1995.\n\f"}, "003312.png": {"text": "253 On Kiwi\u2019s demise, see also Bergen Record, June 18, 1996; Aviation Daily, October 16, 1996; Aviation Week and Space Technology,\nOctober 7, 1996.\n\nCHAPTER 13\n\nHarvard Business School, Case 376-266, Polaroid-Kodak, 1976; and Case 378-173, Polaroid-Kodak (B1), 1978.\n\n256 Land quote, from BusinessWeek, March 2, 1981.\n\n258 Land quote, from Newsweek, July 26, 1982.\n\n266 Land quote, from BusinessWeek, March 2, 1981.\n\n267 Polaroid\u2019s improving relationship with distributors, BusinessWeek, June 20, 1977.\n\n268 instant cameras\u2019 share of the market, in Forbes, February 5, 1979.\n\n269 decline in market share by 1981, BusinessWeek, March 2, 1981. On Kodak\u2019s losses, Forbes, November 15, 1984.\n\n269 On the court case and decision, New York Times, September 14, 1985; Los Angeles Times, October 12, 1985. Layoffs by Kodak,\nChemical Week, January 5, 1986.\n\n270 almost $900 million in damages, United Press International, October 12, 1990.\n\f"}, "003313.png": {"text": "271 \u201cThe day we deliver,\u201d in BusinessWeek, June 20, 1977.\n\n271 Kodak in the copier business, Forbes, November 11, 1984, and St. Petersburg Times, March 18, 1999.\n\nCHAPTER 15\n\nNintendo\n\nHarvard Business School, Case N9-795-102, Power Play (A) Nintendo in 8-Bit Video Games, 1995.\n\n302 virtuous circle, Adam M. Brandenburger and Barry J. Nalebuff, Co-opetition (New York: Currency Doubleday, 1996).\n\n304 \u201cMarketing Kombat,\u201d in Advertising Age, July 17,1995.\n\nLead-Based Additives\n\nHarvard Business School, Case 9-794-111, Marketing Practices in the Lead-Based Gasoline Additive Industry (A), 1995. The EPA\n\nWeb site, www.EPA.gov, History, Timeline, has the dates for EPA regulations.\n\nChemical Week, January 19, 1983.\n\n312 \u201coligopoly,\u201d in Chemical Week, August 26, 1981.\n\f"}, "003314.png": {"text": "313 Federal Trade Commission ruling, Metals Week, April 11, 1983.\n\n313 Ethyl\u2019s additive as percentage of income, Chemical Week, April 14, 1982.\n\n314 Ethyl\u2019s arrangment with Octel, M2 Presswire, December 12, 1997.\n\n314 Great Lake\u2019s earnings by segment, BusinessWeek, May 15, 1995. Ethyl segment information, Ethyl Form 10K, 1997 and 1998.\n\n315 prior notification, M2 Presswire, April 1, 1998. Octel annual reports, 2000-2002.\n\nSotheby\u2019s\n\n316 introduction of buyer\u2019s premium and other background information, Financial Times, February 26, 2000.\n\n317 sliding buyer's commission, Independent, February 27, 2000.\n\n318 first meeting of Taubman and Tennant and other information from the trial, New York Observer, November 26, 2001.\n\n318 Davidge\u2019s deal, Financial Times, January 29, 2000.\n\n319 pressure on Brooks, New York Times, July 27, 2000.\n\n319 settlement of $256 million, New York Times, September 23, 2000.\n\n319 Tennant remained in Britain, Daily News (New York), December 6, 2001.\n\f"}, "003315.png": {"text": "319 \u201cThey needed Mr. Davidge\u2019s notes,\u201d New York Observer, November 26, 2001.\n319 shared some 90-95 percent, Daily News (New York), December 6, 2001.\n\n321 increase in buyer's fees, Wall Street Journal, February 25, 2000.\n\nCHAPTER 16\n\n325 Figure 16.1 appeared originally in Bruce Greenwald, Judd Kahn, Paul Sonkin, and Michael van Biema, Value Investing from\nGraham to Buffett and Beyond (New York: John Wiley and Sons, 2001), which offers a fuller treatment of the value approach to\n\ninvesting.\n\n340 footnote, Warren Buffett, \u201cThe Superinvestors of Graham-and-Doddsville,\u201d in Benjamin Graham, The Intelligent Investor,\n\nFourth Revised Edition (New York: HarperBusiness, 1973). Buffett\u2019s essay was written in 1984.\n\nCHAPTER 17\nMichael E. Porter, \u201cFrom Competitive Advantage to Corporate Strategy,\u201d Harvard Business Review, May-June, 1987.\n\n346 footnote, Gregor Andrade, Mark Mitchell, and Erik Stafford, \u201cNew Evidence and Perspectives on Mergers,\u201d Journal of Economic\n\nPerspectives, 15:2, 2001.\n\f"}, "003316.png": {"text": "349 AT&T acquiring Teleport, \u201cAT&T Merges with Teleport,\u201d Discount Long Distance Digest, January 19, 1998.\n\nCHAPTER 18\n\n366 Table 18.1, Michael van Biema and Bruce Greenwald, \u201cManaging Our Way to Higher Service-Sector Productivity,\u201d Harvard\n\nBusiness Review, 75:4, July-August, 1997.\n\nTables 18.2, 18.4, and 18.5 are drawn from the unpublished version of this paper, table 18.6 from the published version. Also A.M.\n\nBest Reports on insurance companies.\n\n367 AT&T, MCI, and Sprint employee figures, the companies\u2019 annual reports 1992-94.\n\n367 footnote, Martin Neil Baily, Charles Holten, David Campbell, \u201cProductivity Dynamics in Manufacturing Plants,\u201d Brookings Pa-\n\npers: Microeconomics, 1992. This article is the source of table 18.3.\n\n369 on the revival of U.S. manufacturing, Robert H. Hayes, Steven C. Wheelwright, and Kim B. Clark, Dynamic Manufacturing: Cre-\n\nating the Learning Organization (New York: Free Press, 1988).\n\n374 Jim Collins, Good to Great: Why Some Companies Make the Leap...and Others Don\u2019t (New York: HarperCollins, 2001).\n\nAPPENDIX\n\f"}, "003317.png": {"text": "378 G. Bennett Stewart\u2019s The Quest for Value (New York: HarperBusiness, 1991) has a detailed discussion of more precise ways of\n\nmeasuring ROIC by one of the originators of Economic Value Added analysis.\n\f"}}